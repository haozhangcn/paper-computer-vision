440. **Generalizing to Unseen Domains via Adversarial Data Augmentation** --*Riccardo Volpi &middot; Ozan Sener &middot; Hongseok Namkoong &middot; John C Duchi &middot; Vittorio Murino &middot; Silvio Savarese*
 > We are concerned with learning models that generalize well to different unseen domains. We consider a worst-case formulation over data distributions that are near the source domain in the feature space. Only using training data from the source domain, we propose an iterative procedure that augments the dataset with examples from a fictitious target domain that is "hard" under the current model. We show that our iterative scheme is an adaptive data augmentation method where we append adversarial examples at each iteration. For softmax losses, we show that our method is a data-dependent regularization scheme that behaves differently from classical regularizers (e.g., ridge or lasso) that regularize towards zero. On digit recognition and semantic segmentation tasks, we empirically observe that our method learns models that improve performance across a priori unknown data distributions. 
441. **Semi-supervised Deep Kernel Learning: Regression with Unlabeled Data by Minimizing Predictive Variance** --*Neal Jean &middot; Sang Xie &middot; Stefano Ermon*
 > Large amounts of labeled data are typically required to train deep learning models. For many real-world problems, however, acquiring additional data can be expensive or even impossible. We present semi-supervised deep kernel learning (SSDKL), a semi-supervised regression model based on minimizing predictive variance in the posterior regularization framework. SSDKL combines the hierarchical representation learning of neural networks with the probabilistic modeling capabilities of Gaussian processes. By leveraging unlabeled data, we show improvements  on a diverse set of real-world regression tasks over supervised deep kernel learning and semi-supervised methods such as VAT and mean teacher adapted for regression.
442. **Sample Efficient Stochastic Gradient Iterative Hard Thresholding Method for Stochastic Sparse Linear Regression with Limited Attribute Observation** --*Tomoya Murata &middot; Taiji Suzuki*
 > We develop new stochastic gradient methods for efficiently solving sparse linear regression in a partial attribute observation setting, where learners are only allowed to observe a fixed number of actively chosen attributes per example at training and prediction times. It is shown that the methods achieve essentially a sample complexity of $O(1/\varepsilon)$ to attain an error of $\varepsilon$ under a variant of restricted eigenvalue condition, and the rate has better dependency on the problem dimension than existing methods. Particularly, if the smallest magnitude of the non-zero components of the optimal solution is not too small, the rate of our proposed {\it Hybrid} algorithm can be boosted to near the minimax optimal sample complexity of {\it full information} algorithms. The core ideas are (i) efficient construction of an unbiased gradient estimator by the iterative usage of the hard thresholding operator for configuring an exploration algorithm; and (ii) an adaptive combination of the exploration and an exploitation algorithms for quickly identifying the support of the optimum and efficiently searching the optimal parameter in its support. Experimental results are presented to validate our theoretical findings and the superiority of our proposed methods.
443. **Meta-Reinforcement Learning of Structured Exploration Strategies** --*Abhishek Gupta &middot; Russell Mendonca &middot; YuXuan Liu &middot; Pieter Abbeel &middot; Sergey Levine*
 > Exploration is a fundamental challenge in reinforcement learning (RL). Many current exploration methods for deep RL use task-agnostic objectives, such as information gain or bonuses based on state visitation. However, many practical applications of RL involve learning more than a single task, and prior tasks can be used to inform how exploration should be performed in new tasks. In this work, we study how prior tasks can inform an agent about how to explore effectively in new situations. We introduce a novel gradient-based fast adaptation algorithm -- model agnostic exploration with structured noise (MAESN) -- to learn exploration strategies from prior experience. The prior experience is used both to initialize a policy and to acquire a latent exploration space that can inject structured stochasticity into a policy, producing exploration strategies that are informed by prior knowledge and are more effective than random action-space noise. We show that MAESN is more effective at learning exploration strategies when compared to prior meta-RL methods, RL without learned exploration strategies, and task-agnostic exploration methods. We evaluate our method on a variety of simulated tasks: locomotion with a wheeled robot, locomotion with a quadrupedal walker, and object manipulation.
444. **Task-Driven Convolutional Recurrent Models of the Visual System** --*Aran Nayebi &middot; Daniel Bear &middot; Jonas Kubilius &middot; David Sussillo &middot; James J DiCarlo &middot; Surya Ganguli &middot; Daniel Yamins*
 > Feed-forward convolutional neural networks (CNNs) are currently state-of-the-art for object classification tasks such as ImageNet. Further, they are quantitatively accurate models of temporally-averaged responses of neurons in the primate brain's visual system.  However, biological visual systems have two ubiquitous architectural features not shared with typical CNNs: local recurrence within cortical areas, and long-range feedback from downstream areas to upstream areas.  Here we explored the role of recurrence in improving classification performance. We found that standard forms of recurrence (vanilla RNNs and LSTMs) do not perform well within deep CNNs on the ImageNet task. In contrast, custom cells that incorporated two structural features, bypassing and gating, were able to boost task accuracy substantially. We extended these design principles in an automated search over thousands of model architectures, which identified novel local recurrent cells and long-range feedback connections useful for object recognition. Moreover, these task-optimized ConvRNNs explained the dynamics of neural activity in the primate visual system better than feedforward networks, suggesting a role for the brain's recurrent connections in performing difficult visual behaviors.
445. **Experimental Design for Cost-Aware Learning of Causal Graphs** --*Erik Lindgren &middot; Murat Kocaoglu &middot; Alexandros Dimakis &middot; Sriram Vishwanath*
 > We consider the minimum cost intervention design problem: Given the essential graph of a causal graph and a cost to intervene on a variable, identify the set of interventions with minimum total cost that can learn any causal graph with the given essential graph. We first show that this problem is NP-hard. We then prove that we can achieve a constant factor approximation to this problem. We then constrain the sparsity of each intervention. We create an algorithm that returns an intervention design that is nearly optimal in terms of size for sparse graphs with sparse interventions and we discuss how to use it when there are costs on the vertices.
446. **Exploiting Numerical Sparsity for Efficient Learning : Faster Eigenvector Computation and Regression** --*Neha Gupta &middot; Aaron Sidford*
 > In this paper, we obtain improved running times for regression and top eigenvector computation for numerically sparse matrices. Given a data matrix $\mat{A} \in \R^{n \times d}$ where every row $a \in \R^d$ has $\|a\|_2^2 \leq L$ and numerical sparsity $\leq s$, i.e. $\|a\|_1^2 / \|a\|_2^2 \leq s$, we provide faster algorithms for these problems for many parameter settings.  For top eigenvector computation, when $\gap > 0$ is the relative gap between the top two eigenvectors of $\mat{A}^\top \mat{A}$ and $r$ is the stable rank of $\mat{A}$ we obtain a running time of $\otilde(nd + r(s + \sqrt{r s}) / \gap^2)$ improving upon the previous best unaccelerated running time of $O(nd + r d / \gap^2)$. As $r \leq d$ and $s \leq d$ our algorithm everywhere improves or matches the previous bounds for all parameter settings.  For regression, when $\mu > 0$ is the smallest eigenvalue of $\mat{A}^\top \mat{A}$ we obtain a running time of $\otilde(nd + (nL / \mu) \sqrt{s nL / \mu})$ improving upon the previous best unaccelerated running time of $\otilde(nd + n L d / \mu)$. This result expands when regression can be solved in nearly linear time from when $L/\mu = \otilde(1)$ to when $L / \mu = \otilde(d^{2/3} / (sn)^{1/3})$.  Furthermore, we obtain similar improvements even when row norms and numerical sparsities are non-uniform and we show how to achieve even faster running times by accelerating using approximate proximal point \cite{frostig2015regularizing} / catalyst \cite{lin2015universal}. Our running times depend only on the size of the input and natural numerical measures of the matrix, i.e. eigenvalues and $\ell_p$ norms, making progress on a key open problem regarding optimal running times for efficient large-scale learning.
447. **Horizon-Independent Minimax Linear Regression** --*Alan Malek &middot; Peter Bartlett*
 > We consider a linear regression game: at each round, an adversary reveals a covariate vector, the learner predicts a real value, the adversary reveals a label, and the learner suffers the squared prediction error. The aim is to minimize the difference between the cumulative loss and that of the linear predictor that is best in hindsight. Previous work demonstrated that the minimax optimal strategy is easy to compute recursively from the end of the game; this requires the entire sequence of covariate vectors in advance. We show that, once provided with a measure of the scale of the problem, we can invert the recursion and play the minimax strategy without knowing the future covariates. Further, we show that this forward recursion remains optimal even against adaptively chosen labels and covariates, provided that the adversary adheres to a set of constraints that prevent misrepresentation of the scale of the problem. This strategy is horizon-independent, i.e. it incurs no more regret than the optimal strategy that knows in advance the number of rounds of the game. We also provide an interpretation of the minimax algorithm as a follow-the-regularized-leader strategy with a data-dependent regularizer, and obtain an explicit expression for the minimax regret. 
448. **A Convex Duality Framework for GANs** --*Farzan Farnia &middot; David Tse*
 > Generative adversarial network (GAN) is a minimax game between a generator mimicking the true  model and a discriminator distinguishing the samples produced by the generator from the real training samples. Given an unconstrained discriminator able to approximate any function, this game reduces to finding the generative model minimizing a divergence measure, e.g. the Jensen-Shannon divergence, to the data distribution. However, in practice the discriminator is constrained to be in a smaller class F such as neural nets. Then, a natural question is how the minimum divergence interpretation changes as we constrain F. In this work, we address this question by developing a convex duality framework for analyzing GANs. For a convex set F, this duality framework interprets f-GANs as finding the generative model with the minimum f-divergence to the distributions penalized to match the moments of the data distribution, with the moments specified by the discriminators in F. We show a similar result also holds for Wasserstein GANs. As a byproduct, we apply this duality framework to a specific mixture of an f-divergence and a Wasserstein distance. Unlike f-divergences we prove this mixed distance enjoys a continuous behavior in the generative model. This result suggests regularizing the discriminator in f-GANs by either constraining its Lipschitz constant or by adversarially training it using  Wasserstein risk minimization. We provide numerical experiments supporting our theoretical results.
449. **Multiple-Step Greedy Policies in Approximate and Online Reinforcement Learning** --*Yonathan Efroni &middot; Gal Dalal &middot; Bruno Scherrer &middot; Shie Mannor*
 > Multiple-step lookahead policies have demonstrated high empirical competence in Reinforcement Learning, via the use of Monte Carlo Tree Search or Model Predictive Control. In a recent work (Efroni et al., 2018), multiple-step greedy policies and their use in vanilla Policy Iteration algorithms were proposed and analyzed. In this work, we study multiple-step greedy algorithms in more practical setups. We begin by highlighting a counter-intuitive difficulty, arising with soft-policy updates: even in the absence of approximations, and contrary to the 1-step-greedy case, monotonic policy improvement is not guaranteed unless the update stepsize is sufficiently large. Taking particular care about this difficulty, we formulate and analyze online and approximate algorithms that use such a multi-step greedy operator. 
452. **Causal Inference and Mechanism Clustering of a Mixture of Additive Noise Models** --*Shoubo Hu &middot; Zhitang Chen &middot; Vahid Partovi Nia &middot; Laiwan CHAN &middot; Yanhui Geng*
 > The inference of the causal relationship between a pair of observed variables is a fundamental problem in science and approaches exploiting certain kind of independence in one single causal model are most commonly used. In practice, however, observations are often collected from multiple sources with heterogeneous causal models, which renders causal analysis results obtained by a single model skeptical. In this paper, we generalize the Additive Noise Model (ANM) to a mixture model, which consists of a finite number of ANMs, and provide the condition of its causal identifiability. To conduct model estimation, we propose a Gaussian Process Partially Observable Model (GPPOM) to learn the latent parameter associated with each observation, which enables us to not only infer the casual direction but also cluster observations according to their underlying generating mechanisms. Experiments on synthetic and real data demonstrate the effectiveness of our proposed approach.
453. **ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions** --*Hongyang Gao &middot; Zhengyang Wang &middot; Shuiwang Ji*
 > Convolutional neural networks (CNNs) have shown great capability of solving various artificial intelligence tasks. However, the increasing model size has raised challenges in employing them in resource-limited applications. In this work, we propose to compress deep models by using channel-wise convolutions, which replace dense connections among feature maps with sparse ones in CNNs. Based on this novel operation, we build light-weight CNNs known as ChannelNets. ChannelNets use three instances of channel-wise convolutions; namely group channel-wise convolutions, depth-wise separable channel-wise convolutions, and the convolutional classification layer. Compared to prior CNNs designed for mobile devices, ChannelNets achieve a significant reduction in terms of the number of parameters and computational cost without loss in accuracy. Notably, our work represents the first attempt to compress the fully-connected classification layer, which usually accounts for about 25% of total parameters in compact CNNs. Experimental results on the ImageNet dataset demonstrate that ChannelNets achieve consistently better performance compared to prior methods.
454. **Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model** --*Aaron Sidford &middot; Mengdi Wang &middot; Xian Wu &middot; Lin Yang &middot; Yinyu  Ye*
 > In this paper we consider the problem of computing an $\epsilon$-optimal policy of a discounted Markov Decision Process (DMDP) provided we can only access its transition function through a generative sampling model that given any state-action pair samples from the transition function in $O(1)$ time. Given such a DMDP with states $\states$, actions $\actions$, discount factor $\gamma\in(0,1)$, and rewards in range $[0, 1]$ we provide an algorithm which computes an $\epsilon$-optimal policy with probability $1 - \delta$ where {\it both} the run time spent and number of sample taken is upper bounded by  \[ O\left[\frac{|\cS||\cA|}{(1-\gamma)^3 \epsilon^2} \log \left(\frac{|\cS||\cA|}{(1-\gamma)\delta \epsilon} 		\right)  		\log\left(\frac{1}{(1-\gamma)\epsilon}\right)\right] ~. \] For fixed values of $\epsilon$, this improves upon the previous best known bounds by a factor of $(1 - \gamma)^{-1}$ and matches the sample complexity lower bounds proved in \cite{azar2013minimax} up to logarithmic factors.  We also extend our method to computing $\epsilon$-optimal policies for finite-horizon MDP with a generative model and provide a nearly matching sample complexity lower bound. 
455. **Why so gloomy? A Bayesian explanation of human pessimism bias in the multi-armed bandit task** --*Dalin Guo &middot; Angela J Yu*
 > How humans make repeated choices among options with imperfectly known reward outcomes is an important problem in psychology and neuroscience. This is often studied using multi-armed bandits, which are also frequently studied in machine learning. We present data from a human stationary bandit experiment, in which we vary the abundance and variability of reward availability (mean and variance of reward rate distributions). Surprisingly, subjects have significantly underestimated prior mean of reward rates -- elicited at the end of a bandit game, when they are asked to estimate the reward rates of arms never chosen during the game. Previously, human learning in the bandit task was found to be well captured by a Bayesian ideal learning model, the Dynamic Belief Model (DBM), albeit under an incorrect generative assumption of the temporal structure -- humans assume reward rates can change over time even when they are actually fixed. We find that the "pessimism bias" in the bandit task is well captured by the prior mean of DBM when fitted to human choices; but it is poorly captured by the prior mean of the Fixed Belief Model (FBM), an alternative Bayesian model that (correctly) assumes reward rates to be constant. This pessimism bias is also incompletely captured by a simple reinforcement learning model (RL) commonly used in neuroscience and psychology, in terms of fitted initial option values. While it seems highly sub-optimal, and thus mysterious, that humans have an underestimated prior reward expectation, our simulations show that an underestimated prior mean helps to maximize long-term gain, if the observer assumes volatility when reward rates are actually stable and uses a softmax decision policy instead of the optimal one (obtainable by dynamic programming). This raises the intriguing possibility that the brain underestimates reward rates to compensate for the incorrect non-stationarity assumption in the generative model and a suboptimal decision policy.
456. **Learning Link Prediction Heuristics from Local Subgraphs: Theory and Practice** --*Muhan Zhang &middot; Yixin Chen*
 > Link prediction is a key problem for network-structured data. Link prediction heuristics use some score functions, such as common neighbors and Katz index, to measure the likelihood of links. They have obtained wide practical uses due to their simplicity, interpretability, and (often) scalability. However, heuristic methods have strong assumptions on when two nodes are likely to have a link, which limits their effectiveness in networks where these assumptions fail. In this regard, a more reasonable way should be learning suitable ``heuristics'' from networks instead of using predefined ones. By extracting a local subgraph around each target link, we aim to learn a function mapping the subgraph patterns to link existence, thus automatically learning a ``heuristic'' that suits the current network. In this paper, we study this heuristic learning problem for link prediction. We first propose a $\gamma$-decaying heuristic theory. By unifying a wide range of heuristics into a single framework, we prove that all these heuristics can be well approximated from local subgraphs. Our results show that local subgraphs reserve rich information related to link existence. 
457. **Dropping Symmetry for Fast Symmetric Nonnegative Matrix Factorization** --*Zhihui Zhu &middot; Xiao Li &middot; Kai Liu &middot; Qiuwei Li*
 > Symmetric nonnegative matrix factorization (NMF)---a special but important class of the general NMF---is demonstrated to be useful for data analysis and in particular for various clustering tasks. Unfortunately, designing fast algorithms for Symmetric NMF is not as easy as for the nonsymmetric counterpart, the later admitting the splitting property that allows  efficient alternating-type algorithms. To overcome this issue, we transfer the symmetric NMF to a nonsymmetric one, then we can  adopt the idea from the state-of-the-art algorithms for nonsymmetric NMF to design fast algorithms solving symmetric NMF.  We rigorously establish that solving nonsymmetric reformulation returns a solution for symmetric NMF and then apply  fast alternating based algorithms for the corresponding reformulated problem. Furthermore, we show these fast algorithms admit strong convergence guarantee in the sense that the generated sequence is convergent at least at a sublinear rate and it converges globally to a critical point of the symmetric NMF.  We conduct experiments on both synthetic data and image clustering to support our result. 
458. **Scalable methods for 8-bit training of neural networks** --*Ron Banner &middot; Itay Hubara &middot; Elad Hoffer &middot; Daniel Soudry*
 > Quantized Neural Networks (QNNs) are often used to improve network efficiency during the inference phase, i.e. after the network has been trained. Extensive research in the field suggests many different quantization schemes. Still, the number of bits required, as well as the best quantization scheme, are yet unknown. Our theoretical analysis suggests that most of the training process is robust to substantial precision reduction, and points to only a few specific operations that require higher precision.  Armed with this knowledge, we quantize the model parameters,  activations and layer gradients to 8-bit, leaving at higher precision only the final step in the computation of the weight gradients. Additionally, as QNNs require batch-normalization to be trained at high precision, we introduce Range Batch-Normalization (BN) which has significantly higher tolerance to quantization noise and improved computational complexity. Our simulations show that Range BN is equivalent to the traditional batch norm if a precise scale adjustment, which can be approximated analytically, is applied. To the best of the authors' knowledge, this work is the first to quantize the weights, activations, as well as a substantial volume of the gradients stream, in all layers (including batch normalization) to 8-bit while showing state-of-the-art results over the ImageNet-1K dataset. 
460. **GradiVeQ: Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training** --*Mingchao Yu &middot; Zhifeng Lin &middot; Krishna Narra &middot; Songze Li &middot; Youjie Li &middot; Nam Sung Kim &middot; Alexander Schwing &middot; Murali Annavaram &middot; Salman Avestimehr*
 > Data parallelism can boost the training speed of convolutional neural networks (CNN), but could suffer from significant communication costs caused by gradient aggregation. To alleviate this problem, several scalar quantization techniques have been developed to compress the gradients. But these techniques could perform poorly when used together with decentralized aggregation protocols like ring all-reduce (RAR), mainly due to their inability to directly aggregate compressed gradients. In this paper, we empirically demonstrate the strong linear correlations between CNN gradients, and propose a gradient vector quantization technique, named GradiVeQ, to exploit these correlations through principal component analysis (PCA) for substantial gradient dimension reduction. GradiveQ enables direct aggregation of compressed gradients, hence allows us to build a distributed learning system that parallelizes GradiveQ gradient compression and RAR communications. Extensive experiments on popular CNNs demonstrate that applying GradiveQ slashes the wall-clock gradient aggregation time of the original RAR by more than 5x without noticeable accuracy loss, and reduce the end-to-end training time by almost 50%. The results also show that \GradiveQ is compatible with scalar quantization techniques such as QSGD (Quantized SGD), and achieves a much higher speed-up gain under the same compression ratio.
461. **Multi-armed Bandits with Compensation** --*Siwei Wang &middot; Longbo Huang*
 > We propose and study the known-compensation multi-arm bandit (KCMAB) problem, where a system controller offers a set of arms to many short-term players for $T$ steps. In each step, one short-term player arrives to the system. Upon arrival, the player greedily selects an arm with the current best average reward and receives a stochastic reward associated with the arm. In order to incentivize players to explore other arms,  the controller provides proper payment compensation to players. The objective of the controller is to maximize the total reward collected by players while minimizing the  compensation. We first give a compensation lower bound $\Theta(\sum_i {\Delta_i\log T\over KL_i})$, where $\Delta_i$ and $KL_i$ are the expected reward gap and Kullback-Leibler (KL) divergence between distributions of arm $i$ and the best arm, respectively. We then analyze three algorithms to solve the KCMAB problem, and obtain their regrets and compensations. We show that the algorithms all achieve $O(\log T)$ regret and $O(\log T)$ compensation that match the theoretical lower bound. Finally, we use experiments to show the behaviors of those algorithms.  
462. **Content preserving text generation with attribute controls** --*Lajanugen Logeswaran &middot; Honglak Lee &middot; Samy Bengio*
 > In this work, we address the problem of modifying textual attributes of sentences. Given an input sentence and a set of attribute labels, we attempt to generate sentences that are compatible with the conditioning information. To ensure that the model generates content compatible sentences, we introduce a reconstruction loss which interpolates between auto-encoding and back-translation loss components. We propose an adversarial loss to enforce generated samples to be attribute compatible and realistic. Through quantitative, qualitative and human evaluations we demonstrate that our model is capable of generating fluent sentences that better reflect the conditioning information compared to prior methods. We further demonstrate that the model is capable of simultaneously controlling multiple attributes.
464. **LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning** --*Tianyi Chen &middot; Georgios Giannakis &middot; Tao Sun &middot; Wotao Yin*
 > This paper presents a new class of gradient methods for distributed  machine learning that adaptively skip the gradient calculations to  learn with reduced communication and computation. Simple rules  are designed to detect slowly-varying gradients and, therefore,  trigger the reuse of outdated gradients. The resultant gradient-based  algorithms are termed Lazily Aggregated Gradient --- justifying our  acronym \textbf{LAG} used henceforth. Theoretically, the merits of  this contribution are: i) the convergence rate is the same as batch  gradient descent in strongly-convex, convex, and nonconvex cases;  and, ii) if the distributed datasets are heterogeneous (quantified by  certain measurable constants), the communication rounds needed  to achieve a targeted accuracy are reduced thanks to the adaptive  reuse of \emph{lagged} gradients. Numerical experiments on both  synthetic and real data corroborate a significant communication  reduction compared to alternatives.
465. **Practical exact algorithm for trembling-hand equilibrium refinements in games** --*Gabriele Farina &middot; Nicola Gatti &middot; Tuomas Sandholm*
 > Nash equilibrium strategies have the known weakness that they do not prescribe rational play in situations that are reached with zero probability according to the strategies themselves, for example, if players have made mistakes. Trembling-hand refinements---such as extensive-form perfect equilibria and quasi-perfect equilibria---remedy this problem in sound ways. Despite their appeal, they have not received attention in practice since no known algorithm for computing them scales beyond toy instances. In this paper, we design an exact polynomial-time algorithm for finding trembling-hand equilibria in zero-sum extensive-form games. It is several orders of magnitude faster than the best prior ones, numerically stable, and quickly solves game instances with tens of thousands of nodes in the game tree. It enables, for the first time, the use of trembling-hand refinements in practice.
466. **Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents** --*Vashisht Madhavan &middot; Felipe Petroski Such &middot; Jeff Clune &middot; Kenneth Stanley &middot; Joel Lehman*
 > Evolution strategies (ES) are a family of black-box optimization algorithms able to train deep neural networks roughly as well as Q-learning and policy gradient methods on challenging deep reinforcement learning (RL) problems, but are much faster (e.g. hours vs. days) because they parallelize better. However, many RL problems require directed exploration because they have reward functions that are sparse or deceptive (i.e. contain local optima), and it is unknown how to encourage such exploration with ES. Here we show that algorithms that have been invented to promote directed exploration in small-scale evolved neural networks via populations of exploring agents, specifically novelty search (NS) and quality diversity (QD) algorithms, can be hybridized with ES to improve its performance on sparse or deceptive deep RL tasks, while retaining scalability. Our experiments confirm that the resultant new algorithms, NS-ES and two QD algorithms, NSR-ES and NSRA-ES, avoid local optima encountered by ES to achieve higher performance on Atari and simulated robots learning to walk around a deceptive trap. This paper thus introduces a family of fast, scalable algorithms for reinforcement learning that are capable of directed exploration. It also adds this new family of exploration algorithms to the RL toolbox and raises the interesting possibility that analogous algorithms with multiple simultaneous paths of exploration might also combine well with existing RL algorithms outside ES.
467. **Adversarially Robust Generalization Requires More Data ** --*Ludwig Schmidt &middot; Shibani Santurkar &middot; Dimitris Tsipras &middot; Kunal Talwar &middot; Aleksander Madry*
 > Machine learning models are often susceptible to adversarial perturbations of their inputs. Even small perturbations can cause state-of-the-art classifiers with high "standard" accuracy to produce an incorrect prediction with high confidence. To better understand this phenomenon, we study adversarially robust learning from the viewpoint of generalization. We show that already in a simple natural data model, the sample complexity of robust learning can be significantly larger than that of "standard" learning. This gap is information theoretic and holds irrespective of the training algorithm or the model family. We complement our theoretical results with experiments on popular image classification datasets and show that a similar gap exists here as well. We postulate that the difficulty of training robust classifiers stems, at least partially, from this inherently larger sample complexity.
468. **Nonparametric Bayesian Lomax delegate racing for survival analysis with competing risks** --*Quan Zhang &middot; Mingyuan Zhou*
 > We propose Lomax delegate racing (LDR) to explicitly model the mechanism of survival under competing risks and to interpret how the covariates accelerate or decelerate the time to event. LDR explains non-monotonic covariate effects by racing a potentially infinite number of sub-risks, and consequently relaxes the ubiquitous proportional-hazards assumption which may be too restrictive. Moreover, LDR is naturally able to model censoring and missing event times or types. For inference, we develop a Gibbs sampler under data augmentation for moderately sized data, along with a stochastic gradient descent maximum a posteriori inference algorithm for big data applications. Illustrative experiments are provided on both synthetic and real datasets, and comparison with various benchmark algorithms for survival analysis with competing risks demonstrates distinguished performance of LDR. 
469. **Supervising Unsupervised Learning** --*Vikas Garg &middot; Adam T. Kalai*
 > We introduce a framework to leverage knowledge acquired from a repository of (heterogeneous) supervised datasets to new unsupervised datasets. Our perspective avoids the subjectivity inherent in unsupervised learning by reducing it to supervised learning, and  provides a principled way to evaluate unsupervised algorithms. We demonstrate the versatility of our framework via rigorous agnostic bounds on a variety of unsupervised problems. In the context of clustering, our approach helps choose the number of clusters and the clustering algorithm,  remove the outliers, and provably circumvent the Kleinberg's  impossibility result.  Experimental results across hundreds of problems demonstrate significant improvements in performance on unsupervised data with simple algorithms, despite the fact that our problems come from heterogeneous domains. Additionally, our framework lets us leverage deep networks to learn common features from many such small datasets, and perform zero shot learning with massive performance gains. 
470. **Learning from Group Comparisons: Exploiting Higher Order Interactions** --*Yao Li &middot; Minhao Cheng &middot; Kevin Fujii &middot; Fushing Hsieh &middot; Cho-Jui Hsieh*
 > We study the problem of learning from group comparisons, with applications in predicting outcomes of sports and online games. Most of the previous works in this area focus on learning individual effects---they assume each player has an underlying score, and the ''ability'' of the team is modeled by the sum of team members' scores. Therefore, all the current approaches cannot model deeper interaction between team members: some players perform much better if they play together, and some players perform poorly together. In this paper, we propose a new model that takes the player-interaction effects into consideration. However, under certain circumstances, the total number of individuals can be very large, and number of player interactions grows quadratically, which makes learning intractable. In this case, we propose a latent factor model, and show that the sample complexity of our model is bounded under mild assumptions. Finally, we show that our proposed models have much better prediction power on several E-sports datasets, and furthermore can be used to reveal interesting patterns that cannot be discovered by previous methods.
471. **Objective and efficient inference for couplings in neuronal networks** --*Yu Terada &middot; Tomoyuki Obuchi &middot; Takuya Isomura &middot; Yoshiyuki Kabashima*
 > Inferring directional couplings from the spike data of networks is desired in various scientific fields such as neuroscience. Here, we apply a recently proposed objective procedure to the spike data obtained from the Hodgkin--Huxley type models and Â¥textit{in vitro} neuronal networks cultured in a circular structure. As a result, we succeed in reconstructing synaptic connections accurately from the evoked activity as well as the spontaneous one. To obtain the results, we invent an analytic formula approximately implementing a method of screening relevant couplings. This significantly reduces the computational cost of the screening method employed in the proposed objective procedure, making it possible to treat large-size systems as in this study.
472. **Neural Edit Operations for Biological Sequences** --*Satoshi Koide &middot; Keisuke Kawano &middot; Takuro Kutsuna*
 > The evolution of biological sequences, such as proteins or DNAs, is driven by the three basic edit operations:  substitution, insertion, and deletion. Motivated by the recent progress of neural network models for biological tasks, we implement two neural network architectures that can treat such edit operations. The first proposal is the "edit invariant neural networks" based on differentiable Needleman-Wunsch algorithms. The second is the use of deep CNNs with concatenations. Our analysis shows that CNNs can recognize "star-free regular expressions", and that deeper CNNs can recognize more complex regular expressions including insertion/deletion of characters. The experimental results for the protein secondary structure prediction task suggest the importance of the insertion/deletion. The test accuracy on the widely-used CB513 dataset is 71.5%, which is 1.2-points better than of the current state-of-the-art result.
473. **Hessian-based Analysis of Large Batch Training and Robustness to Adversaries** --*  &middot; Amir Gholami &middot; Kurt Keutzer &middot; Michael W Mahoney &middot; Qi Lei*
 > Large batch size training of Neural Networks has been shown to incur accuracy loss when trained with the current methods.  The exact underlying reasons for this are still not completely understood.  Here, we study large batch size training through the lens of the Hessian operator and robust optimization. In particular, we perform a Hessian based study to analyze exactly how the landscape of the loss function changes when training with large batch size. We compute the true Hessian spectrum, without approximation, by back-propagating the second derivative. Extensive experiments on multiple networks show that saddle-points are not the cause for generalization gap of large batch size training, and the results consistently show that large batch converges to points with noticeably higher Hessian spectrum. Furthermore, we show that robust training allows one to favor flat areas, as points with large Hessian spectrum show poor robustness to adversarial perturbation. We further study this relationship, and provide empirical and theoretical proof that the inner loop for robust training is a saddle-free optimization problem \textit{almost everywhere}. We present detailed experiments with five different network architectures, including a residual network, tested on MNIST, CIFAR-10, and CIFAR-100 datasets.
474. **Efficient Neural Network Robustness Certification with General Activation Functions** --*Huan Zhang &middot; Tsui-Wei Weng &middot; Pin-Yu Chen &middot; Cho-Jui Hsieh &middot; Luca Daniel*
 > Finding minimum distortion of adversarial examples and thus certifying robustness in neural networks classifiers is known to be a challenging problem. Nevertheless, recently it has been shown to be possible to give a non-trivial certified lower bound of minimum distortion, and some recent progress has been made towards this direction by exploiting the piece-wise linear nature of ReLU activations. However, a generic robustness certification for \textit{general} activation functions still remains largely unexplored. To address this issue, in this paper we introduce CROWN, a general framework to certify robustness of neural networks with general activation functions. The novelty in our algorithm consists of bounding a given activation function with linear and quadratic functions, hence allowing it to tackle general activation functions including but not limited to the four popular choices: ReLU, tanh, sigmoid and arctan. In addition, we facilitate the search for a tighter certified lower bound by \textit{adaptively} selecting appropriate surrogates for each neuron activation. Experimental results show that CROWN on ReLU networks can notably improve the certified lower bounds compared to the current state-of-the-art algorithm Fast-Lin, while having comparable computational efficiency. Furthermore, CROWN also demonstrates its effectiveness and flexibility on networks with general activation functions, including tanh, sigmoid and arctan. To the best of our knowledge, CROWN is the first framework that can efficiently certify non-trivial robustness for general activation functions in neural networks.
475. **Learning Confidence Sets using Support Vector Machines** --*Wenbo Wang &middot; Xingye Qiao*
 > The goal of confidence-set learning in the binary classification setting is to construct two sets, each with a specific probability guarantee to cover a class. An observation outside the overlap of the two sets is deemed to be from one of the two classes, while the overlap is an ambiguity region which could belong to either class. Instead of plug-in approaches, we propose a support vector classifier to construct confidence sets in a flexible manner. Theoretically, we show that the proposed learner can control the non-coverage rates and minimize the ambiguity with high probability. Efficient algorithms are developed and numerical studies illustrate the effectiveness of the proposed method.
476. **Bandit Learning with Positive Externalities** --*Virag Shah &middot; Jose Blanchet &middot; Ramesh  Johari*
 > In many platforms, user arrivals exhibit a self-reinforcing behavior: future user arrivals are likely to have preferences similar to users who were satisfied in the past. In other words, arrivals exhibit {\em positive externalities}. We study multiarmed bandit (MAB) problems with positive externalities. We show that the self-reinforcing preferences may lead standard benchmark algorithms such as UCB to exhibit linear regret. We develop a new algorithm, Balanced Exploration (BE), which explores arms carefully to avoid suboptimal convergence of arrivals before sufficient evidence is gathered. We also introduce an adaptive variant of BE which successively eliminates suboptimal arms. We analyze their asymptotic regret, and establish optimality by showing that no algorithm can perform better.
477. **Densely Connected Attention Propagation for Reading Comprehension** --*Yi Tay &middot; Anh Tuan Luu &middot; Siu Cheung Hui*
 > We propose DecaProp (Densely Connected Attention Propagation), a new densely connected neural architecture for reading comprehension (RC). There are two distinct characteristics of our model. Firstly, our model densely connects all pairwise layers of the network, modeling relationships between passage and query across all hierarchical levels. Secondly, the dense connectors in our network are learned via attention instead of standard residual skip-connectors. To this end, we propose novel Bidirectional Attention Connectors (BAC) for efficiently forging connections throughout the network. We conduct extensive experiments on four challenging RC benchmarks. Our proposed approach achieves state-of-the-art results on all four, outperforming existing baselines by up to 2.6%14.2% in absolute F1 score.
478. **On the Local Minima of the Empirical Risk** --*Chi Jin &middot; Lydia T. Liu &middot; Rong Ge &middot; Michael Jordan*
 > Population risk is always of primary interest in machine learning; however, learning algorithms only have access to the empirical risk. Even for applications with nonconvex non-smooth losses (such as modern deep networks), the population risk is generally significantly more well behaved from an optimization point of view than the empirical risk.  In particular, sampling can create many spurious local minima. We consider a general framework which aims to optimize a smooth nonconvex function $F$ (population risk) given only access to an approximation $f$ (empirical risk) that is pointwise close to $F$ (i.e., $\norm{F-f}_{\infty} \le \nu$). Our objective is to find the $\epsilon$-approximate local minima of the underlying function $F$ while avoiding the shallow local minima---arising because of the tolerance $\nu$---which exist only in $f$. We propose a simple algorithm based on stochastic gradient descent (SGD) on a smoothed version of $f$ that is guaranteed  to achieve our goal as long as $\nu \le O(\epsilon^{1.5}/d)$. We also provide an almost matching lower bound showing that our algorithm achieves optimal error tolerance $\nu$ among all algorithms making a polynomial number of queries of $f$. As a concrete example, we show that our results can be directly used to give sample complexities for learning a ReLU unit.
479. **Measures of distortion for machine learning** --*Leena Chennuru Vankadara &middot; Ulrike von Luxburg*
 > Given data from a general metric space, one of the standard machine learning pipelines is to first embed the data into a Euclidean space and subsequently apply out of the box machine learning algorithms to analyze the data. The quality of such an embedding is typically described in terms of a distortion measure. In this paper, we show that many of the existing distortion measures behave in an undesired way, when considered from a machine learning point of view. We investigate desirable properties of distortion measures and formally prove that most of the existing measures fail to satisfy these properties. These theoretical findings are supported by simulations, which for example demonstrate that existing distortion measures are not robust to noise or outliers and cannot serve as good indicators for classification accuracy. As an alternative, we suggest a new measure of distortion, called $\sigma$-distortion. We can show both in theory and in experiments that it satisfies all desirable properties and is a better candidate to evaluate distortion in the context of machine learning. 
480. **Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections** --*Xin Zhang &middot; Armando Solar-Lezama &middot; Rishabh Singh*
 > We present a new algorithm to generate minimal, stable, and symbolic corrections to an input that will cause a neural network with ReLU activations to change its output. We argue that such a correction is a useful way to provide feedback to a user when the network's output is different from a desired output. Our algorithm generates such a correction by solving a series of linear constraint satisfaction problems. The technique is evaluated on three neural network models: one predicting whether an applicant will pay a mortgage, one predicting whether a first-order theorem can be proved efficiently by a solver using certain heuristics, and the final one judging whether a drawing is an accurate rendition of a canonical drawing of a cat.
481. **Is Q-Learning Provably Efficient?** --*Chi Jin &middot; Zeyuan Allen-Zhu &middot; Sebastien Bubeck &middot; Michael Jordan*
 > Model-free reinforcement learning (RL) algorithms directly parameterize and update value functions or policies, bypassing the modeling of the environment. They are typically simpler, more flexible to use, and thus more prevalent in modern deep RL than model-based approaches. However, empirical work has suggested that they require large numbers of samples to learn.  The theoretical question of whether not model-free algorithms are in fact \emph{sample efficient} is one of the most fundamental questions in RL. The problem is unsolved even in the basic scenario with finitely many states and actions. We prove that, in an episodic MDP setting, Q-learning with UCB exploration achieves regret $\tlO(\sqrt{H^3 SAT})$ where $S$ and $A$ are the numbers of states and actions, $H$ is the number of steps per episode, and $T$ is the total number of steps. Our regret matches the optimal regret up to a single $\sqrt{H}$ factor.  Thus we establish the sample efficiency of a classical model-free approach. Moreover, to the best of our knowledge, this is the first model-free analysis to establish $\sqrt{T}$ regret \emph{without} requiring access to a ``simulator.''
482. **Adaptive Negative Curvature Descent with Applications in Non-convex Optimization** --*Mingrui Liu &middot; Zhe Li &middot; Xiaoyu Wang &middot; Jinfeng Yi &middot; Tianbao Yang*
 > Negative curvature descent (NCD) method has been utilized to design deterministic or stochastic algorithms for non-convex optimization aiming at finding second-order stationary points or local minima. In existing studies, NCD needs to approximate the smallest eigen-value of the Hessian matrix with a sufficient precision (e.g., $\epsilon_2\ll 1$) in order to achieve a sufficiently accurate second-order stationary solution (i.e., $\lambda_{\min}(\nabla^2 f(\x))\geq -\epsilon_2)$.  One issue  with this approach is that the target precision $\epsilon_2$ is usually set to be very small in order to find a high quality solution, which increases the complexity for computing a negative curvature. To address this issue, we propose an adaptive NCD to allow for an adaptive error dependent on the current gradient's magnitude in approximating the smallest eigen-value of the Hessian, and to encourage competition between  a noisy NCD step and gradient descent step. We consider the applications of the proposed adaptive NCD for both deterministic and stochastic non-convex optimization, and demonstrate that it can help reduce the the overall complexity in computing the negative curvatures during the course of optimization without sacrificing the iteration complexity. 
483. **Fairness Through Computationally-Bounded Awareness** --*Michael P Kim &middot; Omer Reingold &middot; Guy Rothblum*
 > We study the problem of fair classification within the versatile framework of Dwork et al. [ITCS '12], which assumes the existence of a metric that measures similarity between pairs of individuals.  Unlike earlier work, we do not assume that the entire metric is known to the learning algorithm; instead, the learner can query this <em>arbitrary</em> metric a bounded number of times.  We propose a new notion of fairness called <em>metric multifairness</em> and show how to achieve this notion in our setting. Metric multifairness is parameterized by a similarity metric d on pairs of individuals to classify and a rich collection C of (possibly overlapping) "comparison sets" over pairs of individuals.  At a high level, metric multifairness guarantees that <em>similar subpopulations are treated similarly</em>, as long as these subpopulations are identified within the class C.
484. **Porcupine Neural Networks: Approximating Neural Network Landscapes** --*Soheil Feizi &middot; Hamid Javadi &middot; Jesse Zhang &middot; David Tse*
 > Neural networks have been used prominently in several machine learning and statistics applications. In general, the underlying optimization of neural networks is non-convex which makes analyzing their performance challenging. In this paper, we take another approach to this problem by constraining the network such that the corresponding optimization landscape has good theoretical properties without significantly compromising performance. In particular, for two-layer neural networks we introduce Porcupine Neural Networks (PNNs) whose weight vectors are constrained to lie over a finite set of lines. We show that most local optima of PNN optimizations are global while we have a characterization of regions where bad local optimizers may exist. Moreover, our theoretical and empirical results suggest that an unconstrained neural network can be approximated using a polynomially-large PNN.
485. **Information-based Adaptive Stimulus Selection to Optimize Communication Efficiency in Brain-Computer Interfaces** --*Boyla Mainsah &middot; Dmitry  Kalika &middot; Leslie Collins &middot;   &middot; Chandra  Throckmorton*
 > In stimulus-driven brain-computer interfaces (BCIs), the main hurdle that  limits the development of adaptive stimulus selection algorithms is the availability of objective functions that lead to tractable solutions to allow for algorithm implementation within the stringent time requirements of real-time BCI processing. In this work, we present a simple analytical solution of an information-based objective function by transforming the high-dimensional stimulus space into a one-dimensional space that parameterizes the objective function - the prior probability mass of the stimulus under consideration, irrespective of its contents. We demonstrate the utility of our adaptive stimulus selection algorithm in improving BCI performance with results from simulation and online human experiments.  
486. **Non-Ergodic Alternating Proximal  Augmented Lagrangian Algorithms with Optimal Rates** --*Quoc Tran Dinh*
 > We develop novel non-ergodic alternating proximal augmented Lagrangian algorithms (NAPALA) to solve nonsmooth constrained convex optimization problems. Our approach relies on a novel combination of the augmented Lagrangian framework, partial alternating/linearization scheme, Nesterov's acceleration techniques, and homotopy strategies. Our algorithms have several new features compared to existing primal-dual methods. First, they have a Nesterov's acceleration step on the primal variables compared to the dual one in several existing methods. Second, they have an optimal $O(1/k)$-rate  in non-ergodic sense without any smoothness or strong convexity-type assumption, where $k$ is the iteration counter. Third, all the parameters are updated explicitly without heuristic tuning. Finally, they have $O(1/k^2)$-ergodic or non-ergodic rate if one objective term is strongly convex while the problem remains nonstrongly convex. We verify our theoretical development via different numerical examples and compare our methods with some existing state-of-the-art algorithms.
487. **Hierarchical Graph Representation Learning with Differentiable Pooling** --*Zhitao Ying &middot; Jiaxuan You &middot; Christopher Morris &middot; Xiang Ren &middot; Will Hamilton &middot; Jure Leskovec*
 > Recently, graph neural networks (GNNs) have revolutionized the field of graph representation learning through effectively learned node embeddings, and achieved state-of-the-art results in tasks such as node classification and link prediction. However, current GNN methods are inherently flat and do not learn hierarchical representations of graphs---a limitation that is especially problematic for the task of graph classification, where the goal is to predict the label associated with an entire graph. Here we propose DiffPool, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion. DiffPool learns a differentiable soft cluster assignment for nodes at each layer of a deep GNN, mapping nodes to a set of clusters, which then form the coarsened input for the next GNN layer. Our experimental results show that combining existing GNN methods with DiffPool yields an average improvement of 5-10% accuracy on graph classification benchmarks, compared to all existing pooling approaches, achieving a new state-of-the-art on four out of five benchmark datasets. 
488. **A Unified View of Piecewise Linear Neural Network Verification** --*Rudy Bunel &middot; Ilker Turkaslan &middot; Philip Torr &middot; Pushmeet Kohli &middot; Pawan K Mudigonda*
 > The success of Deep Learning and its potential use in many safety-critical   applications has motivated research on formal verification of Neural Network   (NN) models. Despite the reputation of learned NN models to behave as black   boxes and the theoretical hardness of proving their properties, researchers   have been successful in verifying some classes of models by exploiting their   piecewise linear structure and taking insights from formal methods such as   Satisifiability Modulo Theory. These methods are however still far from   scaling to realistic neural networks. To facilitate progress on this crucial   area, we make two key contributions. First, we present a unified framework   that encompasses previous methods. This analysis results in the identification   of new methods that combine the strengths of multiple existing approaches,   accomplishing a speedup of two orders of magnitude compared to the previous   state of the art. Second, we propose a new data set of benchmarks which   includes a collection of previously released testcases. We use the benchmark   to provide the first experimental comparison of existing algorithms and   identify the factors impacting the hardness of verification problems.
489. **Context-dependent upper-confidence bounds for directed exploration** --*Raksha Kumaraswamy &middot; Matthew Schlegel &middot; Adam White &middot; Martha White*
 >   Directed exploration strategies for reinforcement learning are critical for learning an optimal policy in a minimal number of interactions with the environment. Many algorithms use optimism to direct exploration, either through visitation estimates or upper confidence bounds, as opposed to data-inefficient strategies like $\epsilon$-greedy that use random, undirected exploration. Most such data-efficient exploration methods, however, require significant computation, typically relying on a learned model to guide exploration. Least-squares methods have the potential to provide some of the data-efficiency benefits of model-based approaches---because they summarize past interactions---with the computation closer to that of model-free approaches.  In this work, we provide a novel computationally efficient, incremental exploration strategy, leveraging this property of least-squares temporal difference learning (LSTD). We derive upper confidence bounds on the action-values learned by LSTD, with context-dependent (or state-dependent) noise variance. Such context-dependent noise focuses exploration on a subset of variable states, and allows for reduced exploration in other states. We empirically demonstrate that our algorithm can converge more quickly than other incremental exploration strategies using confidence estimates on action-values.
490. **A Smoother Way to Train Structured Prediction** --*Venkata Krishna Pillutla &middot; Zaid Harchaoui &middot; Sham Kakade*
 > We present a framework allowing one to perform smoothing on the inference  used by structured prediction methods. Smoothing breaks the non-smoothness inherent to structured prediction objectives, without the need to resort to convex duality,  and paves the way to the use of fast primal gradient-based optimization algorithms. 
491. **Data-Efficient Model-based Reinforcement Learning with Deep Probabilistic Dynamics Models** --*Kurtland Chua &middot; Roberto Calandra &middot; Rowan McAllister &middot; Sergey Levine*
 > Model-based reinforcement learning (RL) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance, especially those with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models, proposing a new algorithm called probabilistic ensembles with trajectory sampling (PETS). We justify PETS with an empirical analysis of design decisions for both uncertainty-aware dynamics models and uncertainty propagation methods for planning. Our experimental comparison to state-of-the-art model-based and model-free deep RL algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples.
492. **Fast greedy algorithms for dictionary selection with generalized sparsity constraints** --*Kaito Fujii &middot; Tasuku Soma*
 > In dictionary selection, several atoms are selected from finite candidates that successfully approximate given data points in the sparse representation. We propose a novel efficient greedy algorithm for dictionary selection. Not only does our algorithm work much faster than the known methods, but it can also handle more complex sparsity constraints, such as average sparsity. Using numerical experiments, we show that our algorithm outperforms the known methods for dictionary selection, achieving competitive performances with dictionary learning algorithms in a smaller running time.
493. **Recurrently Controlled Recurrent Networks** --*Yi Tay &middot; Anh Tuan Luu &middot; Siu Cheung Hui*
 > Recurrent neural networks (RNNs) such as long short-term memory and gated recurrent units are pivotal building blocks across a broad spectrum of sequence modeling problems. This paper proposes a recurrently controlled recurrent network (RCRN) for expressive and powerful sequence encoding. More concretely, the key idea behind our approach is to learn the recurrent gating functions using recurrent networks. Our architecture is split into two components - a controller cell and a listener cell whereby the recurrent controller actively influences the compositionality of the listener cell. We conduct extensive experiments on a myriad of tasks in the NLP domain such as sentiment analysis (SST, IMDb, Amazon reviews, etc.), question classification (TREC), entailment classification (SNLI, SciTail), answer selection (WikiQA, TrecQA) and reading comprehension (NarrativeQA). Across all 26 datasets, our results demonstrate that RCRN not only consistently outperforms BiLSTMs but also stacked BiLSTMs, suggesting that our controller architecture might be a suitable replacement for the widely adopted stacked architecture. Additionally, RCRN achieves state-of-the-art results on several well-established datasets.
494. **Non-metric Similarity Graphs for Maximum Inner Product Search** --*Stanislav Morozov &middot; Artem Babenko*
 > In this paper we address the problem of Maximum Inner Product Search (MIPS) that is currently the computational bottleneck in a large number of machine learning applications.  While being similar to the nearest neighbor search (NNS), the MIPS problem was shown to be more challenging, as the inner product is not a proper metric function. We propose to solve the MIPS problem with the usage of similarity graphs, i.e., graphs where each vertex is connected to the vertices that are the most similar in terms of some similarity function. Originally, the framework of similarity graphs was proposed for metric spaces and in this paper we naturally extend it to the non-metric MIPS scenario. We demonstrate that, unlike existing approaches, similarity graphs do not require any data transformation to reduce MIPS to the NNS problem and should be used for the original data. Moreover, we explain why such a reduction is detrimental for similarity graphs. By an extensive comparison to the existing approaches, we show that the proposed method is a game-changer in terms of the runtime/accuracy trade-off for the MIPS problem.
495. **Negotiable Reinforcement Learning for Pareto Optimal Sequential Decision-Making** --*Nishant Desai &middot; Andrew Critch &middot; Stuart J Russell*
 > It is commonly believed that an agent making decisions on behalf of two or more principals who have different utility functions should adopt a Pareto optimal policy, i.e., a policy that cannot be improved upon for one principal without making sacrifices for another. Harsanyi's theorem shows that when the principals have a common prior on the outcome distributions of all policies a Pareto optimal policy for the agent is one that maximizes a fixed, weighted linear combination of the principalsâ utilities. In this paper, we derive a more precise generalization for the sequential decision setting in the case of principals with different priors on the dynamics of the environment. We refer to this generalization as the Negotiable Reinforcement Learning (NRL) framework. In this more general case, the relative weight given to each principalâs utility should evolve over time according to how well the agentâs observations conform with that principalâs prior. To gain insight into the dynamics of this new framework, we implement a simple NRL agent and empirically examine its behavior in a simple environment.
496. **A Mathematical Model For Optimal Decisions In A Representative Democracy ** --*Malik Magdon-Ismail &middot; Lirong Xia*
 > Direct democracy is a special   case of an ensemble of classifiers,   where every person (classifier) votes. This fails when the   average voter competence (classifier accuracy) falls below 50\%, which    happens in   noisy settings where voters have limited information.   Representative democracy, where voters choose representatives to vote,   is a specific way to improve the ensemble of classifiers.   We introduce a mathematical model for   studying representative democracy, in particular understanding the parameters   of a representative democracy that gives maximum decision   making capability. Our main result states that under general and natural   conditions,   \begin{enumerate}\itemsep-1pt     \vspace*{-4pt}   \item For fixed voting cost, the optimal number of representatives is     \emph{linear}.   \item For polynomial cost,     the optimal number of representatives is     \emph{logarithmic}.   \end{enumerate}   This work sets the mathematical   foundation for studying the quality-quantity tradeoff   in a representative democracy-type ensemble   (fewer highly qualified representatives   versus more less qualified representatives). 
497. **Learning Bounds for Greedy Approximation with Multiple Explicit Feature Maps** --*Shahin Shahrampour &middot; Vahid Tarokh*
 > Large-scale Mercer kernels can be approximated using low-dimensional feature maps for efficient risk minimization. Due to the inherent trade-off between the feature map sparsity and the approximation accuracy, the key problem is to identify promising feature map components (bases) leading to satisfactory out-of-sample performance. In this work, we tackle this problem by efficiently choosing such bases from multiple kernels in a greedy fashion. Our method sequentially selects these bases from a set of candidate bases using a correlation metric. We prove that the out-of-sample performance depends on three types of errors, one of which (spectral error) relates to spectral properties of the best model in the Hilbert space associated to the combined kernel. The result verifies that when the underlying data model is sparse enough, i.e., the spectral error is negligible, one can control the test error with a small number of bases, scaling poly-logarithmically with data. Our empirical results show that given a fixed number of bases, the method can achieve a lower test error with a smaller time cost, compared to the state-of-the-art in data-dependent random features. 
498. **Fast Rates of ERM and Stochastic Approximation: Adaptive to Error Bound Conditions** --*Mingrui Liu &middot; Xiaoxuan Zhang &middot; Lijun Zhang &middot; Jing Rong &middot; Tianbao Yang*
 > Error bound conditions (EBC) are properties that characterize the growth of an objective function when a point is moved away from the optimal set. They have  recently received increasing attention in the field  of optimization for developing optimization algorithms with fast convergence.  However,  the studies of EBC in statistical learning are hitherto still limited.  The main contributions of this paper are two-fold. First,  we develop fast and intermediate rates of  empirical risk minimization (ERM) under EBC for risk minimization with Lipschitz continuous, and  smooth  convex random functions. Second, we establish fast and intermediate rates of an efficient stochastic approximation (SA) algorithm for risk minimization  with Lipschitz continuous random functions, which requires only one pass of $n$ samples and adapts to EBC. For both approaches, the convergence rates span a full spectrum between $\widetilde O(1/\sqrt{n})$ and $\widetilde O(1/n)$ depending on the power constant in EBC, and could be even faster than $O(1/n)$ in special cases for ERM. Moreover, these  convergence rates are automatically adaptive without using any knowledge of EBC. Overall, this work not only strengthens the understanding of ERM for statistical learning but also brings new fast stochastic algorithms for solving a broad range of statistical learning problems. 
499. **Adversarial Text Generation via Feature-Mover's Distance** --*Liqun Chen &middot; Shuyang Dai &middot; Chenyang Tao &middot; Haichao Zhang &middot; Zhe Gan &middot; Dinghan Shen &middot; Yizhe Zhang &middot; Lawrence Carin*
 > Generative adversarial networks (GANs) have achieved significant success in generating real-valued data. However, the discrete nature of text hinders the application of GAN to text-generation tasks. Instead of using the standard GAN objective, we propose to improve text-generation GAN via a novel approach inspired by optimal transport. Specifically, we consider matching the latent feature distributions of real and synthetic sentences using a novel metric, termed the feature-mover's distance (FMD). This formulation leads to a highly discriminative critic and easy-to-optimize objective, overcoming the mode-collapsing and brittle-training problems in existing methods. Extensive experiments are conducted on a variety of tasks to evaluate the proposed model empirically, including unconditional text generation, style transfer from non-parallel text, and unsupervised cipher cracking. The proposed model yields superior performance, demonstrating wide applicability and effectiveness.
500. **Boolean Decision Rules via Column Generation** --*Sanjeeb Dash &middot; Oktay Gunluk &middot; Dennis Wei*
 > This paper considers the learning of Boolean rules in either disjunctive normal form (DNF, OR-of-ANDs, equivalent to decision rule sets) or conjunctive normal form (CNF, AND-of-ORs) as an interpretable model for classification.  An integer program is formulated to optimally trade classification accuracy for rule simplicity.  Column generation (CG) is used to efficiently search over an exponential number of candidate clauses (conjunctions or disjunctions) without the need for heuristic rule mining.  This approach also bounds the gap between the selected rule set and the best possible rule set on the training data. To handle large datasets, we propose an approximate CG algorithm using randomization.  Compared to three recently proposed alternatives, the CG algorithm dominates the accuracy-simplicity trade-off in 8 out of 16 datasets. When maximized for accuracy, CG is competitive with rule learners designed for this purpose, sometimes finding significantly simpler solutions that are no less accurate.
501. **On Learning Intrinsic Rewards for Policy Gradient Methods** --*Zeyu Zheng &middot; Junhyuk Oh &middot; Satinder Singh*
 > In many sequential decision making tasks, it is challenging to design reward functions that help an RL agent efficiently learn behavior that is considered good by the agent designer. A number of different formulations of the reward-design problem, or close variants thereof, have been proposed in the literature. In this paper we build on the Optimal Rewards Framework of Singh et al. that defines the optimal intrinsic reward function as one that when used by an RL agent achieves behavior that optimizes the task-specifying or extrinsic reward function. Previous work in this framework has shown how good intrinsic reward functions can be learned for lookahead search based planning agents. Whether it is possible to learn intrinsic reward functions for learning agents remains an open problem. In this paper we derive a novel algorithm for learning intrinsic rewards for policy-gradient based learning agents. We compare the performance of an augmented agent that uses our algorithm to provide additive intrinsic rewards to an A2C-based policy learner (for Atari games) and a PPO-based policy learner (for Mujoco domains) with a baseline agent that uses the same policy learners but with only extrinsic rewards. Our results show improved performance on most but not all of the domains.
502. **Spectral Filtering for General Linear Dynamical Systems** --*Elad Hazan &middot; HOLDEN LEE &middot; Karan Singh &middot; Cyril Zhang &middot; Yi Zhang*
 > We give a polynomial-time algorithm for learning latent-state linear dynamical systems without system identification, and without assumptions on the spectral radius of the system's transition matrix. The algorithm extends the recently introduced technique of spectral filtering, previously applied only to systems with a symmetric transition matrix, using a novel convex relaxation to allow for the efficient identification of phases.
503. **PG-TS: Improved Thompson Sampling for Logistic Contextual Bandits** --*Bianca Dumitrascu &middot; Barbara Engelhardt &middot; Karen Feng*
 > We address the problem of regret minimization in logistic contextual bandits, where a learner decides among sequential actions or arms given their respective contexts to maximize binary rewards. Using a fast inference procedure with P\'olya-Gamma distributed augmentation variables, we propose an improved version of Thompson Sampling, a Bayesian formulation of contextual bandits with near-optimal performance. Our approach, P\'olya-Gamma augmented Thompson Sampling (PG-TS), achieves state-of-the-art performance on simulated and real data. PG-TS explores the action space efficiently and exploits high-reward arms, quickly converging to solutions of low regret. Its explicit estimation of the posterior distribution of the context feature covariance leads to substantial empirical gains over approximate approaches. PG-TS is the first approach to demonstrate the benefits of P\'olya-Gamma augmentation in bandits and to propose an efficient Gibbs sampler for approximating the analytically unsolvable integral of logistic contextual bandits.
504. **Optimal Byzantine-Resilient Stochastic Gradient Descent** --*Dan Alistarh &middot; Zeyuan Allen-Zhu &middot; Jerry Li*
 > (this is a theory paper)  This paper studies the problem of distributed stochastic optimization in an adversarial setting where, out of $m$ machines which allegedly compute stochastic gradients every iteration, an $\alpha$-fraction are Byzantine, and can behave arbitrarily and adversarially. Our main result is a variant of stochastic gradient descent (SGD) which finds $\varepsilon$-approximate minimizers of convex functions in $T = \tilde{O}\big( \frac{1}{\varepsilon^2 m} + \frac{\alpha^2}{\varepsilon^2} \big)$ iterations. In contrast, traditional mini-batch SGD needs $T = O\big( \frac{1}{\varepsilon^2 m} \big)$ iterations, but cannot tolerate Byzantine failures. Further, we provide a lower bound showing that, up to logarithmic factors, our algorithm is information-theoretically optimal both in terms of sample complexity and time complexity. 
505. **Learning filter widths of spectral decompositions with wavelets** --*Haidar Khan &middot; BÃ¼lent Yener*
 > Time series classification using deep neural networks, such as convolutional neural networks (CNN), operate on the spectral decomposition of the time series computed using a preprocessing step. This step can include a large number of hyperparameters, such as window length, filter widths, and filter shapes, each with a range of possible values that must be chosen using time and data intensive cross-validation procedures. We propose the wavelet deconvolution (WD) layer as an efficient alternative to this preprocessing step that eliminates a significant number of hyperparameters. The WD layer uses wavelet functions with adjustable scale parameters to learn the spectral decomposition directly from the signal. Using backpropagation, we show the scale parameters can be optimized with gradient descent. Furthermore, the WD layer adds interpretability to the learned time series classifier by exploiting the properties of the wavelet transform. In our experiments, we show that the WD layer can automatically extract the frequency content used to generate a dataset. The WD layer combined with a CNN applied to the phone recognition task on the TIMIT database achieves a phone error rate of 18.1\%, a relative improvement of 4\% over the baseline CNN. Experiments on a dataset where engineered features are not available showed WD+CNN is the best performing method. Our results show that the WD layer can improve neural network based time series classifiers both in accuracy and interpretability by learning directly from the input signal.
506. **Active Matting** --*Xin Yang &middot; Ke Xu &middot; Shaozhe Chen &middot; Shengfeng He &middot; Baocai Yin Yin &middot; Rynson Lau*
 > Image matting is an ill-posed problem. It requires a user input trimap or some  strokes to obtain an alpha matte of the foreground object. A fine user input is essential to obtain a good result, which is either time consuming or suitable for experienced users who know where to place the strokes. In this paper, we explore the intrinsic relationship between the user input and the matting algorithm to address the problem of where and when the user should provide the input. Our aim is to discover the most informative sequence of regions for user input in order to produce a good alpha matte with minimum labeling efforts. To this end, we propose an active matting method with recurrent reinforcement learning. The proposed framework involves human in the loop by sequentially detecting informative regions for trivial human judgement. Comparing to traditional matting algorithms, the proposed framework requires much less efforts, and can produce satisfactory results with just 10 regions. Through extensive experiments, we show that the proposed model reduces user efforts significantly and achieves comparable performance to dense trimaps in a user-friendly manner. We further show that the learned informative knowledge can be generalized across different matting algorithms.
507. **Towards Robust Detection of Adversarial Examples** --*Tianyu Pang &middot; Chao Du &middot; Yinpeng Dong &middot; Jun Zhu*
 > Although the recent progress is substantial, deep learning methods can be vulnerable to the maliciously generated adversarial examples. In this paper, we present a novel training procedure and a thresholding test strategy, towards robust detection of adversarial examples. In training, we propose to minimize the reverse cross-entropy (RCE), which encourages a deep network to learn latent representations that better distinguish adversarial examples from normal ones. In testing, we propose to use a thresholding strategy as the detector to filter out adversarial examples for reliable predictions. Our method is simple to implement using standard algorithms, with little extra training cost compared to the common cross-entropy minimization. We apply our method to defend various attacking methods on the widely used MNIST and CIFAR-10 datasets, and achieve significant improvements on robust predictions under all the threat models in the adversarial setting.
508. **How SGD selects the global minima in over-parameterized learning: A stability perspective** --*Lei Wu &middot; Chao Ma &middot; Weinan E &middot; Zhanxing Zhu*
 > The question of which global minima are accessible by an stochastic gradient decent (SGD)  algorithm with specific learning rate and batch size is studied from the perspective of numerical stability.  The concept of non-uniformity is introduced, which, together with sharpness, characterizes the stability property of a global minimum and hence the accessibility of a particular SGD algorithm to that global minimum. In particular, this analysis shows that  learning rate and batch size play different roles in minima selection.  Extensive empirical results seem to correlate well with the theoretical findings and provide further support to these  claims.
509. **The promises and pitfalls of Stochastic Gradient Langevin Dynamics** --*Alain Durmus &middot; Eric Moulines &middot; Nicolas Brosse*
 > Stochastic Gradient Langevin Dynamics (SGLD) has emerged as a key MCMC algorithm for Bayesian learning from large scale datasets. While SGLD with decreasing step sizes converges weakly to the posterior distribution, the algorithm is often used with a constant step size in practice and has demonstrated spectacular successes in machine learning tasks. The current practice is to set the step size inversely proportional to N where N is the number of training samples. As N becomes large, we show that the SGLD algorithm has an invariant probability measure which significantly departs from the target posterior and behaves like as Stochastic Gradient Descent (SGD). This difference is inherently due to the high variance of the stochastic gradients. Several strategies have been suggested to reduce this effect; among them, SGLD Fixed Point (SGLDFP) uses carefully designed control variates to reduce the variance of the stochastic gradients. We show that SGLDFP gives approximate samples from the posterior distribution, with an accuracy comparable to the Langevin Monte Carlo (LMC) algorithm for a computational cost sublinear in the number of data points. We provide a detailed analysis of the Wasserstein distances between LMC, SGLD, SGLDFP and SGD and explicit expressions of the means and covariance matrices of their invariant distributions. Our findings are supported by limited numerical experiments.
510. **Online Reciprocal Recommendation with Theoretical Performance Guarantees** --*Claudio Gentile &middot; Nikos Parotsidis &middot; Fabio Vitale*
 > A reciprocal recommendation problem is one where the goal of learning is not just to predict a user's preference towards a passive item (e.g., a book), but to recommend the targeted user on one side another user from the other side such that a mutual interest between the two exists. The problem thus is sharply different from the more traditional items-to-users recommendation, since a good match requires meeting the preferences of both users. We initiate a rigorous theoretical investigation of the reciprocal recommendation task in a specific framework of sequential learning. We point out general limitations, formulate reasonable assumptions enabling effective learning and, under these assumptions, we design and analyze a computationally efficient algorithm that uncovers mutual likes at a pace comparable to those achieved by a clearvoyant algorithm knowing all user preferences in advance. Finally, we validate our algorithm against synthetic and real-world datasets, showing improved empirical performance over simple baselines.
511. **Algorithms and Theory for Multiple-Source Adaptation** --*Judy Hoffman &middot; Mehryar Mohri &middot; Ningshan Zhang*
 > This work includes a number of novel contributions for the multiple-source adaptation problem. We present new normalized solutions with strong theoretical guarantees for the cross-entropy loss and other similar losses. We also provide new guarantees that hold in the case where the conditional probabilities for the source domains are distinct. Moreover, we give new algorithms for determining the distribution-weighted combination solution for the cross-entropy loss and other losses. We report the results of a series of experiments with real-world datasets. We find that our algorithm outperforms competing approaches by producing a single robust model that performs well on  any target mixture distribution. Altogether, our theory, algorithms, and empirical results provide a full solution for the multiple-source adaptation problem with very practical benefits.
512. **Efficient Online Portfolio with Logarithmic Regret** --*  &middot; Chen-Yu Wei &middot; Kai Zheng*
 > We study the decades-old problem of online portfolio management and propose the first algorithm with logarithmic regret that is not based on Cover's Universal Portfolio algorithm and admits much faster implementation. Specifically Universal Portfolio enjoys optimal regret $\mathcal{O}(N\ln T)$ for $N$ financial instruments over $T$ rounds, but requires log-concave sampling and has a large polynomial running time. Our algorithm, on the other hand, ensures a slightly larger but still logarithmic regret of $\mathcal{O}(N^2(\ln T)^4)$, and is based on the well-studied Online Mirror Descent framework with a novel regularizer that can be implemented via standard optimization methods in time $\mathcal{O}(TN^{2.5})$ per round. The regret of all other existing works is either polynomial in $T$ or has a potentially unbounded factor such as the inverse of the smallest price relative.
513. **Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion** --*Jacob Buckman*
 > There is growing interest in combining model-free and model-based approaches in reinforcement learning with the goal of achieving the high performance of model-free algorithms with low sample complexity. This is difficult because an imperfect dynamics model can degrade the performance of the learning algorithm, and in sufficiently complex environments, the dynamics model will always be imperfect. As a result, a key challenge is to combine model-based approaches with model-free learning in such a way that errors in the model do not degrade performance. We propose stochastic ensemble value expansion (STEVE), a novel model-based technique that addresses this issue. By dynamically interpolating between model rollouts of various horizon lengths, STEVE ensures that the model is only utilized when doing so does not introduce significant errors. Our approach outperforms model-free baselines on challenging continuous control benchmarks with an order-of-magnitude increase in sample efficiency.
514. **Variational Bayesian Monte Carlo** --*Luigi Acerbi*
 > Many probabilistic models of interest in scientific computing and machine learning have expensive, black-box likelihoods that prevent the application of standard techniques for Bayesian inference, such as MCMC, which would require access to the gradient or a large number of likelihood evaluations. We introduce here a novel sample-efficient inference framework, Variational Bayesian Monte Carlo (VBMC). VBMC combines variational inference with Gaussian-process based, active-sampling Bayesian quadrature, using the latter to efficiently approximate the intractable integral in the variational objective. Our method produces both a nonparametric approximation of the posterior distribution and an approximate lower bound of the model evidence, useful for model selection. We demonstrate VBMC both on several synthetic likelihoods and on a neuronal model with data from real neurons. Across all tested problems and dimensions (up to D = 10), VBMC performs consistently well in reconstructing the posterior and the model evidence with a limited budget of likelihood evaluations, unlike other methods that work only in very low dimensions. Our framework shows great promise as a novel tool for posterior and model inference with expensive, black-box likelihoods.
515. **Statistical mechanics of low-rank tensor decomposition** --*Jonathan Kadmon &middot; Surya Ganguli*
 > Often, large, high dimensional datasets collected across multiple modalities can be organized as a higher order tensor. Low-rank tensor decomposition then arises as a powerful and widely used tool to discover simple low dimensional structures underlying such data. However, we currently lack a theoretical understanding of the algorithmic behavior of low-rank tensor decomposition. We derive Bayesian approximate message passing (AMP) algorithms for recovering arbitrarily shaped low-rank tensors buried within noise, and we employ dynamic mean field theory to precisely characterize their performance.   Our theory reveals the existence of phase transitions between easy, hard and impossible inference regimes, and displays an excellent match with simulations.  Moreover it reveals several qualitative surprises compared to the behavior of symmetric, cubic tensor decomposition. Finally, we compare our AMP algorithm to the most commonly used algorithm, the alternating least squares (ALS), and demonstrate that AMP significantly outperforms ALS in the presence of noise.
516. **Sequential Monte Carlo for probabilistic graphical models via twisted targets** --*Fredrik Lindsten &middot; Jouni Helske &middot; Matti Vihola*
 > Approximate inference in probabilistic graphical models (PGMs) can be grouped into deterministic methods and Monte-Carlo-based methods. The former can often provide accurate and rapid inferences, but are typically associated with biases that are hard to quantify. The latter enjoy asymptotic consistency, but can suffer from high computational costs. In this paper we present a way of bridging the gap between deterministic and stochastic inference. Specifically, we suggest an efficient sequential Monte Carlo (SMC) algorithm for PGMs which can leverage the output from deterministic inference methods. While generally applicable, we show explicitly how this can be done with loopy belief propagation, expectation propagation, and Laplace approximations. The resulting algorithm can be viewed as a post-correction of the biases associated with these methods and, indeed, numerical results show clear improvements over the baseline deterministic methods as well as over "plain" SMC.  
517. **Modelling and unsupervised learning of symmetric deformable object categories** --*James Thewlis &middot; Hakan Bilen &middot; Andrea Vedaldi*
 > We look at the problem of learning the structure of categories of symmetric visual objects from raw images, without manual supervision. We show that we can capture the intuitive notion of symmetry in natural objects, which often clashes with its classical mathematical definition, by looking at the symmetry not of geometric shapes, but of object deformations. We do so by building on the recently-introduced object frame representation and show how the latter can be extended to capture symmetries, mapping them to simple transformation groups in representation space. An advantage of the original object frame is that it is amenable to unsupervised learning. We show that our formulation leads to a direct generalization of this learning strategy that allows learning the symmetries of natural objects also in an unsupervised manner. Finally, we show that our formulation provides an explanation of the ambiguities in pose recovery that arise from certain symmetries and we provide a way of discounting such ambiguities in learning.
518. **Hamiltonian Variational Auto-Encoder** --*Anthony Caterini &middot; Dino Sejdinovic &middot; Arnaud Doucet*
 > Variational Auto-Encoders (VAE) have become very popular techniques to perform inference and learning in latent variable models as they allow us to leverage the rich representational power of neural networks to obtain flexible approximations of the posterior of latent variables as well as tight evidence lower bounds (ELBO). Com- bined with stochastic variational inference, this provides a methodology scaling to large datasets. However, for this methodology to be practically efficient, it is neces- sary to obtain low-variance unbiased estimators of the ELBO and its gradients with respect to the parameters of interest. While the use of Markov chain Monte Carlo (MCMC) techniques such as Hamiltonian Monte Carlo (HMC) has been previously suggested to achieve this [23, 26], the proposed methods require specifying reverse kernels which have a large impact on performance. Additionally, the resulting unbiased estimator of the ELBO for most MCMC kernels is typically not amenable to the reparameterization trick. We show here how to optimally select reverse kernels in this setting and, by building upon Hamiltonian Importance Sampling (HIS) [17], we obtain a scheme that provides low-variance unbiased estimators of the ELBO and its gradients using the reparameterization trick. This allows us to develop a Hamiltonian Variational Auto-Encoder (HVAE). This method can be re-interpreted as a target-informed normalizing flow [20] which, within our context, only requires a few evaluations of the gradient of the sampled likelihood and trivial Jacobian calculations at each iteration.
519. **Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data** --*Yuanzhi Li &middot; Yingyu Liang*
 > Neural networks have many successful applications, while much less theoretical understanding has been gained. Towards bridging this gap, we study the problem of learning a two-layer overparameterized ReLU neural network for multi-class classification via stochastic gradient descent (SGD) from random initialization. In the overparameterized setting, when the data comes from mixtures of well-separated  distributions, we prove that SGD learns a network with a small generalization error, albeit the network has enough capacity to fit arbitrary labels. Furthermore, the analysis provides interesting insights into several aspects of learning neural networks and can be verified based on empirical studies on synthetic data and on the MNIST dataset. 
520. **Bayesian Control of Large MDPs with Uncertain Dynamics in Data-Poor Environments** --*Mahdi Imani &middot; Seyede Fatemeh Ghoreishi &middot; Ulisses M. Braga-Neto*
 > We propose a Bayesian decision making framework for control of Markov Decision Processes (MDPs) with uncertain dynamics and large, possibly continuous, state, action, and parameter spaces in data-poor environments. Most of the existing adaptive controllers for MDPs with uncertain dynamics are based on the reinforcement learning framework and rely on large data sets acquired by sustained direct interaction with the system or via a simulator. This is not feasible in many applications, due to ethical, economic, and physical constraints. The proposed framework addresses the data poverty issue by decomposing the problem into an offline planning stage that does not rely on sustained direct interaction with the system or simulator and an online execution stage. In the offline process, parallel Gaussian process temporal difference (GPTD) learning techniques are employed for near-optimal Bayesian approximation of the expected discounted reward over a sample drawn from the prior distribution of uncertain parameters. In the online stage, the action with the maximum expected return with respect to the posterior distribution of the parameters is selected. This is achieved by an approximation of the posterior distribution using a Markov Chain Monte Carlo (MCMC) algorithm, followed by constructing multiple Gaussian processes over the parameter space for efficient prediction of the means of the expected return at the MCMC sample. The accuracy of the proposed framework is demonstrated using a small example as well as noisy synthetic gene expression data from a melanoma gene regulatory network model.
521. **Proximal Graphical Event Models** --*Dharmashankar Subramanian &middot; Debarun Bhattacharjya &middot; Tian Gao*
 > Event datasets include events that occur irregularly over the timeline and are prevalent in numerous domains. We introduce proximal graphical event models (PGEM) as a representation of such datasets. PGEMs belong to a broader family of models that characterize relationships between various types of events, where the rate of occurrence of an event type depends only on whether or not its parents have occurred in the most recent history. The main advantage over the state of the art models is that they are entirely data driven and do not require additional inputs from the user, which can require knowledge of the domain such as choice of basis functions or hyperparameters in graphical event models. We theoretically justify our learning of  optimal windows for parental history and the choices of parental sets, and the algorithm are sound and complete in terms of parent structure learning.  We present additional efficient heuristics for learning PGEMs from data, demonstrating their effectiveness on synthetic and real datasets.
522. **Does mitigating ML's impact disparity require treatment disparity?** --*Zachary  Lipton &middot; Julian McAuley &middot; Alexandra Chouldechova*
 > Following precedent in employment discrimination law, two notions of disparity are widely-discussed in papers on fairness and ML. Algorithms exhibit treatment disparity if they formally treat members of protected subgroups differently; algorithms exhibit impact disparity when outcomes differ across subgroups (even unintentionally). Naturally, we can achieve impact parity through purposeful treatment disparity. One line of papers aims to reconcile the two parities proposing disparate learning processes (DLPs). Here, the sensitive feature is used during training but a group-blind classifier is produced. In this paper, we show that: (i) when sensitive and (nominally) nonsensitive features are correlated, DLPs will indirectly implement treatment disparity, undermining the policy desiderata they are designed to address; (ii) when group membership is partly revealed by other features, DLPs induce within-class discrimination; and (iii) in general, DLPs provide suboptimal trade-offs between accuracy and impact parity. Experimental results on several real-world datasets highlight the practical consequences of applying DLPs. 
523. **Statistical Optimality of Stochastic Gradient Descent on Hard Learning Problems through Multiple Passes** --*Loucas Pillaud-Vivien &middot; Alessandro Rudi &middot; Francis Bach*
 > We consider stochastic gradient descent (SGD) for least-squares regression with potentially several passes over the data. While several passes have been widely reported to perform practically better in terms of predictive performance on unseen data, the existing theoretical analysis of SGD suggests that a single pass is statistically optimal. While this is true for low-dimensional easy problems, we show that for hard problems, multiple passes lead to statistically optimal predictions while single pass does not; we also show that in these hard models, the optimal number of passes over the data increases with sample size. In order to define the notion of hardness and show that our predictive performances are optimal, we consider potentially infinite-dimensional models and notions typically associated to kernel methods, namely, the decay of eigenvalues of the covariance matrix of the features and the complexity of the optimal predictor as measured through the covariance matrix. We illustrate our results on synthetic experiments with non-linear kernel methods and on a classical benchmark with a linear model.
524. **Credit Assignment For Collective Multiagent RL With Global Rewards** --*Duc Thien Nguyen &middot; Akshat Kumar &middot; Hoong Chuin Lau*
 > Scaling decision theoretic planning to large multiagent systems is challenging due to uncertainty and partial observability in the environment. We focus on a multiagent planning model subclass, relevant to urban settings, where agent interactions are dependent on their ``collective influence'' on each other, rather than their identities. Unlike previous work, we address a general setting where system reward is not decomposable among agents. We develop collective actor-critic RL approaches for this setting, and address the problem of multiagent credit assignment, and computing low variance policy gradient estimates that result in faster convergence to high quality solutions. We also develop difference rewards based credit assignment methods for the collective setting. Empirically our new approaches provide significantly better solutions than previous methods in the presence of global rewards on two real world problems modeling taxi fleet optimization and multiagent patrolling, and a synthetic grid navigation domain. 
525. **A Lyapunov-based Approach to Safe Reinforcement Learning** --*Yinlam Chow &middot; Ofir Nachum &middot; Mohammad Ghavamzadeh &middot; Edgar Duenez-Guzman*
 > In many real-world reinforcement learning (RL) problems, besides optimizing the main objective function, an agent must concurrently avoid violating a number of constraints. In particular, besides optimizing performance it is crucial to guarantee the \emph{safety} of an agent during training as well as deployment (e.g. a robot should avoid taking actions - exploratory or not - which irrevocably harm its hardware). To incorporate safety in RL, we derive algorithms under the framework of Constrained Markov decision problems (CMDPs), an extension of the standard Markov decision problems (MDPs) augmented with constraints on expected cumulative costs. Our approach hinges on a novel \emph{Lyapunov} method. <br /> We define and present a method for constructing Lyapunov functions, which provide an effective way to guarantee the global safety of a behavior policy during training via a set of local, linear constraints. Leveraging these theoretical underpinnings, we show how to use the Lyapunov approach to systematically transform dynamic programming (DP) and RL algorithms into their safe counterparts.  To illustrate their effectiveness, we evaluate these algorithms in several CMDP planning and decision-making tasks on a safety benchmark domain. Our results show that our proposed method significantly outperforms existing baselines in balancing constraint satisfaction and performance.
526. **Learning to Specialize with Knowledge Distillation for Visual Question Answering** --*Jonghwan Mun &middot; Kimin Lee &middot; Jinwoo Shin &middot; Bohyung Han*
 > Visual Question Answering (VQA) is a notoriously challenging problem because it involves various heterogeneous tasks defined by questions within a unified framework. Learning specialized models for individual types of tasks is intuitively attracting but surprisingly difficult; it is not straightforward to outperform naive independent ensemble approaches. We present a principled algorithm to learn specialized models with knowledge distillation under a multiple choice learning framework. The training examples are dynamically assigned to a subset of models for specializing their functionality. The assigned and non-assigned models are learned to predict ground-truth answers and imitate their own base models before specialization, respectively. Our approach alleviates the problem of data deficiency, which is a critical limitation in existing frameworks on multiple choice learning, and allows each model to learn its own specialized expertise without forgetting general knowledge by knowledge distillation. Our experiments show that the proposed algorithm achieves the superior performances compared to naive ensemble methods and other baselines in VQA. Our framework is also effective for more general tasks, e.g., image classification with a large number of labels, which is known to be difficult under existing multiple choice learning schemes.
527. **Efficient Anomaly Detection via Matrix Sketching** --*Parikshit Gopalan &middot; Vatsal Sharan &middot; Udi Wieder*
 > We consider the problem of finding anomalies in high-dimensional data using popular PCA based anomaly scores.  The naive algorithms for computing these scores explicitly compute the PCA of the covariance matrix which uses space quadratic in the dimensionality of the data. We give the first streaming algorithms that use space that is linear or sublinear in the dimension. We prove general results showing that \emph{any} sketch of a matrix that satisfies a certain operator norm guarantee can be used to approximate these scores. We instantiate these results with powerful matrix sketching techniques such as Frequent Directions and random projections to derive efficient and practical algorithms for these problems, which we validate over real-world data sets. Our main technical contribution is to prove matrix perturbation inequalities for operators arising in the computation of these measures.
528. **Dendritic Neural Network with Great Expressive Power** --*Xundong Wu*
 > A typical biological neuron, such as a pyramidal neuron of neocortex receives thousands of afferent synaptic inputs on its dendrite tree and send the efferent axonal output downstream. Dendrite trees are generally modeled as linear structures that funnel weighted synaptic inputs to the cell body in classical artificial neural networks. However, numerous experimental and theoretical studies have shown that dendrite arbors are far more than such simple linear accumulator. That is, synaptic inputs can actively modulate their neighboring synaptic activities, therefore the dendritic structures are highly nonlinear. In this study, we model such local nonlinearity of dendrite trees with our Dendritic Neural Network (D-Net) structure and apply this to typical machine learning tasks. Equipped with localized non-linearity, D-Nets can attain much greater model expressivity than regular neural networks. Such strength is also evidenced by greater fitting power of networks when we train D-Nets with supervised machine learning tasks. We also empirically show that the locality structure also gives D-Nets significant boost to its generalization ability, exemplified by outranking all other neural network architectures in comparison when tested on 121 classification tasks from the UCI machine learning repository.
530. **Neural Arithmetic Logic Units** --*Andrew Trask &middot; Felix Hill &middot; Scott Reed &middot; Jack Rae &middot; Chris Dyer &middot; Phil Blunsom*
 > Neural networks can learn to represent and manipulate numerical information, but they seldom generalize well outside of the range of numerical values encountered during training. To encourage more systematic numerical extrapolation, we propose an architecture that represents numerical quantities as linear activations which are manipulated using primitive arithmetic operators, controlled by learned gates. We call this module a neural arithmetic logic unit (NALU), by analogy to the arithmetic logic unit in traditional processors. Experiments show that NALU-enhanced neural networks can learn to track time, perform arithmetic over images of numbers, translate numerical language into real-valued scalars, execute computer code, and count objects in images. In contrast to conventional architectures, we obtain substantially better generalization both inside and outside of the range of numerical values encountered during training, often extrapolating orders of magnitude beyond trained numerical ranges.
532. **Reward learning from human preferences and demonstrations in Atari** --*Jan Leike &middot; Borja Ibarz &middot; Dario Amodei &middot; Geoffrey Irving &middot; Shane Legg*
 > To solve complex real-world problems with reinforcement learning, we cannot rely on manually specified reward functions. Instead, we need humans to communicate an objective to the agent directly. In this work, we combine two approaches to this problem: learning from expert demonstrations and learning from trajectory preferences. We use both to train a deep neural network to model the reward function and use its predicted reward to train an DQN-based deep reinforcement learning agent on 9 Atari games. Our approach beats the imitation learning baseline in 7 games and achieves strictly superhuman performance on 2 games. Additionally, we investigate the fit of the reward model, present some reward hacking problems, and study the effects of noise in the human labels.
533. **Spectral Signatures in Backdoor Attacks on Deep Nets** --*Brandon Tran &middot; Jerry Li &middot; Aleksander Madry*
 > A recent line of work has uncovered a new form of data poisoning: so-called backdoor attacks. These attacks are particularly dangerous because they do not affect a network's behavior on typical, benign data. Rather, the network only deviates from its expected output when triggered by an adversary's planted perturbation.
534. **The challenge of realistic music generation: modelling raw audio at scale** --*Sander Dieleman &middot; Aaron van den Oord &middot; Karen Simonyan*
 > Realistic music generation is a challenging task. When building generative models of music that are learnt from data, typically high-level representations such as scores or MIDI are used that abstract away the idiosyncrasies of a particular performance. But these nuances are very important for our perception of musicality and realism, so in this work we embark on modelling music in the raw audio domain. It has been shown that autoregressive models excel at generating raw audio waveforms of speech, but when applied to music, we find them biased towards capturing local signal structure at the expense of modelling long-range correlations. This is problematic because music exhibits structure at many different timescales. In this work, we explore autoregressive discrete autoencoders (ADAs) as a means to enable autoregressive models to capture long-range correlations in waveforms. We find that they allow us to unconditionally generate piano music directly in the raw audio domain, which shows stylistic consistency across tens of seconds.
535. **Submodular Maximization via Gradient Ascent: The Case of Deep Submodular   Functions** --*Wenruo Bai &middot; William Stafford Noble &middot; Jeff A Bilmes*
 > We study the problem of maximizing deep submodular functions (DSFs) subject to a matroid constraint. DSFs are an expressive class of submodular functions that include, as strict subfamilies, the facility location, weighted coverage, and sums of concave composed with modular functions. We use a strategy similar to the continuous greedy approach~\cite{calinescu2007maximizing}, but we show that the multilinear extension of any DSF has a natural and computationally attainable concave relaxation that we can optimize using gradient ascent. Our results show a guarantee of \max_{0<\delta<1}(1-\epsilon-\delta-e^{-\delta^2O(k)}) with a running time of O(\nicefrac{n^2}{\epsilon^2}) plus time for pipage rounding to recover a discrete solution, where k is the rank of the matroid constraint. This bound is often better than the standard 1-1/e guarantee of the continuous greedy algorithm, but runs much faster. Our bound also holds even for fully curved (c=1) functions where the guarantee of 1-c/e degenerates to 1-1/e where $c$ is the curvature of f.  We perform computational experiments that support our theoretical results.
536. **Stochastic Expectation Maximization with Variance Reduction** --*Jianfei Chen &middot; Jun Zhu &middot; Yee Whye Teh &middot; Tong Zhang*
 > Expectation-Maximization (EM) is a popular tool for learning latent variable models, but the vanilla batch EM does not scale to large data sets because the whole data set is needed at every E-step. Stochastic Expectation Maximization (sEM) reduces the cost of E-step by stochastic approximation. However, sEM has a slower asymptotic convergence rate than batch EM, and requires a decreasing sequence of step sizes, which is difficult to tune. In this paper, we propose a variance reduced stochastic EM (sEM-vr) algorithm inspired by variance reduced stochastic gradient descent algorithms. We show that sEM-vr has the same exponential asymptotic convergence rate as batch EM. Moreover, sEM-vr only requires a constant step size to achieve this rate, which alleviates the burden of parameter tuning. We compare sEM-vr with batch EM, sEM and other algorithms on Gaussian mixture models and probabilistic latent semantic analysis, and sEM-vr converges significantly faster than these baselines.
537. **Dirichlet belief networks as structured topic prior** --*He Zhao &middot; Lan Du &middot; Wray Buntine &middot; Mingyuan Zhou*
 > Recently, on the success of deep learning, considerable research effort has been devoted to developing deep architectures for topic models. Although several deep models have been proposed to learn better topic proportions of documents, how to leverage the benefits of deep structures for learning word distributions of topics has not yet been rigorously studied. Here we propose a new multi-layer generative process on word distributions of topics, where each layer consists of a set of topics and each topic is drawn from a mixture of the topics in the layer above. As the topics in all the layers can be directly interpreted by words, the proposed model is able to discover interpretable topic hierarchies. As an self-contained module, our model can be flexibly adapted to different kinds of topic models to improve their modelling accuracy and interpretability. Extensive experiments on real corpora demonstrated the advantages of the proposed model.
538. **Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation** --*Tianyu He &middot; Xu Tan &middot; Yingce Xia &middot; Di He &middot; Tao Qin &middot; Zhibo Chen &middot; Tieyan Liu*
 > Neural Machine Translation (NMT) has achieved remarkable progress with the quick evolvement of model structures. In this paper, we propose the concept of layer-wise coordination for NMT, which explicitly coordinates the learning of hidden representations of the encoder and decoder together layer by layer, gradually from low level to high level. Furthermore, we share the parameters of each layer between the encoder and decoder to regularize and coordinate the learning. Experiments show that combined with the state-of-the-art Transformer model, layer-wise coordination achieves improvements on three IWSLT and two WMT translation tasks. More specifically, our method achieves 34.43 and 29.01 BLEU score on WMT16 English-Romanian and WMT14 English-German tasks, outperforming the Transformer baseline.
539. **Learning to Repair Software Vulnerabilities with Generative Adversarial Networks** --*Jacob Harer &middot; Onur Ozdemir &middot; Tomo Lazovich &middot; Christopher Reale &middot; Rebecca Russell &middot; Louis Kim &middot; peter chin*
 > Motivated by the problem of automated repair of software vulnerabilities, we propose an adversarial learning approach that maps from one discrete source domain to another target domain without requiring paired labeled examples or source and target domains to be bijections. We demonstrate that the proposed adversarial learning approach is an effective technique for repairing software vulnerabilities, performing close to seq2seq approaches that require labeled pairs. The proposed Generative Adversarial Network approach is application-agnostic in that it can be applied to other problems similar to code repair, such as grammar correction or sentiment translation.
540. **Monte-Carlo Tree Search for Constrained POMDPs** --*Jongmin Lee &middot; Geon-hyeong Kim &middot; Pascal Poupart &middot; Kee-Eung Kim*
 > Monte-Carlo Tree Search (MCTS) has been successfully applied to very large POMDPs, a standard model for stochastic sequential decision-making problems. However, many real-world problems inherently have multiple goals, where multi-objective formulations are more natural. The constrained POMDP (CPOMDP) is such a model that maximizes the reward while constraining the cost, extending the standard POMDP model. To date, solution methods for CPOMDPs assume an explicit model of the environment, and thus are hardly applicable to large-scale real-world problems. In this paper, we present CC-POMCP (Cost-Constrained POMCP), an online MCTS algorithm for large CPOMDPs that leverages the optimization of LP-induced parameters and only requires a black-box simulator of the environment. In the experiments, we demonstrate that CC-POMCP converges to the optimal stochastic action selection in CPOMDP and pushes the state-of-the-art by being able to scale to very large problems.
541. **Robust Detection of Adversarial Attacks by Modeling the Intrinsic Properties of Deep Neural Networks** --*Zhihao Zheng &middot; Pengyu Hong*
 > It has been shown that deep neural network (DNN) based classifiers are vulnerable to human-imperceptive adversarial perturbations which can cause DNN classifiers to output wrong predictions with high confidence. We propose an unsupervised learning approach to detect adversarial inputs without any knowledge of attackers. Our approach tries to capture the intrinsic properties of a DNN classifier and uses them to detect adversarial inputs. The intrinsic properties used in this study are the output distributions of the hidden neurons in a DNN classifier presented with natural images. Our approach can be easily applied to any DNN classifiers or combined with other defense strategy to improve robustness. Experimental results show that our approach demonstrates state-of-the-art robustness in defending black-box and gray-box attacks.
543. **RenderNet: A deep convolutional network for differentiable rendering from 3D shapes** --*Thu Nguyen-Phuoc &middot; Chuan Li &middot; Stephen Balaban &middot; Yongliang Yang*
 > Traditional computer graphics rendering pipeline is designed for procedurally generating 2D quality images from 3D shapes with high performance. The non-differentiability due to discrete operations such as visibility computation makes it hard to explicitly correlate rendering parameters and the resulting image, posing a significant challenge for inverse rendering tasks. Recent work on differentiable rendering achieves differentiability either by designing surrogate gradients for non-differentiable operations or via an approximate but differentiable renderer. These methods, however, are still limited when it comes to handling occlusion and restricted to particular rendering effects. We present RenderNet, a differentiable rendering convolutional network with a novel projection unit that can render 2D images from 3D shapes. Spatial occlusion and shading calculation are automatically encoded in the network. Our experiments show that RenderNet can successfully learn to implement different shaders, and can be used in inverse rendering tasks to estimate shape, pose, lighting and texture from a single image.
544. **Cluster Variational Approximations for Structure Learning of Continuous-Time Bayesian Networks from Incomplete Data** --*Dominik Linzner &middot; Heinz Koeppl*
 > Continuous-time Bayesian networks (CTBNs) constitute a general and powerful framework for modeling continuous-time stochastic processes on networks. This makes them particularly attractive for learning the directed structures among interacting entities. However, if the available data is incomplete, one needs to simulate the prohibitively complex CTBN dynamics. Existing approximation techniques, such as sampling and low-order variational methods, either scale unfavorably in system size, or are unsatisfactory in terms of accuracy. Inspired by recent advances in statistical physics, we present a new approximation scheme based on cluster-variational methods significantly improving upon existing variational approximations. We can then analytically marginalize CTBN parameters, as these are of secondary importance for structure learning. This recovers a scalable scheme for direct structure learning from incomplete and noisy time-series data. Our approach outperforms existing methods in terms of scalability.
545. **A Reduction for Efficient LDA Topic Reconstruction** --*Flavio Chierichetti &middot; Alessandro Panconesi &middot; Andrea Vattani*
 > We present a novel approach for LDA (Latent Dirichlet Allocation) topic reconstruction. The main technical idea is to show that the distribution over the documents generated by LDA can be transformed into a distribution for a much simpler generative model in which documents are generated from {\em the same set of topics} but have a much simpler structure: documents are single topic and topics are chosen uniformly at random. Furthermore, this reduction is approximation preserving, in the sense that approximate distributions-- the only ones we can hope to compute in practice-- are mapped into approximate distribution in the simplified world. This opens up the possibility of efficiently reconstructing LDA topics in a roundabout way. Compute an approximate document distribution from the given corpus, transform it into an approximate distribution for the single-topic world, and run a reconstruction algorithm in the uniform, single topic world-- a much simpler task than direct LDA reconstruction. Indeed, we show the viability of the approach by giving very simple algorithms for a generalization of two notable cases that have been studied in the literature, $p$-separability and Gibbs sampling for matrix-like topics.
546. **A General Method for Amortizing Variational Filtering** --*Joseph Marino &middot; Milan Cvitkovic &middot; Yisong Yue*
 > We introduce a general-purpose, theoretically-grounded, and simple method for performing filtering variational inference in dynamical latent variable models, which we refer to as the variational filtering EM algorithm. The algorithm is derived from the variational objective in the filtering setting and naturally consists of a Bayesian prediction-update loop, with updates performed using any desired optimization method. A computationally efficient implementation of the algorithm is provided, using iterative amortized inference models to perform inference optimization. Through empirical evaluations with several deep dynamical latent variable models on a variety of sequence data sets, we demonstrate that this simple filtering scheme compares favorably against previously proposed filtering methods in terms of inference performance, thereby improving model quality.
