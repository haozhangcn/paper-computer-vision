112. **Improving Online Algorithms via ML Predictions** --*Manish Purohit &middot; Zoya Svitkina &middot; Ravi Kumar*
 > In this work we study the problem of using machine learned predictions to improve performance of online algorithms.  We consider two classical problems, ski rental and non-clairvoyant job scheduling, and obtain new online algorithms that use predictions to make their decisions.  These algorithms are oblivious to the performance of the predictor, improve with better predictions, but do not degrade much if the predictions are poor.
114. **Ex ante correlation and collusion in zero-sum multi-player extensive-form games** --*Andrea Celli &middot; Gabriele Farina &middot; Nicola Gatti &middot; Tuomas Sandholm*
 > Recent milestones in equilibrium computation, such as the success of Libratus, show that computing strong solutions to two-player zero-sum games is feasible in theory and practice. This is not the case for games with multiple players, which remains one of the main open challenges in computational game theory. This paper focuses on zero-sum games where a team of players faces an opponent, as is the case, for example, in Bridge, collusion in poker, and many non-recreational applications such as war where the colluders do not have time or means of communicating during battle, collusion in bidding where communication during the auction is illegal, and coordinated swindling in public. The possibility for the team members to communicate before game play---that is, correlate their strategies ex ante---makes the use of behavioral strategies unsatisfactory. The reasons for this are closely related to the fact that the team can be represented as a single player with imperfect recall. We propose a new game representation, the realization form, that generalizes the sequence form but can also be applied to imperfect-recall games. Then, we use it to derive an auxiliary game that is equivalent to the original one, and has certain useful properties. By reasoning over the auxiliary game, we devise an anytime algorithm, Fictitious Team-Play, that is guaranteed to converge to a Nash equilibrium and that is dramatically faster than the prior state-of-the-art algorithm for this problem.
115. **Invertibility of Convolutional Generative Networks from Partial Measurements** --*Fangchang Ma &middot; Ulas Ayaz &middot; Sertac Karaman*
 > In this work, we present new theoretical results on convolutional generative neural networks, in particular their invertibility (i.e., the recovery of input latent code given the network output). This inversion problem is highly non-convex, which is in general computationally challenging and has no performance guarantee. However, we rigorously prove that, even when the network output is only partially observed (e.g., with missing pixels), the input of a two-layer convolutional generative network can always be computed from the network output, using simple gradient descent. This new theoretical finding implies that the mapping from the low-dimensional latent space to the high-dimensional image space is bijective (i.e., one-to-one). Our theorem holds for 2-layer convolutional generative network with relu as the activation function, but we demonstrate that the same conclusion empirically extends to multi-layer networks and networks with other activation functions (including the leaky relu, sigmoid and tanh). Our proof is built on our newly proposed permutation technique, which can potentially be generalized to networks with multiple layers and in other theoretical studies on convolutional neural networks, and thus is a merit on its own.
116. **Trading robust representations for sample complexity through self-supervised visual experience** --*Andrea Tacchetti &middot; Stephen Voinea &middot; Georgios Evangelopoulos*
 > Learning in small sample regimes is among the most remarkable features of the human perceptual system. This ability is related to robustness to transformations, which is acquired through visual experience in the form of weak- or self-supervision during development. We explore the idea of allowing artificial systems to learn representations of visual stimuli through weak supervision prior to downstream supervised tasks. We introduce a novel loss function for representation learning using unlabeled image sets and video sequences, and experimentally demonstrate that these representations support one-shot learning and reduce the sample complexity of multiple recognition tasks. We establish the existence of a trade-off between the sizes of weakly supervised, automatically obtained from video sequences, and fully supervised data sets. Our results suggest that equivalence sets other than class labels, which are abundant in unlabeled visual experience, can be used for self-supervised learning of semantically relevant image embeddings.
117. **An intriguing failing of convolutional neural networks and the CoordConv solution** --*Rosanne Liu &middot; Joel Lehman &middot; Eric Frank &middot; Felipe Petroski Such &middot; Alex Sergeev &middot; Jason Yosinski*
 > Few ideas have enjoyed as large an impact on deep learning as convolution. For any problem involving pixels or spatial representations, common intuition holds that convolutional networks may be appropriate. In this paper we show a striking counterexample to this intuition via the seemingly trivial coordinate transform problem, which simply requires learning a mapping between coordinates in (x,y) Cartesian space and coordinates in pixel space. Although convolutional networks would seem appropriate for this task, we show that they fail spectacularly. We demonstrate and carefully analyze the failure first on a toy problem, at which point a simple fix becomes obvious. We call this solution CoordConv, which works by giving convolution access to its own input coordinates through the use of extra coordinate channels. Without sacrificing the computational and parametric efficiency of ordinary convolution, CoordConv allows networks to learn either perfect translation invariance or varying degrees of translation dependence, as required by the end task. CoordConv solves the coordinate transform problem 150 times faster, with 10-100 times fewer parameters, and with perfect generalization.
118. **Optimal Algorithms for Continuous   Non-monotone Submodular and DR-Submodular Maximization** --*Rad Niazadeh &middot; Tim Roughgarden &middot; Joshua Wang*
 > In this paper we study the fundamental problems of maximizing a continuous non monotone submodular function over a hypercube, with and without coordinate-wise concavity. This family of optimization problems has several applications in machine learning, economics, and communication systems. Our main result is the first 1/2 approximation algorithm for continuous submodular function maximization; this approximation factor of is the best possible for algorithms that use only polynomially many queries.  For the special case of DR-submodular maximization, we provide a different 1/2-approximation algorithm that runs in quasi-linear time. Both of these results improve upon prior work [Bian et al., 2017]. Our first algorithm uses novel ideas such as reducing the guaranteed approximation problem to analyzing a zero-sum game for each coordinate, and incorporates the geometry of this zero-sum game to fix the value at this coordinate. Our second algorithm exploits coordinate-wise concavity to identify a monotone equilibrium condition sufficient for getting the required approximation guarantee, and hunts for the equilibrium point using binary search. We further run experiments to verify the performance of our proposed algorithms in related machine learning applications. 
120. **Neural Proximal Gradient Descent for Compressive Imaging** --*Morteza Mardani &middot;   &middot; David Donoho &middot; Vardan Papyan &middot; Hatef Monajemi &middot; Shreyas Vasanawala &middot; John Pauly*
 > Recovering high-resolution images from limited sensory data typically leads to a serious ill-posed inverse problem, demanding inversion algorithms that effectively capture the prior information. Learning a good inverse mapping from training data faces severe challenges, including: (i) scarcity of training data; (ii) need for  plausible reconstructions that are physically feasible; (iii) need for fast reconstruction, especially in real-time applications. We develop a successful system solving all these challenges, using as basic architecture the repetitive application of alternating proximal and data fidelity constraints. We learn a proximal map that works well with real images based on residual networks with recurrent blocks. Extensive experiments are carried out under different settings: (a) reconstructing abdominal MRI of pediatric patients from highly undersampled k-space data and (b) super-resolving natural face images. Our key findings include: 1. a recurrent ResNet with a single residual block (10-fold repetition) yields an effective proximal which accurately reveals MR image details. 2. Our architecture significantly outperforms conventional non-recurrent deep ResNets by 2dB SNR; it is also trained much more rapidly. 3. It outperforms state-of-the-art compressed-sensing Wavelet-based methods by 4dB SNR, with 100x speedups in reconstruction time.
121. **Learning convex bounds for linear quadratic control policy synthesis** --*Jack Umenberger &middot; Thomas B Schön*
 > Learning to make decisions from observed data in dynamic environments remains a problem of fundamental importance in a numbers of fields, from artificial intelligence and robotics, to medicine and finance. This paper concerns the problem of learning control policies for unknown linear dynamical systems so as to maximize a quadratic reward function. We present a method to optimize the expected value of the reward over the posterior distribution of the unknown system parameters, given data. The algorithm involves sequential convex programing, and enjoys reliable local convergence and robust stability guarantees. Numerical simulations and stabilization of a real-world inverted pendulum are used to demonstrate the approach, with strong performance and robustness properties observed in both.
122. **Fast Approximate Natural Gradient Descent in a Kronecker Factored Eigenbasis** --*Thomas George &middot; César Laurent &middot; Xavier Bouthillier &middot; Nicolas Ballas &middot; Pascal Vincent*
 > Optimization algorithms that leverage gradient covariance information, such as variants of natural gradient descent (Amari, 1998), offer the prospect of yielding more effective descent directions. For models with many parameters, the covariance matrix they are based on however becomes gigantic, rendering them inapplicable in their original form. This has motivated research into both simple diagonal approximations and more sophisticated factored approximations such as KFAC (Heskes, 2000; Martens &amp; Grosse, 2015; Grosse &amp; Martens, 2016). In the present work we draw inspiration from both to propose a novel approximation that is both provably better than KFAC and that is amendable to cheap partial updates. It consists in tracking a diagonal variance, not in parameter coordinates, but in a Kronecker-factored eigenbasis, in which the diagonal approximation is likely to be more effective. Experiments show improvements over KFAC in optimization speed for several deep network architectures, both in number of iterations and in wall-clock-time.
123. **e-SNLI: Natural Language Inference with Natural Language Explanations** --*Oana-Maria Camburu &middot; Tim Rocktäschel &middot; Thomas Lukasiewicz &middot; Phil Blunsom*
 > In order for machine learning to garner widespread public adoption, models must be able to provide interpretable and robust explanations for their decisions, as well as learn from natural language explanations. In this work, we extend the Stanford Natural Language Inference dataset with an additional layer of human-annotated free-form explanations of the entailment relations. We further implement models that incorporate these explanations into their training process and output them at test time. We show that our corpus of explanations can be used for various goals, such as obtaining full sentence justifications of a model's decisions and providing consistent improvements on a range of tasks compared to universal sentence representations learned without explanations. Our dataset opens up a range of research directions for using natural language explanations, both for improving models and for asserting their trust.
124. **Reinforcement Learning with Multiple Experts: A Bayesian Model Combination Approach** --*Mike Gimelfarb &middot; Scott Sanner &middot; Chi-Guhn Lee*
 > Potential based reward shaping is a powerful technique for accelerating convergence of reinforcement learning algorithms. Typically, such information includes an estimate of the optimal value function and is often provided by a human expert or other sources of domain knowledge. However, this information is often biased or inaccurate and can mislead many reinforcement learning algorithms. In this paper, we apply Bayesian Model Combination with multiple experts in a way which learns to trust the best combination of experts as training progresses. This approach is both computationally efficient and general, and is shown numerically to improve convergence of various reinforcement learning algorithms across many domains.
125. **Uncertainty-Aware Few-Shot Learning with Probabilistic Model-Agnostic Meta-Learning** --*Kelvin Xu &middot; Chelsea Finn &middot; Sergey Levine*
 > Meta-learning for few-shot learning entails acquiring a prior over previous tasks and experiences, such that new tasks be learned from small amounts of data. However, a critical challenge in few-shot learning is task ambiguity: even when a powerful prior can be meta-learned from a large number of prior tasks, a small dataset for a new task can simply be too ambiguous to acquire a single model (e.g., a classifier) for that task that is accurate. In this paper, we propose a probabilistic meta-learning algorithm that can sample models for a new task from a model distribution. Our approach extends model-agnostic meta-learning, which adapts to new tasks via gradient descent, to incorporate a parameter distribution that is trained via a variational lower bound. At meta-test time, our algorithm adapts via a simple procedure that injects noise into gradient descent, and at meta-training time, the model is trained such that this stochastic adaptation procedure produces samples from the approximate model posterior. Our experimental results show that our method can sample plausible classifiers and regressors in ambiguous few-shot learning problems.
126. **Sanity Checks for Saliency Maps** --*Julius Adebayo &middot; Been Kim &middot; Ian Goodfellow &middot; Justin Gilmer &middot; Moritz Hardt*
 > Saliency methods have emerged as a popular tool to highlight features in an input deemed relevant for the prediction of a learned model. Numerous saliency methods have been proposed, often guided by visual appeal on image data. In this work, we propose an actionable methodology to evaluate what kinds of explanations a given method can and cannot provide. Through extensive experiments we show that several existing saliency methods are independent both of the model and of the data, label pairs. Therefore these methods are inadequate for tasks that are sensitive to either data or model, such as, finding outliers in the data, explaining the relationship between inputs and outputs that the model learned, or debugging the model. We interpret our findings through an analogy with edge detection in images, a technique that requires neither training data nor model. Theory in the case of linear models supports our experimental findings.
127. **Multi-objective Maximization of Monotone Submodular Functions with Cardinality Constraint** --*Rajan Udwani*
 > 	We consider the problem of multi-objective maximization of monotone submodular functions subject to cardinality constraint, often formulated as $\max_{|A|=k}\min_{i\in\{1,\dots,m\}}f_i(A)$. While it is well known that greedy methods work well for a single objective, the problem becomes much harder with multiple objectives. In fact, Krause et al.\ (2008) showed that when the number of objectives $m$ grows as the cardinality $k$ i.e., $m=\Omega(k)$, the problem is inapproximable (unless $P=NP$). On the other hand when $m$ is constant, there is a randomized $(1-1/e)-\epsilon$ approximation with runtime (number of queries to function oracle) $n^{m/\epsilon^3}$ due to Chekuri et al.\ (2010). %In fact, the result of Chekuri et al.\ (2010) is for the far more general case of matroid constant.  	 	In this paper, we focus on finding a fast and practical algorithm that has (asymptotic) approximation guarantees even when $m$ is super constant. We first modify the algorithm of Chekuri et al.\ (2010) to achieve an $(1-1/e)$ approximation for $m=o(\frac{k}{\log^3 k})$, demonstrating a steep transition from constant factor approximability to inapproximability around $\Omega(k)$. More importantly, using Multiplicative-Weight-Updates (MWU) we find a much faster $\tilde{O}(n/\delta^3)$ time, asymptotic $(1-1/e)^2-\delta$ approximation. While the above results are all randomized, we also give a simple deterministic $(1-1/e)-\epsilon$ approximation with runtime $kn^{m/\epsilon^4}$. Finally, we run synthetic experiments on Kronecker graphs and find that our MWU inspired heuristic outperforms existing heuristics.
128. **PAC-Bayes Tree: weighted subtrees with guarantees** --*Tin Nguyen &middot; Samory Kpotufe*
 > We present a weighted-majority classification approach over subtrees of a fixed tree, which provably achieves excess-risk of the same order as the best tree-pruning. Furthermore, the computational efficiency of pruning is maintained at both training and testing time despite having to aggregate over an exponential number of subtrees. We believe this is the first subtree aggregation approach with such guarantees. 
129. **DAGs with NO TEARS: Continuous Optimization for Structure Learning** --*Xun Zheng &middot; Bryon Aragam &middot; Pradeep Ravikumar &middot; Eric Xing*
 > Estimating the structure of directed acyclic graphs (DAGs, also known as {Bayesian networks}) is a challenging problem since the search space of DAGs is combinatorial and scales superexponentially with the number of nodes. Existing approaches rely on various local heuristics for enforcing the acyclicity constraint. In this paper, we introduce a fundamentally different strategy: we formulate the structure learning problem as a purely \emph{continuous} optimization problem over real matrices that avoids this combinatorial constraint entirely.  This is achieved by a novel characterization of acyclicity that is not only smooth but also exact. The resulting problem can be efficiently solved by standard numerical algorithms, which also makes implementation effortless. The proposed method outperforms existing ones, without imposing any structural assumptions on the graph such as bounded treewidth or in-degree.
130. **Implicit Bias of Gradient Descent on Linear Convolutional Networks** --*Suriya Gunasekar &middot; Jason Lee &middot; Daniel Soudry &middot; Nati Srebro*
 > We show that gradient descent on full-width linear convolutional networks of depth $L$ converges to a linear predictor related to the $\ell_{2/L}$ bridge penalty in the frequency domain. This is in contrast to linearly fully connected networks, where gradient descent converges to the hard margin linear SVM solution, regardless of depth. 
131. **Learning and Testing Causal Models with Interventions** --*Jayadev Acharya &middot; Arnab Bhattacharyya &middot; Constantinos  Daskalakis &middot; Saravanan Kandasamy*
 > We consider testing and learning problems on causal Bayesian networks as defined by Pearl (Pearl, 2009). Given a causal Bayesian network M on a graph with n discrete variables and bounded in-degree and bounded ``confounded components'', we show that O(\log n) interventions on an unknown causal Bayesian network X on the same graph, and O~(n/epsilon^2) samples per intervention, suffice to efficiently distinguish whether X=M or whether there exists some intervention under which X and M are farther than epsilon in total variation distance.  We also obtain sample/time/intervention efficient algorithms for: (i) testing the identity of two unknown causal Bayesian networks on the same graph; and (ii) learning a causal Bayesian network on a given graph.  Although our algorithms are non-adaptive, we show that adaptivity does not help in general: Omega(log n) interventions are necessary for testing the identity of two unknown causal Bayesian networks on the same graph, even adaptively.  Our algorithms are enabled by a new subadditivity inequality for the squared Hellinger distance between two causal Bayesian networks.
132. **Discovering Feedback Codes via Deep Learning** --*Hyeji Kim &middot; Yihan Jiang &middot; Sreeram Kannan &middot; Sewoong Oh &middot; Pramod Viswanath*
 > The design of codes for communicating reliably over a statistically well defined  channel is an important endeavor involving deep mathematical research and wide-ranging practical applications. In this work, we present the first family of codes obtained via deep learning, which significantly beats state-of-the-art codes  designed over several decades of research. The communication channel under consideration is the Gaussian noise channel with feedback, whose study was initiated by Shannon; feedback is known theoretically to improve reliability of communication, but no practical codes that do so have ever been successfully constructed. 
133. **Identification and Estimation of Causal Effects from Dependent Data** --*Eli Sherman &middot; Ilya Shpitser*
 > The assumption that data samples are independent and identically distributed (iid) is standard in many areas of statistics and machine learning. Nevertheless, in some settings, such as social networks, infectious disease modeling, and reasoning with spatial and temporal data, this assumption is false. An extensive literature exists on making causal inferences under the iid assumption [12, 8, 21, 16], but, as pointed out in [14], causal inference in non-iid contexts is challenging due to the combination of unobserved confounding bias and data dependence. In this paper we develop a general theory describing when causal inferences are possible in such scenarios. We use segregated graphs [15], a generalization of latent projection mixed graphs [23], to represent causal models of this type and provide a complete algorithm for non-parametric identification in these models. We then demonstrate how statistical inferences may be performed on causal parameters identified by this algorithm, even in cases where parts of the model exhibit full interference, meaning only a single sample is available for parts of the model [19]. We apply these techniques to a synthetic data set which considers the adoption of fake news articles given the social network structure, articles read by each person, and baseline demographics and socioeconomic covariates.
134. **Quantifying Linguistic Shifts: The Global Anchor Method and Its Applications** --*Zi Yin &middot; Vinayak Sachidananda &middot; Balaji Prabhakar*
 > Language is dynamic, constantly evolving and adapting with respect to time, domain or topic. The adaptability of language is an active research area, where researchers discover social, cultural and domain-specific changes in language using distributional tools such as word embeddings. In this paper, we introduce the global anchor method for detecting corpus-level language shifts. We show both theoretically and empirically that the global anchor method is equivalent to the alignment method, a widely-used method for comparing word embeddings, in terms of detecting corpus-level language shifts. Despite their equivalence in terms of detection abilities, we demonstrate that the global anchor method is superior in terms of applicability as it can compare embeddings of different dimensionalities. Furthermore, the global anchor method has implementation and parallelization advantages. We show that the global anchor method reveals fine structures in the evolution of language and domain adaptation. When combined with the graph Laplacian technique, the global anchor method recovers the evolution trajectory and domain clustering of disparate text corpora.
135. **Gather-Scatter: Context Propagation for ConvNets** --*Jie Hu &middot; Li Shen &middot; Gang Sun &middot; Samuel Albanie &middot; Andrea Vedaldi*
 > The powerful image representations learned by deep convolutional neural networks (ConvNets) have propelled this family of models to a state of dominance in image classification.  But by constructing features in a strictly bottom-up manner with local operators, ConvNets may be unable to efficiently exploit contextual information that resides in the relationships between features. The focus of this work is to propose a simple, lightweight solution to the issue of limited context propagation in ConvNets.  Our approach, which we formulate as a gather-scatter operator pair, propagates context across a group of neurons by aggregating responses over their extent and redistributing the aggregates back through the group.  The simplicity of our approach brings several benefits: the operators add few parameters, minimal computational overhead and, importantly, can be directly integrated into existing architectures to improve performance without careful hyperparameter tuning.  We present evidence that integration of gather-scatter operators into a ConvNet produces qualitatively different intermediate feature representations.  Moreover, we show with experiments on the CIFAR-10, CIFAR-100 and ImageNet datasets that improving context diffusion can be just as important as increasing the depth of a network, at a fraction of the cost.  In fact, we find that by supplementing a ResNet-50 model with gather-scatter operators, it is able to outperform its 101-layer counterpart on ImageNet with no additional learnable parameters.
136. **The emergence of multiple retinal cell types through efficient coding of natural movies** --*Stephane Deny &middot; Jack Lindsey &middot; Surya Ganguli &middot; Samuel Ocko*
 > One of the most striking aspects of early visual processing in the retina is the immediate parcellation of visual information into multiple parallel pathways, formed by different retinal ganglion cell types each tiling the entire visual field. Existing theories of efficient coding have been unable to account for the functional advantages of such cell-type diversity in encoding natural scenes. Here we go beyond previous theories to analyze how a simple linear retinal encoding model with different convolutional cell types efficiently encodes naturalistic spatiotemporal movies with a fixed firing rate budget. We find that optimizing the receptive fields and cell densities of two cell types makes them match the properties of two main cell types in the primate retina, midget and parasol cells, in terms of spatial and temporal sensitivity, cell spacing, and their relative ratio. Moreover, our theory gives a precise account of how the ratio of midget to parasol cells decreases with retinal eccentricity.  Also, we train a nonlinear encoding model with a rectifying nonlinearity to efficiently encode naturalistic movies, and again find emergent receptive fields resembling those of midget and parasol cells that are now further subdivided into ON and OFF types. Thus our work provides a theoretical justification, based on the efficient coding of naturalistic movies, for the existence of the four most dominant cell types in the primate retina that together comprise 90\% of all ganglion cells.          
137. **Learning Attractor Dynamics for Generative Memory** --*Yan Wu &middot; Tim Lillicrap &middot; Gregory Wayne &middot; Karol Gregor*
 > A central challenge faced by memory systems is the robust retrieval of a stored pattern in the presence of interference due to other stored patterns and noise. A theoretically well-founded solution to robust retrieval is given by attractor dynamics, which iteratively cleans up patterns during recall. However, incorporating attractor dynamics into modern deep learning systems poses difficulties: attractor basins are characterised by vanishing gradients, which are known to make training neural networks difficult.  In this work, we exploit recent advances in variational inference and avoid the vanishing gradient problem by training a generative distributed memory with a variational lower-bound-based Lyapunov function. The model is minimalistic with surprisingly few parameters. Experiments shows it converges to correct patterns upon iterative retrieval and achieves competitive performance as both a memory model and a generative model.
138. **Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures** --*Sergey Bartunov &middot; Adam Santoro &middot; Blake Richards &middot; Geoffrey E Hinton &middot; Tim Lillicrap*
 > The backpropagation of error algorithm (BP) is often said to be impossible to implement in a real brain. The recent success of deep networks in machine learning and AI, however, has inspired proposals for understanding how the brain might learn across multiple layers, and hence how it might implement or approximate BP. As of yet, none of these proposals have been rigorously evaluated on tasks where BP-guided deep learning has proved critical, or in architectures more structured than simple fully-connected networks. Here we present the first results on scaling up biologically motivated models of deep learning on datasets which need deep networks with appropriate architectures to achieve good performance. We present results on MNIST, CIFAR-10, and ImageNet and explore variants of the difference target-propagation (DTP) algorithm. We focus on DTP and introduce weight-transport-free variants modified to remove backpropagation from the penultimate layer, in both fully- and locally-connected architectures. These algorithms perform well for MNIST, but for CIFAR and ImageNet we find that DTP and variants perform significantly worse than BP, especially for network composed of locally connected units, opening questions about whether new architectures and algorithms are required to scale these approaches. Our results and implementation details help establish baselines for biologically motivated deep learning schemes going forward.
139. **Statistical and Computational Trade-Offs in Kernel K-Means** --*Daniele Calandriello &middot; Lorenzo Rosasco*
 > We investigate the efficiency of k-means  in terms of both statistical and computational requirements. More precisely,  we study  a Nystr\"om approach to kernel k-means. We analyze the statistical properties of the proposed method and show that it achieves  the same accuracy of exact kernel k-means with only a fraction of computations. Indeed, we prove under basic assumptions  that sampling  $\sqrt{n}$ Nystr\"om  landmarks allows to greatly reduce computations without incurring in any loss of accuracy. To the best of our knowledge this is the first result showing in this kind for unsupervised learning.  
140. **Co-regularized Alignment for Unsupervised Domain Adaptation** --*Abhishek Kumar &middot; Prasanna Sattigeri &middot; kahini wadhawan &middot; Leonid Karlinsky &middot; Rogerio S Feris &middot; Bill Freeman &middot; Gregory Wornell*
 > Deep neural networks, trained with large amount of labeled data, can fail to generalize well when tested with examples from a target domain whose distribution differs from the training data distribution, referred as the source domain. It can be expensive or even infeasible to obtain required amount of labeled data in all possible domains. Unsupervised domain adaptation sets out to address this problem, aiming to learn a good predictive model for the target domain using labeled examples from the source domain but only unlabeled examples from the target domain.  Domain alignment approaches this problem by matching the source and target feature distributions, and has been used as a key component in many state-of-the-art domain adaptation methods. However, matching the marginal feature distributions does not guarantee that the corresponding class conditional distributions will be aligned across the two domains. We propose co-regularized domain alignment for unsupervised domain adaptation, which constructs multiple diverse feature  spaces and aligns source and target distributions in each of them individually, while encouraging that alignments agree with each other with regard to the class predictions on the unlabeled target examples. The proposed method is generic and can be used to improve any domain adaptation method which uses domain alignment. We instantiate it in the context of a recent state-of-the-art method and  observe that it provides significant performance improvements on several domain adaptation benchmarks.
141. **Hardware Conditioned Policies for Multi-Robot Transfer Learning** --*Tao Chen &middot; Adithyavairavan Murali &middot; Abhinav Gupta*
 > Deep reinforcement learning could be used to learn dexterous robotic policies but it is extremely challenging to transfer them to new robots with vastly different hardware properties. It is also prohibitively expensive to learn a new policy from scratch for each robot hardware due to the high sample complexity of modern state-of-the-art algorithms. We propose a novel approach called \textit{Hardware Conditioned Policies} where we train a universal policy conditioned on a vector representation of robot hardware. We considered robots in simulation with varied dynamics, kinematic structure, kinematic lengths and degrees-of-freedom. First, we use the kinematic structure directly as the hardware encoding and show great zero-shot transfer to completely novel robots not seen during training. For robots with lower zero-shot success rate, we also demonstrate that fine-tuning the policy network is significantly more sample-efficient than training a model from scratch. In tasks where knowing the agent dynamics is crucial for success, we learn an embedding for robot hardware and show that policies conditioned on the encoding of hardware tend to generalize and transfer well. 
142. **Sample Complexity of Nonparametric Semi-Supervised Learning** --*Chen Dan &middot;   &middot; Bryon Aragam &middot; Pradeep Ravikumar &middot; Eric Xing*
 > We study the sample complexity of semi-supervised learning (SSL) and introduce new assumptions based on the mismatch between a mixture model learned from unlabeled data and the true mixture model induced by the (unknown) class conditional distributions. Under these assumptions, we establish an $\Omega(K\log K)$ labeled sample complexity bound without imposing parametric assumptions, where $K$ is the number of classes. Our results suggest that even in nonparametric settings it is possible to learn a near-optimal classifier using only a few labeled samples. Unlike previous theoretical work which focuses on binary classification, we consider general multiclass classification ($K>2$), which requires solving a difficult permutation learning problem. This permutation defines a classifier whose classification error is controlled by the Wasserstein distance between mixing measures, and we provide finite-sample results characterizing the behaviour of the excess risk of this classifier. Finally, we describe three algorithms for computing these estimators based on a connection to bipartite graph matching, and perform experiments to illustrate the superiority of the MLE over the majority vote estimator.
143. **SNIPER: Efficient Multi-Scale Training** --*Bharat Singh &middot; Mahyar Najibi &middot; Larry S Davis*
 > We present SNIPER, an algorithm for performing scale invariant training in instance level visual recognition tasks. Instead of processing every pixel in an image pyramid, SNIPER only processes context regions around ground-truth instances (referred to as chips) at the appropriate scale. For background sampling, these context-regions are generated using proposals extracted from a region proposal network trained with a short learning schedule. Hence, the number of chips generated per image during training adaptively changes based on the scene complexity. SNIPER only processes 30% more pixels compared to the commonly used single scale training at 800x1333 pixels on the COCO dataset. But, it also observes samples from extreme resolutions of the image pyramid, like 1400x2000 pixels. As SNIPER operates on low resolution chips (512x512 pixels), it can have a batch size as large as 20 on a single GPU even with a ResNet-101 backbone. Therefore it can benefit from batch-normalization during training without the need for synchronizing batch-normalization statistics across GPUs. SNIPER brings training of instance level recognition tasks like object detection closer to the protocol for image classification and suggests that the commonly accepted guideline that it is important to train on high resolution images for instance level visual recognition tasks might not be correct. Our implementation based on Faster-RCNN with a ResNet-101 backbone obtains an mAP of 47.6% on the COCO dataset for bounding box detection and can process 5 images per second with a single GPU. 
144. **The Effect of Network Width on the Performance of  Large-batch Training** --*Lingjiao Chen &middot; Hongyi Wang &middot; Paraschos Koutris &middot; Dimitris Papailiopoulos &middot; Jinman Zhao*
 > Distributed implementations of mini-batch stochastic gradient descent (SGD)  suffer from communication overheads, attributed to the high frequency of gradient updates inherent in small-batch training. Training with large batches can reduce these overheads; however it besets the convergence of the algorithm and the generalization performance.
145. **Representer Point Selection for Explaining Deep Neural Networks** --*Chih-Kuan  Yeh &middot; Joon Sik Kim &middot; Ian En-Hsu Yen &middot; Pradeep Ravikumar*
 > We propose to explain the predictions of a deep neural network, by pointing to the set of what we call representer points in the training set, for a given black-box test point prediction. Specifically, we show that we can decompose the pre-activation prediction of a neural network into a linear combination of activations of training points, with the weights corresponding to what we call representer values, which thus capture the importance of that training point on the learned parameters of the network. But it provides a deeper understanding of the network than simply training point influence: with positive representer values corresponding to excitatory training points, and negative values corresponding to inhibitory points, which as we show provides considerably more insight. Our method is also much more scalable, allowing for real-time feedback in a manner not feasible with influence functions. 
146. **The Importance of Sampling inMeta-Reinforcement Learning** --*Bradly Stadie &middot; Ge Yang &middot; Pieter Abbeel &middot; Yuhuai Wu &middot; Yan Duan &middot; Xi Chen &middot; Rein Houthooft &middot; Ilya Sutskever*
 > We interpret meta-reinforcement learning as the problem of learning how to quickly find a good sampling distribution in a new environment. This interpretation leads to the development of two new meta-reinforcement learning algorithms: E-MAML and E-$\text{RL}^2$. Results are presented on a new environment we call `Krazy World': a difficult high-dimensional gridworld which is designed to highlight the importance of correctly differentiating through sampling distributions in  meta-reinforcement learning. Further results are presented on a set of maze environments. We show E-MAML and E-$\text{RL}^2$ deliver better performance than baseline algorithms on both tasks.
147. **Confounding-Robust Policy Improvement** --*Angela Zhou &middot; Nathan Kallus*
 > We study the problem of learning personalized decision policies from observational data while accounting for possible unobserved confounding in the data-generating process. Unlike previous approaches which assume unconfoundedness, i.e. no unobserved confounders affected treatment assignment as well as outcome, we calibrate policy learning for realistic violations of this unverifiable assumption with uncertainty sets motivated by sensitivity analysis in causal inference. Our framework for confounding-robust policy improvement optimizes the minimax regret of a candidate policy against a baseline or reference "status quo" policy, over a uncertainty set around nominal propensity weights. We prove that if the uncertainty set is well-specified, robust policy learning can do no worse than the baseline, and only improve if the data supports it. We characterize the adversarial subproblem and use efficient algorithmic solutions to optimize over parametrized spaces of decision policies such as logistic treatment assignment. We assess our methods on synthetic data and a large clinical trial, demonstrating that confounded selection can hinder policy learning and lead to unwarranted harm, while our robust approach guarantees safety and focuses on well-evidenced improvement.
150. **The Limit Points of (Optimistic) Gradient Descent in Min-Max Optimization** --*Constantinos Daskalakis &middot; Ioannis Panageas*
 > Motivated by applications in Optimization, Game Theory, and the training of Generative Adversarial Networks, the convergence properties of first order methods in min-max problems have received extensive study. It has been recognized that they may cycle, and there is no good understanding of their limit points when they do not. When they converge, do they converge to local min-max solutions? We characterize the limit points of two basic first order methods, namely Gradient Descent/Ascent (GDA) and Optimistic Gradient Descent Ascent (OGDA).  We show that both dynamics avoid unstable critical points for almost all initializations. Moreover, for small step sizes and under mild assumptions, the set of  {OGDA}-stable critical points is a superset of {GDA}-stable critical points, which is a superset of local min-max solutions (strict in some cases). The connecting thread is that the behavior of these dynamics can be studied from a dynamical systems perspective.
151. **Beyond Grids: Learning Graph Representations for Visual Recognition** --*Yin Li &middot; Abhinav Gupta*
 > We propose learning graph representations from 2D feature maps for visual recognition. Our method draws inspiration from region based recognition, and learns to transform a 2D image into a graph structure. The vertices of the graph define clusters of pixels ("regions"), and the edges measure the similarity between these clusters in a feature space. Our method further learns to propagate information across all vertices on the graph, and is able to project the learned graph representation back into 2D grids. Our graph representation facilitates reasoning beyond regular grids and can capture long range dependencies among regions. We demonstrate that our model can be trained from end-to-end, and is easily integrated into existing networks. Finally, we evaluate our method on three challenging recognition tasks: semantic segmentation, object detection and object instance segmentation. For all tasks, our method outperforms state-of-the-art methods.
152. **PAC-Bayes bounds for stable algorithms with instance-dependent priors** --*Omar Rivasplata &middot; Csaba Szepesvari &middot; John S Shawe-Taylor &middot; Emilio Parrado-Hernandez &middot; Shiliang Sun*
 > PAC-Bayes bounds have been proposed to get risk estimates based on a training sample. In this paper the PAC-Bayes approach is combined with stability of the hypothesis learned by a Hilbert space valued algorithm. The PAC-Bayes setting is used with a Gaussian prior centered at the expected output. Thus a novelty of our paper is using priors defined in terms of the data-generating distribution. Our main result estimates the risk of the randomized algorithm in terms of the hypothesis stability coefficients. We also provide a new bound for the SVM classifier, which is compared to other known bounds experimentally. Ours appears to be the first stability-based bound that evaluates to non-trivial values.
153. **Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition** --*Kuan Han &middot; Haiguang Wen &middot; Yizhen Zhang &middot;   &middot; Eugenio Culurciello &middot; Zhongming Liu*
 > Inspired by "predictive coding" - a theory in neuroscience, we develop a bi-directional and dynamical neural network with local recurrent processing, namely predictive coding network (PCN). Unlike any feedforward-only convolutional neural network, PCN includes both feedback connections, which carry top-down predictions, and feedforward connections, which carry bottom-up errors of prediction. Feedback and feedforward connections enable adjacent layers to interact locally and recurrently to refine representations towards minimization of layer-wise prediction errors. When unfolded over time, the recurrent processing gives rise to an increasingly deeper hierarchy of non-linear transformation, allowing a shallow network to dynamically extend itself into an arbitrarily deep network. We train and test PCN for image classification with SVHN, CIFAR and ImageNet datasets. Despite notably fewer layers and parameters, PCN achieves competitive performance compared to classical and state-of-the-art models. Further analysis shows that the internal representations in PCN converge over time and yield increasingly better accuracy in object recognition. Errors of top-down prediction also map visual saliency or bottom-up attention. This work takes us one step closer to bridging human and machine intelligence in vision.
155. **Watch Your Step: Learning Node Embeddings via Graph Attention** --*Sami Abu-El-Haija &middot; Bryan Perozzi &middot; Rami Al-Rfou &middot; Alexander Alemi*
 > Graph embedding methods represent nodes in a continuous vector space, preserving different types of relational information from the graph. There are many hyper-parameters to these methods (e.g. the length of a random walk) which have to be manually tuned for every graph. In this paper, we replace previously fixed hyper-parameters with trainable ones that we automatically learn via backpropagation.  In particular, we learn a novel attention model on the power series of the transition matrix, which guides the random walk to optimize an upstream objective. Unlike previous approaches to attention models, the method that we propose utilizes attention parameters exclusively on the data itself (e.g. on the random walk), and are not used by the model for inference. We experiment on link prediction tasks, as we aim to produce embeddings that best-preserve the graph structure, generalizing to unseen information. We improve state-of-the-art on a comprehensive suite of real world datasets including social, collaboration, and biological networks. Adding attention to random walks can reduce the error by 20\% to 45\% on datasets we attempted. We show that our learned attention parameters can vary significantly for different graphs, and correspond to the optimal choice of hyper-parameter if we manually tune existing methods.
156. **A Stein variational Newton method** --*Gianluca Detommaso*
 > Stein variational gradient descent (SVGD) was recently proposed as a general purpose nonparametric variational inference algorithm: it minimizes the Kullback–Leibler divergence between the target distribution and its approximation by implementing a form of functional gradient descent on a reproducing kernel Hilbert space [Liu &amp; Wang, NIPS 2016]. In this paper, we accelerate and generalize the SVGD algorithm by including second-order information, thereby approximating a Newton-like iteration in function space. We also show how second-order information can lead to more effective choices of kernel. We observe significant computational gains over the original SVGD algorithm in multiple test cases.
157. **Reducing Network Agnostophobia** --*Terrance Boult &middot; Akshay Raj Dhamija &middot; Manuel Günther*
 > Agnostophobia, the fear of the unknown, can be experienced by deep learning1engineers while applying their networks to real-world applications. Unfortunately, network behavior is not well defined for inputs far from its training. In an uncontrolled environment, networks face many instances which are not of interest to them and have to be rejected in order to avoid a false positive. This problem has previously been tackled by researchers by either a) thresholding softmax, which by construction must return one of the known classes, or b) using an additional background or garbage class. In this paper, we show that both of these approaches help, but are generally insufficient when previously unseen classes are encountered. We introduce a new evaluation metric which focuses on comparing the performance of multiple approaches in scenarios where unknowns are encountered. Our major contributions are our simple yet effective Entropic Openset, and Objectosphere losses, which similar to the current approaches train with negative samples. However, these novel losses are designed to maximize entropy for unknown inputs while also increasing separation in deep feature magnitude between known and unknown classes. Experiments on MNIST and CIFAR-10 show that our novel loss16is significantly better at dealing with unknown inputs from datasets such as letters, Not MNIST, Devanagari, and SVHN
158. **Quadrature-based features for kernel approximation** --*Marina Munkhoeva &middot; Yermek Kapushev &middot; Evgeny Burnaev &middot; Ivan Oseledets*
 > We consider the problem of improving kernel approximation via randomized feature maps. These maps arise as Monte Carlo approximation to integral representations of kernel functions and scale up kernel methods for larger datasets. Based on an efficient numerical integration technique, we propose a unifying approach that reinterprets the previous random features methods and extends to better estimates of the kernel approximation. We derive the convergence behavior and conduct an extensive empirical study that supports our hypothesis.
159. **Phase Retrieval Under a Generative Prior** --*Oscar Leong &middot; Paul Hand &middot; Vlad Voroninski*
 > We introduce a novel deep-learning inspired formulation of the \textit{phase retrieval problem}, which asks to recover a signal $y_0 \in \R^n$ from $m$ quadratic observations, under structural assumptions on the underlying signal. As is common in many imaging problems, previous methodologies have considered natural signals as being sparse with respect to a known basis, resulting in the decision to enforce a generic sparsity prior. However, these methods for phase retrieval have encountered possibly fundamental limitations, as no computationally efficient algorithm for sparse phase retrieval has been proven to succeed with fewer than $O(k^2\log n)$ generic measurements, which is larger than the theoretical optimum of $O(k \log n)$. In this paper, we sidestep this issue by considering a prior that a natural signal is in the range of a generative neural network $G : \R^k \rightarrow \R^n$.  We introduce an empirical risk formulation that has favorable global geometry for gradient methods, as soon as $m = O(k)$, under the model of a multilayer fully-connected neural network with random weights.  Specifically, we show that there exists a descent direction outside of a small neighborhood around the true $k$-dimensional latent code and a negative multiple thereof.  This formulation for structured phase retrieval thus benefits from two effects: generative priors can more tightly represent natural signals than sparsity priors, and this empirical risk formulation can exploit those generative priors at an information theoretically optimal sample complexity, unlike for a sparsity prior. We corroborate these results with experiments showing that exploiting generative models in phase retrieval tasks outperforms both sparse and general phase retrieval methods.
160. **Learning SMaLL Predictors** --*Vikas Garg &middot; Ofer Dekel &middot; Lin Xiao*
 > We introduce a new framework for learning in severely resource-constrained settings. Our technique delicately amalgamates the representational richness of multiple linear predictors with the sparsity of Boolean relaxations, and thereby yields classifiers that are compact, interpretable, and accurate. We provide a rigorous formalism of the learning problem, and establish fast convergence of the ensuing algorithm via relaxation to a minimax saddle point objective. We corroborate the theoretical foundations of our work with an extensive empirical evaluation. Our method,  Sparse Multiprototype Linear Learner (SMaLL), achieves state-of-the-art performance on several OpenML datasets.
161. **Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data** --*Ehsan Hajiramezanali &middot; Siamak  Zamani Dadaneh &middot; Alireza Karbalayghareh &middot; Mingyuan Zhou &middot; Xiaoning Qian*
 > Precision medicine aims for personalized prognosis and therapeutics by utilizing recent genome-scale high-throughput profiling techniques, including next-generation sequencing (NGS). However, translating NGS data faces several challenges. First, NGS count data are often overdispersed, requiring appropriate modeling. Second, compared to the number of involved molecules and system complexity, the number of available samples for studying complex disease, such as cancer, is often limited, especially considering disease heterogeneity. The key question is whether we may integrate available data from all different sources or domains to achieve reproducible disease prognosis based on NGS count data. In this paper, we develop a Bayesian Multi-Domain Learning (BMDL) model that derives domain-dependent latent representations of overdispersed count data based on hierarchical negative binomial factorization for accurate cancer subtyping even if the number of samples for a specific cancer type is small. Experimental results from both our simulated and NGS datasets from The Cancer Genome Atlas (TCGA) demonstrate the promising potential of BMDL for effective multi-domain learning without ``negative transfer'' effects often seen in existing multi-task learning and transfer learning methods. 
162. **Learning safe policies with expert guidance** --*Jiexi Huang &middot; Fa Wu &middot; Doina Precup &middot; Yang Cai*
 > We propose a framework for ensuring safe behavior of a reinforcement learning agent when the reward function may be difficult to specify. In order to do this, we rely on the existence of demonstrations from expert policies, and we provide a theoretical framework for the agent to optimize in the space of rewards consistent with its existing knowledge. We propose two methods to solve the resulting optimization: an exact ellipsoid-based method and a method in the spirit of the "follow-the-perturbed-leader" algorithm. Our experiments demonstrate the behavior of our algorithm in both discrete and continuous problems. The trained agent safely avoids states with potential negative effects while imitating the behavior of the expert in the other states.
163. **Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias** --*Abhinav Gupta &middot; Adithyavairavan Murali &middot; Dhiraj Gandhi &middot; Lerrel Pinto*
 > Data-driven approaches to solving robotic tasks have gained a lot of traction in recent years. However, most existing policies are trained on large-scale datasets collected in curated lab settings. If we aim to deploy these models in unstructured visual environments like people's homes, they will be unable to cope with the mismatch in data distribution. In such light, we present the first systematic effort in collecting a large dataset for robotic grasping in homes. First, to scale and parallelize data collection, we built a low cost mobile manipulator assembled for under 3K USD. Second, data collected using low cost robots suffer from noisy labels due to imperfect execution and calibration errors. To handle this, we develop a framework which factors out the noise as a latent variable. Our model is trained on 28K grasps collected in several houses under an array of different environmental conditions. We evaluate our models by physically executing grasps on a collection of novel objects in multiple unseen homes. The models trained with our home dataset showed a marked improvement of 43.7% over a baseline model trained with data collected in lab. Our architecture which explicitly models the latent noise in the dataset also performed 10% better than one that did not factor out the noise. We hope this effort inspires the robotics community to look outside the lab and embrace learning based approaches to handle inaccurate cheap robots.
164. **Evading the Adversary in Invariant Representation** --*Daniel Moyer &middot; Shuyang Gao &middot; Rob Brekelmans &middot; Aram Galstyan &middot; Greg Ver Steeg*
 > Representations of data that are invariant to changes in specified nuisance factors are useful for a wide range of problems: removing potential bias in prediction problems, controlling the effects of known confounders, and disentangling meaningful factors of variation. Unfortunately, learning representations that exhibit invariance to arbitrary nuisance factors yet remain useful for other tasks is challenging. Existing approaches cast the trade-off between task performance and invariance in an adversarial way, using an iterative minimax optimization. We show that adversarial training is unnecessary and sometimes counter-productive by casting invariant representation learning for various tasks as a single information-theoretic objective that can be directly optimized. We demonstrate that this approach matches or exceeds performance of state-of-the-art adversarial approaches for learning fair representations and for generative modeling with controllable transformations.
166. **Theoretical Linear Convergence of Unfolded ISTA and Its Practical Weights and Thresholds** --*Xiaohan Chen &middot;   &middot; Zhangyang Wang &middot; Wotao Yin*
 > In recent years, unfolding iterative algorithms as neural networks has been shown an empirical success in solving sparse recovery problems. However, its theoretical understanding is still immature, which prevents us from fully utilizing the power of neural networks. In this work, we study unfolded ISTA (Iterative Shrinkage Thresholding Algorithm) for sparse signal recovery. We introduce a weight structure that is necessary for asymptotic convergence to the true sparse signal. With this structure, unfolded ISTA can attain a linear convergence, which is better than the sublinear convergence of ISTA/FISTA in general cases. Furthermore, we propose to incorporate thresholding in the network to perform support selection, which is easy to implement and able to boost the convergence rate both theoretically and empirically. Extensive simulations, including sparse vector recovery and a compressive sensing experiment on real image data, corroborate our theoretical results and demonstrate their practical usefulness.
167. **Learning Compressed Transforms with Low Displacement Rank** --*Anna Thomas &middot; Albert Gu &middot; Tri Dao &middot; Atri Rudra &middot; Christopher Ré*
 > The low displacement rank (LDR) framework for structured matrices represents a matrix through two displacement operators and a low-rank residual. Existing use of LDR matrices in deep learning has applied fixed displacement operators encoding forms of shift invariance akin to convolutions. We introduce a rich class of LDR matrices with much more general displacement operators, and explicitly learn over both the operator and the low-rank component. This class generalizes several previous constructions while preserving compression and efficient computation. We prove bounds on the the VC dimension of multi-layer neural networks with structured weight matrices and show empirically that our compact parameterization can reduce the sample complexity of learning. When replacing weight layers in fully-connected, convolutional, and recurrent neural networks for image classification and language modeling tasks, our new classes consistently exceed the accuracy of existing compression approaches, and on some tasks even outperform fully-connected layers while using more than 20X fewer parameters. 
168. **SING: Symbol-to-Instrument Neural Generator** --*Alexandre Defossez &middot; Neil Zeghidour &middot; Nicolas Usunier &middot; Leon Bottou &middot; Francis Bach*
 > Recent progress in deep learning for audio synthesis opens the way to models that directly produce the waveform, shifting away from the traditional paradigm of relying on vocoders or MIDI synthesizers for speech or music generation. Despite their successes, current state-of-the-art neural audio synthesizers such as WaveNet and SampleRNN suffer from prohibitive training and inference times because they are based on autoregressive models that generate audio samples one at a time at a rate of 16kHz. In this work, we study the more computationally efficient alternative of generating the waveform frame-by-frame with large strides. We present a lightweight neural audio synthesizer for the original task of generating musical notes given desired instrument, pitch and velocity. Our model is trained end-to-end to generate notes from nearly 1000 instruments with a single decoder, thanks to a new loss function that minimizes the distances between the log spectrograms of the generated and target waveforms. On the generalization task of synthesizing notes for pairs of pitch and instrument not seen during training, the model is competitive in terms of perceptual quality to a state-of-the-art autoencoder based on WaveNet,  and is 85 times faster for training and 2,500 times faster for inference.
169. **Reversible Recurrent Neural Networks** --*Matthew MacKay &middot; Paul Vicol &middot; Jimmy Ba &middot; Roger Grosse*
 > Recurrent neural networks (RNNs) provide state-of-the-art performance in processing sequential data but are memory intensive to train, limiting the flexibility of RNN models which can be trained. Reversible RNNs---RNNs for which the hidden-to-hidden transition can be reversed---offer a path to reduce the memory requirements of training, as hidden states need not be stored and instead can be recomputed during backpropagation. We begin by arguing that perfectly reversible RNNs, which require no storage of the hidden activations, are fundamentally limited because they cannot forget information from their hidden state. We find that even if forgetting is allowed, the hidden-to-hidden transition can still be reversed by storing the forgotten information. Through efficient storage of this information, memory requirements of training RNNs are greatly reduced. Our method achieves roughly equivalent performance to traditional models while saving 5--15 times memory on language modeling and neural machine translation tasks.
170. **FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network** --*Venkata Aditya Kusupati &middot; Manish Singh &middot; Kush Bhatia &middot; Ashish Kumar &middot; Prateek Jain &middot; Manik Varma*
 > This paper develops the FastRNN and FastGRNN algorithms to address the twin RNN limitations of inaccurate training and inefficient prediction. Previous approaches have improved accuracy at the expense of increased prediction costs making them infeasible for resource-constrained and real-time applications. Unitary RNNs have increased accuracy somewhat by restricting the range of the state transition matrix's singular values but have also increased the model size as they required a larger number of hidden units to make up for the loss in expressive power. Gated RNNs have obtained state-of-the-art accuracies by adding extra parameters thereby resulting in even larger models. FastRNN addresses these limitations by developing a leaky integrator unit inspired peephole connection that does not constrain the range of the singular values explicitly and has only two extra scalar parameters. FastGRNN then extends the peephole to a gated architecture by reusing the RNN matrices in the gate to match state-of-the-art accuracies but with a 2-4x smaller model as compared to other gated architectures and with almost no overheads over a standard RNN. Further compression could be achieved by allowing FastGRNN's matrices to be low-rank, sparse and quantized without a significant loss in accuracy. Experiments on multiple benchmark datasets revealed that FastGRNN could make more accurate predictions with up to a 35x smaller model as compared to leading unitary and gated RNN techniques. FastGRNN's code can be publicly downloaded from~\citep{anonymous}.
171. **Efficient High Dimensional Bayesian Optimization with Additivity and Quadrature Fourier Features** --*Mojmir Mutny &middot; Andreas Krause*
 > We develop an efficient and provably no-regret Bayesian optimization (BO) algorithm for optimization of black-box functions in high dimensions. We assume a generalized additive model with possibly overlapping variable groups. When the groups do not overlap, we are able to provide the first provably no-regret \emph{polynomial time} (in the number of evaluations of the acquisition function) algorithm for solving high dimensional BO. To make the optimization efficient and feasible, we introduce a novel deterministic Fourier Features approximation based on numerical integration with detailed analysis for the squared exponential kernel. The error of this approximation decreases \emph{exponentially} with the number of features, and allows for a precise approximation of both posterior mean and variance. In addition, the kernel matrix inversion improves in its complexity from cubic to essentially linear in the number of data points measured in basic arithmetic operations.
172. **A Structured Prediction Approach for Label Ranking** --*Anna Korba &middot; Alexandre Garcia &middot; Florence d'Alché-Buc*
 > We propose a novel label ranking method based on the framework of structured prediction, more specifically output kernel regression, which usually solves a supervised learning problem in two steps: the regression step in a well-chosen feature space and the pre-image step. We use specific feature maps/embeddings for ranking data, which convert any ranking/permutation into a vector representation. These embeddings are all well-tailored for our approach, either by resulting in consistent estimators, or by solving trivially the pre-image problem which is often the bottleneck in structured prediction. We also propose their natural extension the case of partial rankings and prove their efficiency on real-world datasets.
173. **Inferring Latent Velocities from Weather Radar Data using Gaussian Processes** --*Rico Angell &middot; Daniel Sheldon*
 > Archived data from the US network of weather radars hold detailed information about bird migration over the last 25 years, including very high-resolution partial measurements of velocity. Historically, most of this spatial resolution is discarded and velocities are summarized at a very small number of locations due to modeling and algorithmic limitations. This paper presents a Gaussian process (GP) model to reconstruct high-resolution full velocity fields across the entire US. The GP faithfully models all aspects of the problem in a single joint framework, including spatially random velocities, partial velocity measurements, station-specific geometries, measurement noise, and an ambiguity known as aliasing. We develop fast inference algorithms based on the FFT; to do so, we employ a creative use of Laplace's method to sidestep the fact that the kernel of the joint process is non-stationary.
174. **Wavelet regression and additive models for irregularly spaced data** --*Asad Haris &middot; Ali Shojaie &middot; Noah Simon*
 > We present a novel approach for nonparametric regression using wavelet basis functions. Our proposal, \name, can be applied to non-equispaced data with sample size not necessarily a power of 2. We develop an efficient proximal gradient descent algorithm for computing the estimator and establish adaptive minimax convergence rates. The main appeal of our approach is that it naturally extends to additive and sparse additive models for a potentially large number of covariates. We prove minimax optimal convergence rates under a weak compatibility condition for sparse additive models. The compatibility condition holds when we have a small number of covariates; in addition, we establish convergence rates for when the condition is not met. We complement our theoretical results with empirical studies comparing \name\ to existing methods.
176. **Unsupervisedly Learned Latent Graphs as Transferable Representations** --*Zhilin Yang &middot; Zhizhen Zhao &middot; Bhuwan Dhingra &middot; Kaiming He &middot; William W Cohen &middot; Ruslan Salakhutdinov &middot; Yann LeCun*
 > Modern deep transfer learning approaches have mainly focused on learning \emph{generic} feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different types of input embeddings or features.
177. **Policy-Conditioned Uncertainty Sets for Robust Markov Decision Processes** --*Andrea Tirinzoni &middot; Marek Petrik &middot; Xiangli Chen &middot; Brian Ziebart*
 > What policy should be employed in a Markov decision process with uncertain parameters? Robust optimization answer to this question is to use rectangular uncertainty sets, which independently reflect available knowledge about each state, and then obtains a decision policy that maximizes expected reward for the worst-case decision process parameters from these uncertainty sets. While this rectangularity is convenient computationally and leads to tractable solutions, it often produces policies that are too conservative in practice, and does not facilitate knowledge transfer between portions of the state space or across related decision processes. In this work, we propose non-rectangular uncertainty sets that bound marginal moments of state-action features defined over entire trajectories through a decision process. This enables generalization to different portions of the state space while retaining appropriate uncertainty of the decision process. We develop algorithms for solving the resulting robust decision problems, which reduce to finding an optimal policy for a mixture of decision processes, and demonstrate the benefits of our approach experimentally.
178. **Adaptive Path-Integral Approach to Representation Learning and Planning for Dynamical Systems** --*Jung-Su Ha &middot; Young-Jin Park &middot; Hyeok-Joo Chae &middot; Soon-Seo Park &middot; Han-Lim Choi*
 > We present a representation learning algorithm that learns a low-dimensional latent dynamical system from high-dimensional sequential raw data, e.g., video. The framework builds upon recent advances in amortized inference methods that use both an inference network and a refinement procedure to output samples from a variational distribution given an observation sequence, and takes advantage of the duality between control and inference to approximately solve the intractable inference problem using the path integral control approach. The learned dynamical model can be used to predict and plan the future states; we also present the efficient planning method that exploits the learned low-dimensional latent dynamics. Numerical experiments show that the proposed path-integral control based variational inference method leads to tighter lower bounds in statistical model learning of sequential data.
179. **Improving Neural Program Synthesis with Inferred Execution Traces** --*Eui Chul Shin &middot; Illia Polosukhin &middot; Dawn Song*
 > The task of program synthesis, or automatically generating programs that are consistent with a provided specification, remains a challenging task in artificial intelligence. As in other fields of AI, deep learning-based end-to-end approaches have made great advances in program synthesis. However, more so than other fields such as computer vision, program synthesis provides greater opportunities to explicitly exploit structured information such as execution traces, which contain a superset of the information input/output pairs. While they are highly useful for program synthesis, as execution traces are more difficult to obtain than input/output pairs, we use the insight that we can split the process into two parts: infer the trace from the input/output example, then infer the program from the trace. This simple modification leads to state-of-the-art results in program synthesis in the Karel domain, improving accuracy to 81.3% from the 77.12% of prior work.
180. **Distributed Multitask Reinforcement Learning with Quadratic Convergence** --*Rasul Tutunov &middot; Dongho Kim &middot; Haitham Bou Ammar*
 > Multitask reinforcement learning (MTRL) suffers from scalability issues when the number of tasks or trajectories grows large. The main reason behind this drawback is the reliance on centeralised solutions. Recent methods exploited the connection between MTRL and general consensus to propose scalable solutions. These methods, however, suffer from two drawbacks. First, they rely on predefined objectives, and, second, exhibit linear convergence guarantees. In this paper, we improve over state-of-the-art by deriving multitask reinforcement learning from a variational inference perspective. We then propose a novel distributed solver for MTRL with quadratic convergence guarantees.
181. **Balanced Policy Evaluation and Learning** --*Nathan Kallus*
 > We present a new approach to the problems of evaluating and learning personalized decision policies from observational data of past contexts, decisions, and outcomes. Only the outcome of the enacted decision is available and the historical policy is unknown. These problems arise in personalized medicine using electronic health records and in internet advertising. Existing approaches use inverse propensity weighting (or, doubly robust versions) to make historical outcome (or, residual) data look like it were generated by a new policy being evaluated or learned. But this relies on a plug-in approach that rejects data points with a decision that disagrees with the new policy, leading to high variance estimates and ineffective learning. We propose a new, balance-based approach that too makes the data look like the new policy but does so directly by finding weights that optimize for balance between the weighted data and the target policy in the given, finite sample, which is equivalent to minimizing worst-case or posterior conditional mean square error. Our policy learner proceeds as a two-level optimization problem over policies and weights. We demonstrate that this approach markedly outperforms existing ones both in evaluation and learning, which is unsurprising given the wider support of balance-based weights. We establish extensive theoretical consistency guarantees and regret bounds that support this empirical success. 
182. **Statistical Recurrent Models on Manifold valued Data** --*Rudrasis Chakraborty &middot; Chun-Hao Yang &middot; Xingjian Zhen &middot; Monami Banerjee &middot; Derek Archer &middot; David Vaillancourt &middot; Vikas Singh &middot; Baba Vemuri*
 > In a number of disciplines, the data (e.g., graphs, manifolds) to be analyzed are non-Euclidean in nature.   Geometric deep learning corresponds to techniques that generalize deep neural network models to such non-Euclidean spaces. Several   recent papers have shown how convolutional neural networks (CNNs) can be extended to learn with graph-based data.   In this work, we study the setting where the data (or measurements) are ordered, longitudinal or temporal in nature and live on a Riemannian manifold -- this setting is common in a variety of problems in statistical machine learning, vision, and medical imaging. We show how recurrent statistical recurrent network models can be defined in such spaces. We give an efficient algorithm and conduct a rigorous analysis of its statistical properties. We perform extensive numerical experiments showing competitive performance with state of the art methods but with far fewer parameters. We also show applications to a statistical analysis task in brain imaging, a regime where deep neural network models have only been utilized in limited ways.
183. **Exploration in Structured Reinforcement Learning** --*Jungseul Ok &middot; Damianos Tranos &middot; Alexandre Proutiere*
 > We address reinforcement learning problems with finite state and action spaces where the underlying MDP has some known structure that could be potentially exploited to minimize the exploration of suboptimal (state, action) pairs. For any arbitrary structure, we derive problem-specific regret lower bounds satisfied by any learning algorithm. These lower bounds are made explicit for unstructured MDPs and for those whose transition probabilities and average reward function are Lipschitz continuous w.r.t. the state and action. For Lipschitz MDPs, the bounds are shown not to scale with the sizes S and A of the state and action spaces, i.e., they are smaller than c log T where T is the time horizon and the constant c only depends on the Lipschitz structure, the span of the bias function, and the minimal action sub-optimality gap. This contrasts with unstructured MDPs where the regret lower bound typically scales as SA logT. We deviseDEL (DirectedExploration Learning), an algorithm that matches our regret lower bounds. We further simplify the algorithm for Lipschitz MDPs, and show that the simplified version is still able to efficiently exploit the structure.
184. **Differential Privacy for Growing Databases** --*Rachel Cummings &middot; Sara Krehbiel &middot; Kevin Lai &middot; Uthaipon Tantipongpipat*
 > The large majority of differentially private algorithms focus on the static setting, where queries are made on an unchanging database. This is unsuitable for the myriad applications involving databases that grow over time. To address this gap in the literature, we consider the dynamic setting, in which new data arrive over time. Previous results in this setting have been limited to answering a single non-adaptive query repeatedly as the database grows. In contrast, we provide tools for richer and more adaptive analysis of growing databases. Our first contribution is a novel modification of the private multiplicative weights algorithm, which provides accurate analysis of exponentially many adaptive linear queries (an expressive query class including all counting queries) for a static database. Our modification maintains the accuracy guarantee of the static setting even as the database grows without bound. Our second contribution is a set of general results which show that many other private and accurate algorithms can be immediately extended to the dynamic setting by rerunning them at appropriate points of data growth with minimal loss of accuracy, even when data growth is unbounded.
186. **Group Equivariant Capsule Networks** --*Jan E. Lenssen &middot; Matthias Fey &middot; Pascal Libuschewski*
 > We present group equivariant capsule networks, a framework to introduce guaranteed equivariance and invariance properties to the capsule network idea. We restrict pose vectors and learned transformations to be elements of a group, which allows us to prove equivariance of pose vectors and invariance of activations under application of the group law. Requirements are a modified spatial aggregation method for capsules and a generic routing by agreement algorithm with abstract rules, which we both present in this work. Further, we connect our equivariant capsule networks with work from the field of group convolutional networks, which consist of convolutions that are equivariant under applications of the group law. Through this connection, we are able to provide intuitions of how both methods relate and are able to combine both approaches in one deep neural network architecture, combining the strengths from both fields. The resulting framework allows sparse evaluation of feature maps defined over groups, provides control over specific equivariance and invariance properties and uses routing by agreement instead of pooling operations. It provides interpretable and equivariant representation vectors as output capsules, which disentangle evidence of object existence from its pose.
187. **Data Amplification: A Unified and Competitive Approach to Property Estimation** --*Yi HAO &middot; Alon Orlitsky &middot; Ananda Theertha Suresh &middot; Yihong Wu*
 > Estimating properties of discrete distributions is a fundamental problem in statistical learning. We design the first unified, linear-time, competitive, property estimator that for a wide class of properties and for all underlying distributions uses just $2n$ samples to achieve the performance attained by the empirical estimator with $n\sqrt{\log n}$ samples. This provides off-the-shelf, distribution-independent,  ``amplification'' of the amount of data available relative to common-practice estimators.   We illustrate the estimator's practical advantages by comparing it to existing estimators for a wide variety of properties and distributions. In most cases, its performance with $n$ samples is even as good as that of the empirical estimator with $n\log n$ samples, and for essentially all properties, its performance is comparable to that of the best existing estimator designed specifically for that property.
188. **Reinforcement Learning of Theorem Proving** --*Josef Urban &middot; Cezary Kaliszyk &middot; Henryk Michalewski &middot; Mirek Olšák*
 > We introduce a theorem proving algorithm that uses practically no domain heuristics for guiding its connection-style proof search. Instead, it runs many Monte-Carlo simulations guided by reinforcement learning from previous proof attempts. We produce several versions of the prover, parameterized by different learning and guiding algorithms. The strongest version of the system is trained on a large corpus of mathematical problems and evaluated on previously unseen problems. The trained system solves within the same number of inferences over 40% more problems than a baseline prover, which is an unusually high improvement in this hard AI domain. To our knowledge this is the first time reinforcement learning has been convincingly applied to solving general mathematical problems on a large scale.
189. **Legendre Decomposition for Tensors** --*Mahito Sugiyama &middot; Hiroyuki Nakahara &middot; Koji Tsuda*
 > We present a novel nonnegative tensor decomposition method, called Legendre decomposition, which factorizes an input tensor into a multiplicative combination of parameters. Thanks to the well-developed theory of information geometry, the reconstructed tensor is unique and always minimizes the KL divergence from an input tensor. We empirically show that Legendre decomposition can more accurately reconstruct tensors than nonnegative CP and Tucker decomposition.
190. **A flexible neural representation for physics prediction** --*Damian Mrowca &middot; Chengxu Zhuang &middot; Elias Wang &middot; Nick Haber &middot; Li Fei-Fei &middot; Josh Tenenbaum &middot; Daniel Yamins*
 > Humans have a remarkable capacity to understand the physical dynamics of objects in their environment, flexibly capturing complex structures and interactions at multiple levels of detail. <br /> Inspired by this ability, we propose a hierarchical particle-based object representation that covers a wide variety of types of three-dimensional objects, including both arbitrary rigid geometrical shapes and deformable materials. <br /> We then describe the Hierarchical Relation Network (HRN), an end-to-end differentiable neural network based on hierarchical graph convolution, that learns to predict physical dynamics in this representation.  Compared to other neural network baselines, the HRN accurately handles complex collisions and nonrigid deformations, generating plausible dynamics predictions at long time scales in novel settings, and scaling to large scene configurations. These results demonstrate an architecture with the potential to form the basis of next-generation physics predictors for use in computer vision, robotics, and quantitative cognitive science.
191. **Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs** --*Timur Garipov &middot; Pavel Izmailov &middot; Dmitrii Podoprikhin &middot; Dmitry Vetrov &middot; Andrew G Wilson*
 > The loss functions of deep neural networks are complex and their geometric properties are not well understood.  We show that the optima of these complex loss functions are in fact connected by simple curves, over which training and test accuracy are nearly constant.  We introduce a training procedure to discover these high-accuracy pathways between modes.  Inspired by this new geometric insight, we also propose a new ensembling method entitled Fast Geometric Ensembling (FGE). Using FGE we can train high-performing ensembles in the time required to train a single model.  We achieve improved performance compared to the recent state-of-the-art Snapshot Ensembles, on  CIFAR-10, CIFAR-100, and ImageNet.
192. **Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels** --*Zhilu Zhang &middot; Mert Sabuncu*
 > Deep neural networks (DNNs) have achieved tremendous success in a variety of applications across many disciplines. Yet, their superior performance comes with the expensive cost of requiring correctly annotated large-scale datasets. Moreover, due to DNNs' rich capacity, errors in training labels can hamper performance. To combat this problem, mean absolute error (MAE) has recently been proposed as a noise-robust alternative to the commonly-used categorical cross entropy (CCE) loss. However, as we show in this paper, MAE can perform poorly with DNNs and large-scale datasets. Here, we present a theoretically grounded set of noise-robust loss functions that can be seen as a generalization of MAE and CCE. Proposed loss functions can be readily applied with any existing DNN architecture and algorithm, while yielding good performance in a wide range of noisy label scenarios. We report results from experiments conducted with CIFAR-10, CIFAR-100 and FASHION-MNIST datasets and synthetically generated noisy labels. 
193. **A Bayesian Nonparametric View on Count-Min Sketch** --*Diana Cai &middot; Michael Mitzenmacher &middot; Ryan Adams*
 > The count-min sketch is a time- and memory-efficient randomized data structure that provides a point estimate of the number of times an item has appeared in a data stream.  The count-min sketch and related hash-based data structures are ubiquitous in systems that must track frequencies of data such as URLs, IP addresses, and language n-grams.  We present a Bayesian view on the count-min sketch, using the same data structure, but providing a posterior distribution over the frequencies that characterizes the uncertainty arising from the hash-based approximation.  In particular, we take a nonparametric approach and consider tokens generated from a from a Dirichlet process (DP) random measure, which allows for an unbounded number of unique tokens.  Using properties of the DP, we show that it is possible to straightforwardly compute posterior marginals of the unknown true counts and that the modes of these marginals recover the count-min sketch estimator, inheriting the associated probabilistic guarantees.  Using simulated data with known ground truth, we investigate the properties of these estimators.  Lastly, we also study a modified problem in which the observation stream consists of collections of tokens (i.e., documents) arising from a random measure drawn from a stable beta process.  This variant shares many of the convenient properties of the Dirichlet process construction, but also allows for power law scaling behavior in the number of unique tokens.
196. **Learning Plannable Representations with Causal InfoGAN** --*Aviv Tamar &middot; Pieter Abbeel &middot; Ge Yang &middot; Thanard Kurutach &middot; Stuart Russell*
 > We study the problem of long-horizon planning in dynamical systems with high-dimensional observations, such as images. We propose a framework for learning low-dimensional and structured representations of observations from a dynamical system, which can be used for planning with conventional AI planning algorithms. Our framework learns a generative model of sequential observations, where the generative process is induced by a transition in a low-dimensional \emph{planning model}, and an additional noise. By maximizing the mutual information between the generated observations and the transition in the planning model, we obtain a low-dimensional representation that best explains the causal nature of the data. Our framework can be used with planning models that comply with modern search-based planning algorithms, such as discrete binary representations. We show that our method can perform plausible planning of visual rope manipulation. 
198. **Orthogonally Decoupled Variational Gaussian Processes** --*Hugh Salimbeni &middot; Ching-An Cheng &middot; Byron Boots &middot; Marc Deisenroth*
 > Gaussian processes provide a powerful non-parametric framework for reasoning over functions. Despite appealing theories, its superlinear computational and memory complexities have presented a long-standing challenge. The state-of-the-art methods of sparse variational inference trade modeling accuracy with complexity. However, their complexities still scale superlinearly in the number of basis functions, so they can learn from large datasets only when a small model is used. Recently, a decoupled approach was proposed to remove the unnecessary coupling between the complexities of modeling the mean and the covariance functions. It achieves a linear complexity in the number of mean parameters, so an expressive posterior mean function can be modeled. While promising, this approach suffers from optimization difficulties due to ill-conditioning and non-convexity. In this work, we propose an alternative decoupled parametrization. It adopts an orthogonal basis in the mean function to model the residues that cannot be learned by the standard coupled approach. Therefore, our method extends, rather than replaces, the coupled approach to achieve strictly better performance. This construction admits a straightforward natural gradient update rule, so the structure of the information manifold that is lost during decoupling can be leveraged to speed up learning. Empirically, our algorithm demonstrates significantly faster convergence in multiple experiments.
202. **Estimators for Multivariate Information Measures in General Probability Spaces** --*Arman Rahimzamani &middot; Himanshu Asnani &middot; Pramod Viswanath &middot; Sreeram Kannan*
 > Information theoretic quantities play an important role in various settings in machine learning, including causality testing, structure inference in graphical models, time-series problems, feature selection as well as in providing privacy guarantees. A key quantity of interest is the mutual information and generalizations thereof, including conditional mutual information, multivariate mutual information, total correlation and directed information. While the aforementioned information quantities are well defined in arbitrary probability spaces, existing estimators employ a $\Sigma H$ method, which can only work in purely discrete space or purely continuous case since entropy (or differential entropy) is well defined only in that regime. In this paper, we define a general graph divergence measure ($\mathbb{GDM}$), generalizing the aforementioned information measures and we construct a novel estimator via a coupling trick that directly estimates these multivariate information measures using the Radon-Nikodym derivative. These estimators are proven to be consistent in a general setting which includes several cases where the existing estimators fail, thus providing the only known estimators for the following settings: (1) the data has some discrete and some continuous valued components (2) some (or all) of the components themselves are discrete-continuous \textit{mixtures} (3) the data is real-valued but does not have a joint density on the entire space, rather is supported on a low-dimensional manifold. We show that our proposed estimators significantly outperform known estimators on synthetic and real datasets. 
205. **Minimax Rates in Contextual Partial Monitoring** --*Alan Malek &middot; Ali Jadbabaie &middot; Alexander Rakhlin*
 > We generalize the finite partial monitoring problem to the contextual setting. Partial monitoring allows learning even when the loss of the chosen action is not observed. In the non-contextual problem, the minimax regret is known to be O(T^{2/3}) if a global observability condition is satisfied and improves to O(\sqrt{T}) under a stronger local observability condition. Perhaps surprisingly, we show that the same characterization does not hold in the contextual case and a stronger notion of pairwise observability is necessary for O(\sqrt{T}) minimax regret. In particular, we provide a lower bound of O(T^{2/3}) for any non-pairwise observable game, which applies to locally observable games. We also propose two algorithms in the adversarial setting. The first requires a finite policy class but allows for arbitrary contexts and can be tuned to obtain the optimal O(\sqrt{T}) rate in pairwise observable settings or the optimal O(T^{2/3}) rate otherwise. The second allows for arbitrary policy classes with an empirical risk minimization oracle but requires i.i.d. contexts; we also show an optimal O(T^{2/3}) upper bound and an efficient implementation using only a constant number of oracle calls per round.
206. **Compact Representation of Uncertainty In Clustering** --*Craig Greenberg &middot; Nicholas Monath &middot; Ari Kobren &middot; Patrick Flaherty &middot; Andrew McGregor &middot; Andrew McCallum*
 > For many classic structured prediction problems, probability distributions over the dependent variables can be efficiently computed using widely-known algorithms and data structures (such as forward-backward, and its corresponding trellis for exact probability distributions in Markov models). However, we know of no previous work studying efficient representations of exact distributions over clusterings.  This paper presents definitions and proofs for a dynamic-programming inference procedure that computes the partition function, the marginal probability of a cluster, and the MAP clustering---all exactly.  Rather than the $N^{th}$ Bell number, these exact solutions take time and space proportional to the substantially smaller powerset of $N$.  Indeed, we reduce the best known time complexity for this problem by a factor of $N$.  While still large, this previously unknown result is intellectually interesting in its own right, makes feasible exact inference for important real-world small data applications (such as medicine), and provides a natural stepping stone towards sparse-trellis approximations that enable further scalability (which we also explore). In experiments, we demonstrate the superiority of our approach over approximate methods in analyzing real-world gene expression data used in cancer treatment.
207. **Randomized Prior Functions for Deep Reinforcement Learning** --*Ian Osband &middot; John S Aslanides &middot; Albin Cassirer*
 > Dealing with uncertainty is essential for efficient reinforcement learning. There is a growing literature on uncertainty estimation for deep learning from fixed datasets, but many of the most popular approaches are poorly-suited to sequential decision problems. Other methods, such as bootstrap sampling, have no mechanism for uncertainty that does not come from the observed data. We highlight why this can be a crucial shortcoming and propose a simple remedy through addition of a randomized untrainable `prior' network to each ensemble member. We prove that this approach is efficient with linear representations, provide simple illustrations of its efficacy with nonlinear representations and show that this approach scales to large-scale problems far better than previous attempts.
208. **Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects** --*Adam Kosiorek &middot; Hyunjik Kim &middot; Yee Whye Teh &middot; Ingmar Posner*
 > We present Sequential Attend, Infer, Repeat (SQAIR), an interpretable deep generative model for image sequences. It can reliably discover and track objects through the sequence; it can also conditionally generate future frames, thereby simulating expected motion of objects.  This is achieved by explicitly encoding object numbers, locations and appearances in the latent variables of the model. SQAIR retains all strengths of its predecessor, Attend, Infer, Repeat (AIR, Eslami et. al. 2016), including unsupervised learning, made possible by inductive biases present in the model structure. We use a moving multi-\textsc{mnist} dataset to show limitations of AIR in detecting overlapping or partially occluded objects, and show how \textsc{sqair} overcomes them by leveraging temporal consistency of objects. Finally, we also apply SQAIR to real-world pedestrian CCTV data, where it learns to reliably detect, track and generate walking pedestrians with no supervision.
210. **A statistical model for graph partitioning with high-dimensional covariates** --*Yash Deshpande &middot; Subhabrata Sen &middot; Andrea Montanari &middot; Elchanan Mossel*
 > We provide the first information theoretical tight analysis for inference of latent community structure given a sparse graph along with high dimensional node covariates, correlated with the same latent communities. Our work bridges recent theoretical breakthroughs in detection of latent community structure without nodes covariates and a large body of empirical work using diverse heuristics for combining node covariates with graphs for inference. The tightness of our analysis implies in particular, the information theoretical necessity of combining the different sources of information.  Our analysis holds for networks of large degrees as well as for a Gaussian version of the model. 
211. **Neural Tangent Kernel: Convergence and Generalization in Neural Networks** --*Arthur Jacot-Guillarmod &middot; Clement Hongler &middot; Franck Gabriel*
 > At initialization, artificial neural networks (ANNs) are equivalent to Gaussian processes in the infinite-width limit, thus connecting them to kernel methods. We prove that the evolution of an ANN during training can also be described by a kernel: during gradient descent on the parameters of an ANN, the network function (which maps input vectors to output vectors) follows the so-called kernel gradient associated with a new object, which we call the Neural Tangent Kernel (NTK). This kernel is central to describe the generalization features of ANNs. While the NTK is random at initialization and varies during training, in the infinite-width limit it converges to an explicit limiting kernel and stays constant during training. This makes it possible to study the training of ANNs in function space instead of parameter space. Convergence of the training can then be related to the positive-definiteness of the limiting NTK.
212. **Adversarial Multiple Source Domain Adaptation** --*Han Zhao &middot; Shanghang Zhang &middot; Guanhang Wu &middot;  José M. F. Moura &middot; Joao P Costeira &middot; Geoffrey Gordon*
 > While domain adaptation has been actively researched, most algorithms focus on the single-source-single-target adaptation setting. In this paper we propose new generalization bounds and algorithms under both classification and regression settings for unsupervised multiple source domain adaptation. Our theoretical analysis naturally leads to an efficient learning strategy using adversarial neural networks: we show how to interpret it as learning feature representations that are invariant to the multiple domain shifts while still being discriminative for the learning task. To this end, we propose multisource domain adversarial networks (MDAN) that approach domain adaptation by optimizing task-adaptive generalization bounds. To demonstrate the effectiveness of MDAN, we conduct extensive experiments showing superior adaptation performance on both classification and regression problems: sentiment analysis, digit classification, and vehicle counting. 
214. **An Event-Based Framework for Task Specification and Control** --*Justin Fu &middot; Sergey Levine &middot; Dibya Ghosh &middot; Larry Yang &middot; Avi Singh*
 > The design of a reward function often poses a major practical challenge to real-world applications of reinforcement learning. Approaches such as inverse reinforcement learning attempt to overcome this challenge, but require expert demonstrations, which can be difficult or expensive to obtain in practice. We propose inverse event-based control, which generalizes inverse reinforcement learning methods to cases where full demonstrations are not needed, such as when only samples of desired goal states are available. Our method is grounded in an alternative perspective on control and reinforcement learning, where an agent's goal is to maximize the probability that one or more events will happen at some point in the future, rather than maximizing cumulative rewards. We demonstrate the effectiveness of our methods on continuous control tasks, with a focus on high-dimensional observations like images where rewards are hard or even impossible to specify.
215. **Co-teaching: Robust Training Deep Neural Networks with Extremely Noisy Labels** --*Bo Han &middot; Quanming Yao &middot; Xingrui Yu &middot; Gang Niu &middot; Miao Xu &middot; Weihua Hu &middot; Ivor Tsang &middot; Masashi Sugiyama*
 > It is challenging to train deep neural networks robustly with noisy labels, as the capacity of deep neural networks is so high that they can totally over-fit on these noisy labels. In this paper, motivated by the memorization effects of deep networks, which shows networks fit clean instances first and then noisy ones, we present a new paradigm called ``\textit{Co-teaching}'' combating with noisy labels. We train two networks simultaneously. First, in each mini-batch data, each network filters noisy instances based on memorization effects. Then, it teaches the remained instances to its peer network for updating the parameters. Empirical results on benchmark datasets demonstrate that, the robustness of deep learning models trained by Co-teaching approach is much superior than that of state-of-the-art methods.
217. **Adversarial Regularizers in Inverse Problems** --*Sebastian Lunz &middot; Carola Schoenlieb &middot; Ozan Öktem*
 > Inverse Problems in medical imaging and computer vision are traditionally solved using purely model-based methods. Among those variational regularization models are one of the most popular approaches. We propose a new framework for applying data-driven approaches to inverse problems, using a neural network as a regularization functional. The network learns to discriminate between the distribution of ground truth images and the distribution of unregularized reconstructions. Once trained, the network is applied to the inverse problem by solving the corresponding variational problem. Unlike other data-based approaches for inverse problems, the algorithm can be applied even if only unsupervised training data is available. Experiments demonstrate the potential of the framework for denoising on the BSDS dataset and for computer tomography reconstruction on the LIDC dataset.
219. **Generalisation of structural knowledge in the Hippocampal-Entorhinal system** --*James Whittington &middot; Timothy Muller &middot; Caswell Barry &middot; Tim Behrens*
 > A central problem to understanding intelligence is the concept of generalisation. This allows previously learnt structure to be exploited to solve tasks in novel situations differing in their particularities. We take inspiration from neuroscience, specifically the Hippocampal-Entorhinal system (containing place and grid cells), known to be important for generalisation. We propose that to generalise structural knowledge, the representations of the structure of the world, i.e. how entities in the world relate to each other, need to be separated from representations of the entities themselves. We show, under these principles, artificial neural networks embedded with hierarchy and fast Hebbian memory, can learn the statistics of memories, generalise structural knowledge, and also exhibit neuronal representations mirroring those found in the brain. We experimentally support model assumptions, showing a preserved relationship between grid and place cells across environments.
221. **Teaching Inverse Reinforcement Learners via Features and Demonstrations** --*Luis Haug &middot; Sebastian Tschiatschek &middot; Adish Singla*
 > Inverse reinforcement learning (IRL) algorithms enable a learning agent to train a desired behaviour by first estimating the reward function optimized by demonstrations provided by an expert, and then find an optimal policy for that estimated reward function. The typical assumption is that the learning agent knows the features that the true reward function depends on. In this paper, we study IRL in the setting where this is not the case, i.e., where there is a mismatch between the world views of the learner and the expert. We introduce a natural quantity, the teaching risk, which measures the potential suboptimality of policies that look optimal to the learner in this setting. We show that bounds on the teaching risk garantuee that the learner is able to find a near-optimal policy using variants of standard IRL algorithms. Based on these findings, we suggest a teaching scheme in which the expert can update the learner’s world view in order to decrease the teaching risk, and thus ultimately enable her to find a near-optimal policy.
222. **Continuity vs. Injectivity in Dimensionality Reduction: a Quantitative Topology View** --*Yik Chau Lui &middot; Gavin Weiguang Ding &middot; Ruitong Huang &middot; Robert McCann*
 > In this paper,  we investigate Dimensionality reduction (DR) maps in an information retrieval setting from a quantitative topology point of view. In particular,  we show that no DR maps can achieve perfect precision and perfect recall simultaneously.  Thus a continuous DR map must have imperfect precision. We further prove an upper bound on the precision of Lipschitz continuous DR maps. While precision is a natural measure in an information retrieval setting,  it does not measure `how' wrong the retrieved data is. We therefore propose a new measure based on Wasserstein distance that comes with theoretical guarantee in terms of a lower bound.   A key technical step in our proofs is a particular optimization problem of the $L_2$-Wasserstein distance over a constrained set of distributions. We provide a complete solution to this optimization problem,  which can be of independent interest on the technical side. Lastly, simulation confirms the tightness of the bound.
223. **Deep Poisson gamma dynamical systems** --*  &middot; Bo Chen &middot; Hao Zhang &middot; Mingyuan Zhou*
 > We develop deep Poisson-gamma dynamical systems (DPGDS) to model sequentially observed multivariate count data, improving previously proposed models by not only mining deep hierarchical latent structure from the data, but also capturing both first-order and long-range temporal dependencies. Using sophisticated but simple-to-implement data augmentation techniques, we derived closed-form Gibbs sampling update equations by first backward and upward propagating auxiliary latent counts, and then forward and downward sampling latent variables. Moreover, we develop stochastic gradient MCMC inference that is scalable to very long multivariate count time series. Experiments on both synthetic and a variety of real-world data demonstrate that the proposed model not only has excellent predictive performance, but also provides highly interpretable multilayer latent structure to represent hierarchical and temporal information propagation.
224. **Data-dependent PAC-Bayes priors via differential privacy** --*Gintare Karolina Dziugaite &middot; Daniel Roy*
 > The Probably Approximately Correct (PAC) Bayes framework (McAllester, 1999) can incorporate knowledge about the learning algorithm and (data) distribution through the use of distribution-dependent priors, yielding tighter generalization bounds on data-dependent posteriors. Using this flexibility, however, is difficult, especially when the data distribution is presumed to be unknown. We show how an ε-differentially private data-dependent prior yields a valid PAC-Bayes bound, and then show how non-private mechanisms for choosing priors obtain the same generalization bound provided they are close in 2-Wasserstein distance to an ε-differentially private mechanism. As an application of this result, we show that a Gaussian prior mean chosen via stochastic gradient Langevin dynamics (SGLD; Welling and Teh, 2011) leads to a valid PAC-Bayes bound, despite SGLD only converging in 2-Wasserstein distance to an ε-differentially private mechanism. We study our data-dependent bounds empirically, and show that they can be nonvacuous even when other distribution-dependent bounds are vacuous.
225. **Almost Optimal Algorithms for Linear Stochastic Bandits with Heavy-Tailed Payoffs** --*Han Shao &middot; Xiaotian Yu &middot; Irwin King &middot; Michael Lyu*
 > In linear stochastic bandits, it is commonly assumed that payoffs are with sub-Gaussian noises. In this paper, under a weaker assumption on noises, we study the problem of linear stochastic bandits with heavy-tailed payoffs (LinBET), where the distributions have finite moments of order $1+\epsilon$, for some $\epsilon\in (0,1]$. We rigorously analyze the regret lower bound of LinBET as $\Omega(T^{\frac{1}{1+\epsilon}})$, implying that finite moments of order 2 (i.e., finite variances) yield the bound of $\Omega(\sqrt{T})$, with $T$ being the total number of rounds to play bandits. The provided lower bound also indicates that the state-of-the-art algorithms for LinBET are far from optimal. By adopting median of means with a well-designed allocation of decisions and truncation based on historical information, we elaborately develop two novel bandit algorithms, where the regret upper bounds match the lower bound up to polylogarithmic factors. To the best of our knowledge, we are the first to solve LinBET optimally in the sense of the polynomial order on $T$.  Our proposed algorithms are evaluated based on synthetic datasets, and outperform the state-of-the-art results.
226. **Deep Network for the Integrated 3D Sensing of Multiple People in Natural Images** --*Andrei Zanfir &middot; Alin Popa &middot; Elisabeta Marinoiu &middot; Mihai Zanfir &middot; Cristian Sminchisescu*
 > We present a feed-forward, multitask, end-to-end trainable system for the integrated 2d localization, as well as 3d pose and shape estimation, of multiple people in monocular images. The challenge is the formal modeling of the problem that intrinsically requires discrete and continuous computation (e.g. grouping people vs. predicting 3d pose). The model identifies human body structures (joints and limbs) in images, groups them based on 2d and 3d information fused using learned scoring functions, and optimally aggregates such responses into partial or complete 3d human skeleton hypotheses under kinematic tree constraints, but without knowing in advance the number of people in the scene and their visibility relations. We design a single multi-task deep neural network with differentiable stages where the person grouping problem is formulated as an integer program based on learned body part scores parameterized by both 2d and 3d information. This avoids suboptimality resulting from separate 2d and 3d reasoning, with grouping performed based on the combined information. The calculation can be formally described as a linear binary integer program with globally optimal solution. The final predictive stage of 3d pose and shape is based on a learned attention process where information from different human body parts is optimally fused. State-of-the-art results are obtained in large scale datasets like Human3.6M and Panoptic. 
227. **Scaling provable adversarial defenses** --*Eric Wong &middot; Frank Schmidt &middot; Jan Hendrik Metzen &middot; J. Zico Kolter*
 > Recent work has developed methods for learning deep network classifiers that are \emph{provably} robust to norm-bounded adversarial perturbation; however, these methods are currently only possible for relatively small feedforward networks.  In this paper, in an effort to scale these approaches to substantially larger models, we extend previous work in three main directly.  First, we present a technique for extending these training procedures to much more general networks, with skip connections (such as ResNets) and general nonlinearities; the approach is fully modular, and can be implemented automatically analogously to automatic differentiation. Second, in the specific case of $\ell_\infty$ adversarial perturbations and networks with ReLU nonlinearities, we adopt a nonlinear random projection for training, which scales \emph{linearly} in the number of hidden units (previous approached scaled quadratically).  Third, we show how to further improve robust error through cascade models.  On both MNIST and CIFAR data sets, we train classifiers that improve substantially on the state of the art in provable robust adversarial error bounds: from 5.8% to 3.1% on MNIST  (with $\ell_\infty$ perturbations of $\epsilon=0.1$), and from 80% to 36.4% on CIFAR (with $\ell_\infty$ perturbations of $\epsilon=2/255$).
228. **Learning to Play With Intrinsically-Motivated, Self-Aware Agents** --*Nick Haber &middot; Damian Mrowca &middot; Stephanie Wang &middot; Li Fei-Fei &middot; Daniel Yamins*
 > Infants are experts at playing, with an amazing ability to generate novel structured behaviors in unstructured environments that lack clear extrinsic reward signals. We seek to mathematically formalize these abilities using a neural network that implements curiosity-driven intrinsic motivation.  Using a simple but ecologically naturalistic simulated environment in which an agent can move and interact with objects it sees, we propose a "world-model" network that learns to predict the dynamic consequences of the agent's actions.  Simultaneously, we train a separate explicit "self-model" that allows the agent to track the error map of its world-model. It then uses the self-model to adversarially challenge the developing world-model. We demonstrate that this policy causes the agent to explore novel and informative interactions with its environment, leading to the generation of a spectrum of complex behaviors, including ego-motion prediction, object attention, and object gathering.  Moreover, the world-model that the agent learns supports improved performance on object dynamics prediction, detection, localization and recognition tasks.  Taken together, our results are initial steps toward creating flexible autonomous agents that self-supervise in realistic physical environments.
229. **On avoiding discrimination in online learning** --*Avrim Blum &middot; Suriya Gunasekar &middot; Thodoris Lykouris &middot; Nati Srebro*
 > We study the design of online learning algorithms that, when run on members of different groups, do not discriminate against some group. We consider the most basic question in such a setting: how can we design an online learning algorithm that, given access to individually non-discriminatory predictors, guarantees the classical no-regret property and overall non-discrimination at the same time? We show a strong impossibility result for this goal with respect to "equal opportunity" that requires equal false negative rates across groups. On the positive side, we show that for another notion of non-discrimination, "equalized error rates", such a guarantee is achievable.
230. **Stochastic Primal-Dual Method for Empirical Risk Minimization with O(1) Per-Iteration Complexity** --*Conghui Tan &middot; Shiqian Ma &middot; Tong Zhang &middot; Ji Liu*
 > Regularized empirical risk minimization problem with linear predictor appears frequently in machine learning. In this paper, we propose a new stochastic primal-dual method to solve this class of problems. Different from existing methods, our proposed methods only require O(1) operations in each iteration. We also develop a variance-reduction variant of the algorithm that converges linearly. Numerical experiments suggest that our methods are faster than existing ones such as proximal SGD, SVRG and SAGA on high-dimensional problems.
231. **Transfer Learning with Neural AutoML** --*Catherine Wong &middot; Neil Houlsby &middot; Yifeng Lu &middot; Andrea Gesmundo*
 > We reduce the computational cost of Neural AutoML with transfer learning. AutoML relieves human effort by automating the design of ML algorithms. Neural AutoML has become popular for the design of deep learning architectures, however, this method has a high computation cost. To address this we propose Transfer Neural AutoML that uses knowledge from prior tasks to speed up network design. We extend RL-based architecture search methods to support parallel training on multiple tasks and then transfer the search strategy to new tasks. On language and image classification data, Transfer Neural AutoML reduces convergence time over single-task training by over an order of magnitude on many tasks.
232. **Distributionally Robust Graphical Models** --*Rizal Fathony &middot; Ashkan Rezaei &middot; Mohammad Ali Bashiri &middot; Xinhua Zhang &middot; Brian Ziebart*
 > In many structured prediction problems, complex relationships between variables are compactly defined using graphical structures. The most prevalent graphical prediction methods ---probabilistic graphical models and large margin methods--- have their own distinct strengths but also come with significant drawbacks. Conditional random fields (CRFs) are Fisher consistent, but they do not permit integration of customized loss functions into their learning process. Large-margin models, such as structured support vector machines (SSVM), have the flexibility to incorporate customized loss metrics, but lack Fisher consistency guarantees. We present adversarial graphical models (AGM), a distributionally robust approach for constructing a predictor that performs robustly for a class of data distributions defined using a graphical structure. Our approach enjoys both the flexibility of incorporating customized loss functions into its design as well as the statistical guarantee of Fisher consistency. We present exact learning and prediction algorithms for AGM requiring similar time complexity as existing graphical models and show its practical benefits in our experiments.
