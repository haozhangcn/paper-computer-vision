233. **Learning Conditioned Graph Structures for Interpretable Visual Question Answering** --*Will Norcliffe-Brown &middot; Stathis Vafeias &middot; Sarah Parisot*
 > Visual Question answering is a challenging problem requiring a combination of concepts from Computer Vision and Natural Language Processing. Most existing approaches use a two streams strategy, computing image and question features that are consequently merged using a variety of techniques. Nonetheless, very few rely on  higher level image representations, which allow to capture semantic and spatial relationships. In this paper, we propose a novel graph-based approach for Visual Question Answering. Our method combines a graph learner module, which learns a question specific graph representation of the input image, with the recent concept of graph convolutions, aiming to learn image representations that capture question specific interactions. We test our approach on the VQA v2 dataset using a simple baseline architecture enhanced by the proposed graph learner module. We obtain state of the art results with 65.77% accuracy and demonstrate the interpretability of the proposed method.
234. **Information-theoretic Limits for Community Detection in Network Models** --*Chuyang Ke &middot; Jean Honorio*
 > We analyze the information-theoretic limits for the recovery of node labels in several network models. This includes the Stochastic Block Model, the Exponential Random Graph Model, the Latent Space Model, the Directed Preferential Attachment Model, and the Directed Small-world Model. For the Stochastic Block Model, the non-recoverability condition depends on the probabilities of having edges inside a community, and between different communities. For the Latent Space Model, the non-recoverability condition depends on the dimension of the latent space, and how far and spread are the communities in the latent space. For the Directed Preferential Attachment Model and the Directed Small-world Model, the non-recoverability condition depends on the ratio between homophily and neighborhood size. We also consider dynamic versions of the Stochastic Block Model and the Latent Space Model.
235. **Generative Adversarial Examples** --*Yang Song &middot; Rui Shu &middot; Nate Kushman &middot; Stefano Ermon*
 > Adversarial examples are typically constructed by perturbing an existing data point, and current defense methods are focused on guarding against this type of attack. In this paper, we propose a new class of adversarial examples that are synthesized entirely from scratch using a conditional generative model. We first train an Auxiliary Classifier Generative Adversarial Network (AC-GAN) to model the class-conditional distribution over inputs. Then, conditioned on a desired class, we search over the AC-GAN latent space to find images that are likely under the generative model and are misclassified by a target classifier. We demonstrate through human evaluation that this new kind of adversarial inputs, which we call Generative Adversarial Examples, are legitimate and belong to the desired class. Our empirical results on the MNIST, SVHN, and CelebA datasets show that generative adversarial examples can easily bypass strong adversarial training and certified defense methods which can foil existing adversarial attacks.
236. **Bilevel learning of the Group Lasso structure** --*Jordan Frecon &middot; Saverio Salzo &middot; Massimiliano Pontil*
 > Regression with group-sparsity penalty plays a central role in high-dimensional prediction problems. However, most of existing methods require the group structure to be known a priori. In practice, this strong assumption often results in a degradation of the prediction performance. To circumvent this issue, we present a method to estimate the group structure by means of a continuous bilevel optimization problem where the data is split into training and validation sets. Our approach relies on an approximation where the lower problem is replaced by a smooth dual forward-backward scheme with Bregman distances. We provide guarantees regarding its convergence to the exact problem and demonstrate the well behaviour of the method on synthetic experiments. Finally, a preliminary application to genes expression data is tackled in order to unveil functional groups. 
237. **Differentiable MPC for End-to-end Planning and Control** --*Brandon Amos &middot; Ivan Jimenez &middot; Jacob Sacks &middot; Byron Boots &middot; J. Zico Kolter*
 > In this paper we present foundations for using model predictive control (MPC) as a differentiable policy class in reinforcement learning.    Specifically, we differentiate through MPC by using the KKT conditions of the convex approximation at a fixed point of the solver.  Using this strategy, we are able to learn the cost and dynamics of a controller via end-to-end learning in a larger system. We empirically show results in an imitation learning setting, demonstrating that we can recover the underlying dynamics and cost more efficiently and reliably than with a generic neural network policy class.
238. **Constrained Cross-Entropy Method for Safe Reinforcement Learning** --*Min Wen &middot; Ufuk Topcu*
 > We study a safe reinforcement learning problem in which the constraints are defined as the expected cost over finite-length trajectories. We propose a constrained cross-entropy-based method to solve this problem. The method explicitly tracks its performance with respect to constraint satisfaction and thus is well-suited for safety-critical applications. We show that the asymptotic behavior of the proposed algorithm can be almost-surely described by that of an ordinary differential equation. Then we give sufficient conditions on the properties of this differential equation to guarantee the convergence of the proposed algorithm. At last, we show with simulation experiments that the proposed algorithm can effectively learn feasible policies without assumptions on the feasibility of initial policies, even with non-Markovian objective functions and constraint functions.
239. **How to tell when a clustering is (approximately) correct using convex relaxations** --*Marina Meila*
 > We introduce a generic method to obtain guarantees of near-optimality and uniqueness (up to small perturbations) for a clustering. This  method can be instantiated for a variety of clustering loss functions for which convex relaxations exist. Obtaining the guarantees amounts to  solving a convex optimization problem. We demonstrate the practical relevance of this method by obtaining distribution free guarantees for the K-means clustering  problem  on realistic data sets. The guarantees do not depend on any distributional assumptions, but they depend on the data set at hand.  They exist only when the data is  clusterable.
240. **Revisiting $(\epsilon, \gamma, \tau)$-similarity learning for domain adaptation** --*Sofien Dhouib &middot; Ievgen Redko*
 > Similarity learning is an active research area in machine learning that tackles the problem of finding a similarity function tailored to an observable data sample in order to achieve efficient classification. This learning scenario has been generally formalized by the means of a $(\epsilon, \gamma, \tau)-$good similarity learning framework in the context of supervised classification and has been shown to have strong theoretical guarantees. In this paper, we propose to extend the theoretical analysis of similarity learning to the domain adaptation setting, a particular situation occurring when the similarity is learned and then deployed on samples following different probability distributions. We give a new definition of an $(\epsilon, \gamma)-$good similarity for domain adaptation and prove several results quantifying the performance of a similarity function on a target domain after it has been trained on a source domain. We particularly show that if the source domain support contains that of the target then principally new domain adaptation learning bounds can be proved. 
241. **Stochastic Chebyshev Gradient Descent for Spectral Optimization** --*Insu Han &middot; Haim Avron &middot; Jinwoo Shin*
 > A large class of machine learning techniques requires the solution of optimization problems involving spectral functions of parametric matrices, e.g. log-determinant and nuclear norm. Unfortunately, computing the gradient of a spectral function is generally of cubic complexity, as such gradient descent methods are rather expensive for optimizing objectives involving the spectral function. Thus, one naturally turns to stochastic gradient methods in hope that they will provide a way to reduce or altogether avoid the computation of full gradients. However, here a new challenge appears: there is no straightforward way to compute unbiased stochastic gradients for spectral functions. In this paper, we develop unbiased stochastic gradients for spectral-sums, an important subclass of spectral functions. Our unbiased stochastic gradients are based on combining randomized trace estimators with stochastic truncation of the Chebyshev expansions. A careful design of the truncation distribution allows us to offer distributions that are variance-optimal, which is crucial for fast and stable convergence of stochastic gradient methods. We further leverage our proposed stochastic gradients to devise stochastic methods for objective functions involving spectral-sums, and rigorously analyze their convergence rate. The utility of our methods is demonstrated in numerical experiments.
242. **Out-of-Distribution Detection using Multiple Semantic Label Representations** --*Gabi Shalev &middot; Yossi Adi &middot; Joseph Keshet*
 > Deep Neural Networks are powerful models that attained remarkable results on a variety of tasks. These models are shown to be extremely efficient when training and test data are drawn from the same distribution. However, it is not clear how a network will act when it is fed with an out-of-distribution example. In this work, we consider the problem of out-of-distribution detection in neural networks. We propose to use multiple semantic dense representations instead of sparse representation as the target label. Specifically, we propose to use several word representations obtained from different corpora or architectures as target labels. We evaluated the proposed model on computer vision, and speech commands detection tasks and compared it to previous methods. Results suggest that our method compares favorably with previous work. Besides, we present the efficiency of our approach for detecting wrongly classified and adversarial examples.
244. **Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces** --*Yu-An Chung &middot; Wei-Hung Weng &middot; Schrasing Tong &middot; James Glass*
 > Recent research has shown that word embedding spaces learned from text corpora of different languages can be aligned without any parallel data supervision. Inspired by the success in unsupervised cross-lingual word embeddings, in this paper we target learning a cross-modal alignment between the embedding spaces of speech and text learned from corpora of their respective modalities in an unsupervised fashion. The proposed framework learns the individual speech and text embedding spaces, and attempts to align the two spaces via adversarial training, followed by a refinement procedure. We show how our framework could be used to perform the tasks of spoken word classification and translation, and the experimental results on these two tasks demonstrate that the performance of our unsupervised alignment approach is comparable to its supervised counterpart. Our framework is especially useful for developing automatic speech recognition (ASR) and speech-to-text translation systems for low- or zero-resource languages, which have little parallel audio-text data for training modern supervised ASR and speech-to-text translation models, but account for the majority of the languages spoken across the world.
245. **Disconnected Manifold Learning for Generative  Adversarial Networks** --*Mahyar Khayatkhoei &middot; Maneesh K. Singh &middot; Ahmed Elgammal*
 > Real images often lie on a union of disjoint manifolds rather than one globally connected manifold, and this can cause several difficulties for the training of common Generative Adversarial Networks (GANs). In this work, we first show that single generator GANs are unable to correctly model a distribution supported on a disconnected manifold, and investigate how sample quality, mode collapse and local convergence are affected by this. Next, we show how using a collection of generators can address this problem, providing new insights into the success of such multi-generator GANs. Finally, we explain the serious issues caused by considering a fixed prior over the collection of generators and propose a novel approach for learning the prior and inferring the necessary number of generators without any supervision. Our proposed modifications can be applied on top of any other GAN model to enable learning of distributions supported on disconnected manifolds. We conduct several experiments to illustrate the aforementioned shortcoming of GANs, its consequences in practice, and the effectiveness of our proposed modifications in alleviating these issues.
246. **Bayesian Model-Agnostic Meta-Learning** --*Jaesik Yoon &middot; Taesup Kim &middot; Ousmane Dia &middot; Sungwoong Kim &middot; Yoshua Bengio &middot; Sungjin Ahn*
 > Learning to infer Bayesian posterior from a few-shot dataset is an important step towards robust meta-learning due to the model uncertainty inherent in the problem. In this paper, we propose a novel Bayesian model-agnostic meta-learning method. The proposed method combines gradient-based meta-learning with nonparametric variational inference in a principled probabilistic framework. During fast adaptation, the method is capable of learning complex uncertainty structure beyond a point estimate or a simple Gaussian approximation. In addition, a robust Bayesian meta-update mechanism with a new meta-loss prevents overfitting during meta-update. Remaining an efficient gradient-based meta-learner, the method is also  model-agnostic and simple to implement. Experiment results show the accuracy and robustness of the proposed method in various tasks: sinusoidal regression, image classification, active learning, and reinforcement learning.
247. **Exploring Sparse Features in Deep Reinforcement Learning towards Fast Disease Diagnosis** --*Yu-Shao Peng &middot; Kevin Tang &middot; Hsuan-Tien Lin &middot; Edward Chang*
 > This paper proposes a policy gradient method with two techniques, {\em reward shaping} and {\em reconstruction}, to improve the performance of online symptom checking. Reward shaping can guide the search towards better directions. Reconstruction can guide the agent to learn correlations between features. Together, they can find symptom queries that can yield positive responses from a patient with high probability.  Consequently, using these techniques a symptom checker can obtain much improved diagnoses.
248. **Streaming~Kernel~PCA~with~$\tilde{O}(\sqrt{n})$~Random~Features** --*Enayat Ullah &middot; Poorya Mianjy &middot; Teodor Vanislavov Marinov &middot; Raman Arora*
 > We study the statistical and computational aspects of kernel principal component analysis using random Fourier features and show that under mild assumptions, $O(\sqrt{n} \log n)$ features suffices to achieve $O(1/\epsilon^2)$ sample complexity. Furthermore, we give a memory efficient streaming algorithm based on classical Oja's algorithm that achieves this rate
249. **Relational recurrent neural networks** --*Adam Santoro &middot; Ryan Faulkner &middot; David Raposo &middot; Jack Rae &middot; Mike Chrzanowski &middot; Theophane Weber &middot; Daan Wierstra &middot; Oriol Vinyals &middot; Razvan Pascanu &middot; Tim Lillicrap*
 > Memory-based neural networks model temporal data by leveraging an ability to remember information for long periods. It is unclear, however, whether they also have an ability to perform complex relational reasoning with the information they remember. Here, we first confirm our intuitions that standard memory architectures may struggle at tasks that heavily involve an understanding of the ways in which entities are connected -- i.e., tasks involving relational reasoning. We then improve upon these deficits by using a new memory module -- a Relational Memory Core (RMC) -- which employs multi-head dot product attention to allow memories to interact. Finally, we test the RMC on a suite of tasks that may profit from more capable relational reasoning across sequential information, and show large gains in RL domains (BoxWorld &amp; Mini PacMan), program evaluation, and language modeling, achieving state-of-the-art results on the WikiText-103, Project Gutenberg, and GigaWord datasets.
250. **Unsupervised Text Style Transfer using Language Models as Discriminators** --*Zichao  Yang &middot; Zhiting Hu &middot; Chris Dyer &middot; Eric Xing &middot; Taylor Berg-Kirkpatrick*
 > Binary classifiers are employed as discriminators in GAN-based unsupervised style transfer models to ensure that transferred sentences are similar to sentences in the target domain. One difficulty with the binary discriminator is that error signal is sometimes insufficient to train the model to produce rich-structured language. In this paper, we propose a technique of using a target domain language model as the discriminator to provide richer, token-level feedback during the learning process. Because our language model scores sentences directly using a product of locally normalized probabilities, it offers more stable and more useful training signal to the generator. We train the generator to minimize the negative log likelihood (NLL) of generated sentences evaluated by a language model. By using continuous approximation of the discrete samples, our model can be trained using back-propagation in an end-to-end way. Moreover, we find empirically with a language model as a structured discriminator, it is possible to eliminate the adversarial training steps using negative samples, thus making training more stable. We compare our model with previous work using convolutional neural networks (CNNs) as discriminators and show our model outperforms them significantly in three tasks including word substitution decipherment, sentiment modification and related language translation.
251. **Bandit Learning with Implicit Feedback** --*Yi Qi &middot; Hongning Wang &middot; Qingyun Wu*
 > Implicit feedback, such as user clicks, although abundant in online information service systems, does not provide substantial evidence on users' evaluation of system's output. Such incomplete supervision inevitably misleads model estimation, especially in a bandit learning setting where the feedback is acquired on the fly. In this work, we study a contextual bandit problem with implicit feedback by modeling the feedback as a composition of user result examination and relevance judgment. Since users' examination behavior is unobserved, we introduce latent variables to model it. We perform Thompson sampling on top of variational Bayesian inference for arm selection and model update. Rigorous upper regret bound analysis of the proposed algorithm proves its feasibility of learning from implicit feedback; and extensive empirical evaluations on click logs collected from a major MOOC platform further demonstrate its learning effectiveness in practice. 
252. **Training Deep Models Faster with Robust, Approximate Importance Sampling** --*Tyler B Johnson &middot; Carlos Guestrin*
 > In theory, importance sampling speeds up stochastic gradient algorithms for supervised learning by prioritizing training instances. In practice, the cost of computing importances greatly limits the impact of importance sampling. We propose a robust, approximate importance sampling procedure (RAIS) for stochastic gradient descent. By approximating the ideal sampling distribution using robust optimization, RAIS provides much of the benefit of exact importance sampling with drastically reduced overhead.  Empirically, we find RAIS-SGD and standard SGD follow similar learning curves, but RAIS moves faster through these paths.
253. **Learning Attentional Communication for Multi-Agent Cooperation** --*Jiechuan Jiang &middot; Zongqing Lu*
 > Communication could potentially be an effective way for multi-agent cooperation. However, information sharing among all agents or in predefined communication architectures that existing methods adopt can be problematic. When there is a large number of agents, agents hardly differentiate valuable information that helps cooperative decision making from globally shared information. Therefore, communication barely help, and could even impair the learning of multi-agent cooperation. Predefined communication architectures, on the other hand, restrict communication among agents and thus restrain potential cooperation. To tackle these difficulties, in this paper, we propose an attentional communication model that learns when communication is needed and how to integrates shared information for cooperative decision making. Our model leads to efficient and effective communication for large-scale multi-agent cooperation. Empirically, we show the strength of our model in various cooperative scenarios, where agents are able to develop more coordinated and sophisticated strategies than existing methods.
254. **Implicit Probabilistic Integrators for ODEs** --*Onur Teymur &middot; Han Cheng Lie &middot; Tim Sullivan &middot; Ben Calderhead*
 > We introduce a family of implicit probabilistic integrators for initial value problems (IVPs) taking as a starting point the multistep Adams--Moulton method. The implicit construction allows for dynamic feedback from the forthcoming time-step, by contrast with previous probabilistic integrators, all of which are based on explicit methods. We begin with a concise survey of the rapidly-expanding field of probabilistic ODE solvers. We then introduce our method, which builds on and adapts the work of Conrad et al. (2016) and Teymur et al. (2016), and provide a rigorous proof of its well-definedness and convergence. We discuss the problem of the calibration of such integrators and suggest one approach. We give an illustrative example highlighting the effect of the use of probabilistic integrators -- including our new method -- in the setting of parameter inference within an inverse problem.
255. **Chaining Mutual Information and Tightening Generalization Bounds** --*Amir Asadi &middot; Emmanuel Abbe &middot; Sergio Verdu*
 > Bounding the generalization error of learning algorithms has a long history, that yet falls short in explaining various generalization successes including those of deep learning. Two important difficulties are (i) exploiting the dependencies between hypotheses, (ii) exploiting the dependencies between the algorithm's input and output. Progress on the first point was made with the chaining method, used in the VC dimension bound. More recently, progress on the second point was made with the mutual information method by Russo and Zou '15. Yet, these two methods are currently disjoint. In this paper, we introduce a technique to combine chaining and mutual information methods, to obtain a generalization bound that is both algorithmic-dependent and that exploits dependencies between hypotheses. We provide an example in which our bound significantly outperforms both the chaining and the mutual information method. As a corollary, we tighten Dudley's inequality under knowledge that a learning algorithm chooses its output from a small subset of hypotheses with high probability; an assumption motivated by the performance of SGD discussed in Zhang et al.\ '17. 
257. **Distributed Multi-Player Bandits - a Game of Thrones Approach** --*Ilai Bistritz &middot; Amir Leshem*
 > We consider a multi-armed bandit game where N players compete for K arms for T turns. Each player has different expected rewards for the arms, and the instantaneous rewards are independent and identically distributed. Performance is measured using the expected sum of regrets, compared to optimal assignment of arms to players. We assume that each player only knows her actions and the reward she received each turn. Players cannot observe the actions of other players, and no communication between players is possible. We present a distributed algorithm and prove that it achieves an expected sum of regrets of near-O\left(\log^{2}T\right) . This is the first algorithm to achieve a poly-logarithmic regret in this fully distributed scenario. All other works have assumed that either all players have the same vector of expected rewards or that communication between players is possible.  
258. **Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction** --*Roei Herzig &middot; Moshiko Raboh &middot; Gal Chechik &middot; Jonathan Berant &middot; Amir Globerson*
 > Machine understanding of complex images is a key goal of artificial intelligence. One challenge underlying this task is that visual scenes contain multiple inter-related objects, and that global context plays an important role in interpreting the scene. A natural modeling framework for capturing such effects is structured prediction, which optimizes over complex labels, while modeling within-label interactions. However, it is unclear what principles should guide the design of a structured prediction model that utilizes the power of deep learning components. Here we propose a design principle for such architectures that follows from a natural requirement of permutation invariance. We prove a necessary and sufficient characterization for architectures that follow this invariance, and discuss its implication on model design. Finally, we show that the resulting model achieves new state of the art results on the Visual Genome scene graph labeling benchmark, outperforming all recent approaches.
259. **Stimulus domain transfer in recurrent models for large scale cortical population prediction on video** --*Fabian Sinz &middot; Alexander Ecker &middot; Paul Fahey &middot; Edgar Walker &middot; Erick Cobos &middot;   &middot; Dimitri Yatsenko &middot; Xaq Pitkow &middot; Jacob Reimer &middot; Andreas Tolias*
 > To better understand the representations in visual cortex, we need to generate better predictions of neural activity in awake animals presented with their ecological input: natural video. Despite recent advances in models for static images, models for predicting responses to natural video are scarce and standard linear-nonlinear models perform poorly. We developed a new deep recurrent network architecture that predicts inferred spiking activity of thousands of mouse V1 neurons simultaneously recorded with two-photon microscopy, while accounting for confounding factors such as the animal's gaze position and brain state changes related to running state and pupil dilation. Powerful system identification models provide an opportunity to gain insight into cortical functions through {\em in silico} experiments that can subsequently be tested in the brain. However, in many cases this approach requires that the model is able to generalize to stimulus statistics that it was not trained on, such as band-limited noise and other parameterized stimuli. We investigated these domain transfer properties in our model and find that our model trained on natural images is able to correctly predict the orientation tuning of neurons in responses to artificial noise stimuli. Finally, we show that we can fully generalizing from movies to noise and maintain high predictive performance on both by fine-tuning the final layer's weights on a network otherwise trained on natural movies. The converse, however, is not true.
260. **BRUNO: A Deep Recurrent Model for Exchangeable Data** --*Iryna Korshunova &middot; Jonas Degrave &middot; Ferenc Huszar &middot; Yarin Gal &middot; Arthur Gretton &middot; Joni Dambre*
 > We present a novel model architecture which leverages deep learning tools to perform exact Bayesian inference on sets of high dimensional, complex observations. Our model is provably exchangeable, meaning that the joint distribution over observations is invariant under permutation: this property lies at the heart of Bayesian inference. The model does not require variational approximations to train, and new samples can be generated conditional on previous samples, with cost linear in the size of the conditioning set. The advantages  of our architecture are demonstrated on learning tasks that require generalisation from short observed sequences while modelling sequence variability, such as conditional image generation, few-shot learning, and anomaly detection.
261. **End-to-End Differentiable Physics for Learning and Control** --*Filipe de Avila Belbute-Peres &middot; Kevin Smith &middot; Kelsey Allen &middot; Josh Tenenbaum &middot; J. Zico Kolter*
 > We present a differentiable physics engine that can be integrated as a module in deep neural networks for end-to-end learning.  As a result, structured physics knowledge can be embedded into larger systems, allowing them, for example, to match observations by performing precise simulations, while achieves high sample efficiency.  Specifically, in this paper we demonstrate how to perform backpropagation analytically through a physical simulator defined via a linear complementarity problem.  Unlike traditional finite difference methods, such gradients can be computed analytically, which allows for greater flexibility of the engine. Through experiments in diverse domains, we highlight the system's ability to learn physical parameters from data, efficiently match and simulate observed visual behavior, and readily enable control via gradient-based planning methods.
262. **A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks** --*Kimin Lee &middot; Kibok Lee &middot; Honglak Lee &middot; Jinwoo Shin*
 > Detecting test samples drawn sufficiently far away from the training distribution statistically or adversarially is the fundamental requirement to deploy a good classifier in many real-world machine learning applications. However, deep neural networks with the softmax classifier are known to produce highly overconfident posterior distributions even for such abnormal samples. In this paper, we propose a simple yet effective method for detecting any abnormal samples, which is applicable to any pre-trained softmax neural classifier. We obtain the class conditional Gaussian distributions with respect to (low- and upper-level) features of the deep models under Gaussian discriminant analysis, which result in a confidence score based on the Mahalanobis distance. While most prior methods have been evaluated for detecting either out-of-distribution or adversarial samples, but not both, the proposed method achieves the state-of-art performances for both cases in our experiments. Moreover, we found that our proposed method is more robust in extreme cases, e.g., when the training dataset has noisy labels or small number of samples. Finally, we show that {the proposed method} enjoys broader usage by applying it to class incremental learning: whenever out-of-distribution samples are detected, our classification rule can incorporate new classes well without further training deep models.
263. **Multitask Reinforcement Learning for Zero-shot Generalization with Subtask Dependencies** --*SUNGRYULL SOHN &middot; Junhyuk Oh &middot; Honglak Lee*
 > We introduce a new RL problem where the agent is required to execute a given subtask graph which describes a set of subtasks and their dependency. Unlike existing approaches that explicitly describe what the agent should do, our problem only describes properties of subtasks and relationships among them, which requires the agent to perform a complex reasoning to find the optimal subtask to execute. To solve this problem, we propose a neural subtask graph solver (NSS) which encodes the subtask graph using a recursive neural network. To overcome the difficulty of training, we propose a novel non-parametric gradient-based policy to pre-train our NSS agent and further finetune it through actor-critic method. The experimental results on two 2D visual domains show that our agent can perform a complex reasoning to find the optimal way of executing the subtask graph and generalize well to the unseen subtask graphs. In addition, we compare our agent with a Monte-Carlo tree search (MCTS) method showing that our method is much more efficient than MCTS, and the performance of NSS can be further improved by combining it with MCTS.
264. **Parameters as interacting particles: asymptotic scaling, convexity, and error of neural networks** --*Grant Rotskoff &middot; Eric Vanden-Eijnden*
 >  The performance of neural networks on high-dimensional data distributions suggests that it may be possible to parameterize a representation of a \emph{given} high-dimensional function with controllably small errors, potentially outperforming standard interpolation methods.  We demonstrate, both theoretically and numerically, that this is indeed the case.  We map the parameters of a neural network to a system of particles relaxing with an interaction potential determined by the loss function.  We show that in the limit that the number of parameters $n$ is large, the landscape of the mean-squared error becomes convex and the representation error in the function scales as $O(n^{-1})$.  As a consequence, we rederive the universal approximation theorem for neural networks but we additionally prove that the optimal representation can be achieved through stochastic gradient descent, the algorithm ubiquitously used for parameter optimization in machine learning.  In the asymptotic regime, we study the fluctuations around the optimal representation and show that they arise at a scale $O(n^{-1})$, for suitable choices of the batch size.  These fluctuations in the landscape demonstrate the necessity of the noise inherent in stochastic gradient descent and our analysis provides a precise scale for tuning this noise.  Our results apply to both single and multi-layer neural networks, as well as standard kernel methods like radial basis functions.  From our insights, we extract several practical guidelines for large scale applications of neural networks, emphasizing the importance of both noise and quenching, in particular.
265. **Deep Homogeneous Mixture Models: Representation, Separation, and Approximation** --*Priyank Jaini &middot; Pascal Poupart &middot; Yaoliang Yu*
 > At their core, many unsupervised learning models provide a compact representation of homogeneous density mixtures, but their similarities and differences are not always clearly understood. In this work, we formally establish the relationships among latent tree graphical models (including special cases such as hidden Markov models and tensorial mixture models), hierarchical tensor formats and sum-product networks. Based on this connection, we then give a unified treatment of exponential separation in \emph{exact} representation size between deep mixture architectures and shallow ones. In contrast, for \emph{approximate} representation, we show that the conditional gradient algorithm can approximate any homogeneous mixture within $\epsilon$ accuracy by combining $O(1/\epsilon^2)$ ``shallow'' architectures, where the hidden constant may decrease (exponentially) with respect to the depth. Our experiments on both synthetic and real datasets confirm the benefits of depth in density estimation.
266. **Provably Correct Automatic Sub-Differentiation for Qualified Programs** --*Sham Kakade &middot; Jason Lee*
 > The \emph{Cheap Gradient Principle}~\citep{Griewank:2008:EDP:1455489} --- the computational cost of computing a $d$-dimensional vector of  partial derivatives of a scalar function is nearly the same (often within a factor of $5$)  as that of simply computing the scalar function itself --- is of central importance in optimization; it allows us to quickly obtain (high-dimensional) gradients of scalar loss functions which are subsequently used in black box gradient-based optimization procedures. The current state of affairs is markedly different with regards to computing sub-derivatives: widely used ML libraries, including TensorFlow and PyTorch, do \emph{not} correctly compute (generalized) sub-derivatives even on simple differentiable examples. This work considers the question: is there a \emph{Cheap Sub-gradient Principle}?  Our main result shows that, under certain restrictions on our library of non-smooth functions (standard in non-linear programming), provably correct generalized sub-derivatives can be computed at a computational cost that is within a (dimension-free) factor of $6$ of the cost of computing the scalar function itself.  
267. **Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders** --*Tengfei Ma &middot; Jie Chen &middot; Cao Xiao*
 > Deep generative models have achieved remarkable success in various data domains, including images, time series, and natural languages. There remain, however, substantial challenges for combinatorial structures, including graphs. One of the key challenges lies in the difficulty of ensuring semantic validity in context. For examples, in molecular graphs, the number of bonding-electron pairs must not exceed the valence of an atom; whereas in protein interaction networks, two proteins may be connected only when they belong to the same or correlated gene ontology terms. These constraints are not easy to be incorporated into a generative model. In this work, we propose a regularization framework for variational autoencoders as a step toward semantic validity. We focus on the matrix representation of graphs and formulate penalty terms that regularize the output distribution of the decoder to encourage the satisfaction of validity constraints. Experimental results confirm a much higher likelihood of sampling valid graphs in our approach, compared with others reported in the literature.
268. **Model-Agnostic Private Learning** --*Raef Bassily &middot; Abhradeep Guha Thakurta &middot; Om Dipakbhai Thakkar*
 > We design differentially private learning algorithms that are agnostic to the learning model assuming access to limited amount of unlabeled public data. First, we give a new differentially private algorithm for answering a sequence of $m$ online classification queries (given by a sequence of $m$ unlabeled public feature vectors) based on a private training set. Our private algorithm follows the paradigm of subsample-and-aggregate, in which any generic non-private learner is trained on disjoint subsets of the private training set, then for each classification query, the votes of the resulting classifiers ensemble are aggregated in a differentially private fashion. Our private aggregation is based on a novel combination of distance-to-instability framework \cite{ST13} and the sparse-vector technique \cite{DNRRV09,HR10}.  We show that our algorithm makes a conservative use of the privacy budget. In particular, if the underlying non-private learner yields classification error at most $\alpha\in (0, 1)$, then our construction answers more queries than what is implied by a straightforward application of advanced composition theorems from differential privacy; and by at least a factor of $1/\alpha$ in some cases. Next, we apply the knowledge transfer technique to construct a private learner that outputs a classifier, which can be used to answer unlimited number of queries. In the (agnostic) PAC model, we analyze our construction and prove upper bounds on the sample complexity for both the realizable and the non-realizable cases. As in non-private sample complexity, our bounds are completely characterized by the VC dimension of the concept class. 
269. **On the Convergence and Robustness of Training GANs with Regularized Optimal Transport** --*Maziar Sanjabi &middot; Jimmy Ba &middot; Meisam Razaviyayn &middot; Jason Lee*
 > Generative Adversarial Networks (GANs) are one of the most practical methods for learning data distributions. A popular GAN formulation is based on the use of Wasserstein distance as a metric between probability distributions. Unfortunately, minimizing the Wasserstein distance between the data distribution and the generative model distribution is a computationally challenging problem as its objective is non-convex, non-smooth, and even hard to compute. In this work, we show that obtaining gradient information of the smoothed Wasserstein GAN formulation, which is based on regularized Optimal Transport (OT), is computationally effortless and hence one can apply first order optimization methods to minimize this objective. Consequently, we establish theoretical convergence guarantee to stationarity for a proposed class of GAN optimization algorithms. Unlike the original non-smooth formulation, our algorithm only requires solving the discriminator to approximate optimality. We apply our method to learning MNIST digits as well as CIFAR-10 images.  Our experiments show that our method is computationally efficient and generates images comparable to the state of the art algorithms given the same architecture and computational power.
270. **Manifold-tiling Localized Receptive Fields are Optimal in Similarity-preserving Neural Networks** --*Anirvan M Sengupta &middot; Cengiz Pehlevan &middot; Mariano Tepper &middot; Alexander Genkin &middot; Dmitri Chklovskii*
 > Many neurons in the brain, such as place cells in the rodent hippocampus, have localized receptive fields, i.e. they respond to a small neighborhood of stimulus space. What is the functional significance of such representations and how can they arise? Here, we propose that localized receptive fields emerge in similarity-preserving networks of rectifying neurons that learn low-dimensional manifolds populated by sensory inputs.  Numerical simulations of such networks on standard datasets yield manifold-tiling localized receptive fields. More generally, we show analytically that, for data lying on symmetric manifolds, optimal solutions of objectives, from which similarity-preserving networks are derived, have localized receptive fields. Therefore, nonnegative similarity-preserving mapping (NSM) implemented by neural networks can model representations of continuous manifolds in the brain.
271. **A probabilistic population code based on neural samples** --*Sabyasachi Shivkumar &middot; Richard D Lange &middot; Ankani Chattoraj &middot; Ralf M Haefner*
 > Sensory processing is often characterized as implementing probabilistic inference: networks of neurons compute posterior beliefs over unobserved causes given the sensory inputs. How these beliefs are computed and represented by neural responses is much-debated (Fiser et al. 2010, Pouget et al. 2013). A central debate concerns the questions of whether neural responses represent samples of latent variables (Hoyer \&amp; Hyvarinnen 2003) or parameters of their distributions (Ma et al. 2006) with efforts being made to distinguish between them (Grabska-Barwinska et al. 2013). A separate debate addresses the question of whether neural responses are proportionally related to the encoded probabilities (Barlow 1969), or proportional to the logarithm of those probabilities (Jazayeri \&amp; Movshon 2006, Beck et al. 2006, Beck et al. 2012).  Here, we show that these alternatives -- contrary to common assumptions -- are not mutually exclusive and that the very same system can be compatible with all of them. As a central analytical result, we show that modeling neural responses in area V1 as samples from a posterior distribution over latents in a linear Gaussian model of the image implies that those neural responses form a probabilistic population code (PPC, Beck et al. 2006). In particular, the posterior distribution over some experimenter-defined variable like ``orientation'' is part of the exponential family with sufficient statistics that are linear in the neural sampling-based firing rates.
272. **Dual Policy Iteration** --*Wen Sun &middot; Geoffrey Gordon &middot; Byron Boots &middot; J. Bagnell*
 > Recently, a novel class of Approximate Policy Iteration (API) algorithms have demonstrated impressive practical performance (e.g., ExIt from [1], AlphaGo-Zero from [2]). This new family of algorithms maintains, and alternately optimizes, two policies: a fast, reactive policy (e.g., a deep neural network) deployed at test time, and a slow, non-reactive policy (e.g., Tree Search), that can plan multiple steps ahead. The reactive policy is updated under supervision from the non-reactive policy, while the non-reactive policy is improved with guidance from the reactive policy. In this work we study this Dual Policy Iteration (DPI) strategy in an alternating optimization framework and provide a convergence analysis that extends existing API theory. We also develop a special instance of this framework which reduces the update of non-reactive policies to model-based optimal control using learned local models, and provides a theoretically sound way of unifying model-free and model-based RL approaches with unknown dynamics. We demonstrate the efficacy of our approach on various continuous control Markov Decision Processes.
273. **Predictive Uncertainty Estimation via Prior Networks** --*Andrey Malinin &middot; Mark Gales*
 > Estimating how uncertain an AI system is in its predictions is important to improve the safety of such systems. Uncertainty in predictive can result from uncertainty in model parameters, irreducible data uncertainty and uncertainty due to distributional mismatch between the test and training data distributions. Different actions might be taken depending on the source of the uncertainty so it is important to be able to distinguish between them. Recently, baseline tasks and metrics have been defined and several practical methods to estimate uncertainty developed. These methods, however, attempt to model uncertainty due to distributional mismatch either implicitly through model uncertainty or as data uncertainty. This work proposes a new framework for modeling predictive uncertainty called Prior Networks (PNs) which explicitly models distributional uncertainty. PNs do this by parameterizing a prior distribution over predictive distributions. This work focuses on uncertainty for classification and evaluates PNs on the tasks of identifying out-of-distribution (OOD) samples and detecting misclassification on the MNIST dataset, where they are found to outperform previous methods. Experiments on synthetic and MNIST data show that unlike previous non-Bayesian methods PNs are able to distinguish between data and distributional uncertainty.
274. **GILBO: One Metric to Measure Them All** --*Alexander Alemi &middot; Ian Fischer*
 > We propose a simple, tractable lower bound on the mutual information contained in the joint generative density of any latent variable generative model: the GILBO (Generative Information Lower BOund). It offers a data-independent measure of the complexity of the learned latent variable description, giving the log of the effective description length. It is well-defined for both VAEs and GANs. We compute the GILBO for 800 GAN s and VAE s each trained on four datasets (MNIST, FashionMNIST, CIFAR-10 and CelebA) and discuss the results.
275. **Efficient online algorithms for fast-rate regret bounds under sparsity** --*Pierre Gaillard &middot; Olivier Wintenberger*
 > We consider the online convex optimization problem. In the setting of arbitrary sequences and finite set of parameters, we establish a new fast-rate  quantile regret bound. Then we investigate the optimization into the $\ell_1$-ball by discretizing the parameter space. Our algorithm is projection free and we propose an efficient solution by restarting the algorithm on adaptive discretization grids. In the adversarial setting, we develop an algorithm that achieves several rates of convergence with different dependences on the sparsity of the objective. In the i.i.d. setting, we establish new risk bounds that are adaptive to the sparsity of the problem and to the regularity of the risk (ranging from a rate $1/\sqrt{T}$ for general convex risk to $1/T$ for strongly convex risk). These results generalize previous works on sparse online learning. They are obtained under a weak assumption on the risk (Åojasiewicz's assumption) that allows multiple optima which is crucial when dealing with degenerate situations.
276. **Gen-Oja: Simple & Efficient Algorithm for Streaming Generalized Eigenvector Computation** --*Kush Bhatia &middot; Aldo Pacchiano &middot; Nicolas Flammarion &middot; Peter Bartlett &middot; Michael Jordan*
 > In this paper, we study the problems of principle Generalized Eigenvector computation and Canonical Correlation Analysis in the stochastic setting. We propose a simple and efficient algorithm for these problems. We prove the global convergence of our algorithm, borrowing ideas from the theory of fast-mixing Markov chains and two-Time-Scale Stochastic Approximation, showing that it achieves the optimal rate of convergence. In the process, we develop tools for understanding stochastic processes with Markovian noise which might be of independent interest.
277. **Hybrid Macro/Micro Level Backpropagation for Training Deep Spiking Neural Networks** --*Yingyezhe Jin &middot; Peng Li &middot; Wenrui Zhang*
 > Spiking neural networks (SNNs) are positioned to enable spatio-temporal information processing and ultra-low power event-driven neuromorphic hardware. However,  SNNs are yet to reach the same performances of conventional deep artificial neural networks (ANNs), a long-standing challenge due to complex dynamics and non-differentiable spike events encountered in training. The existing SNN error backpropagation (BP) methods are limited in terms of scalability, lack of proper handling of spiking discontinuities, and/or mismatch between the rate-coded loss function and computed gradient. We present a hybrid macro/micro level backpropagation algorithm (HM2-BP) for training multi-layer SNNs. The temporal effects are precisely captured by the proposed spike-train level post-synaptic potential (S-PSP) at the microscopic level.  The rate-coded errors are defined at the macroscopic level,  computed and back-propagated across both macroscopic and microscopic levels.  Different from existing BP methods, HM2-BP directly computes the gradient of the rate-coded loss function w.r.t tunable parameters. We evaluate the proposed HM2-BP algorithm by training deep fully connected and convolutional SNNs based on  the static MNIST [13] and dynamic neuromorphic N-MNIST [22] datasets. HM2-BP achieves an accuracy level of 99.49% and $98.88% for MNIST and N-MNIST, respectively, outperforming the best reported performances obtained from the existing SNN BP algorithms. It also achieves competitive performances surpassing those of conventional deep learning models when dealing with asynchronous spiking streams.
278. **Bayesian Alignments of Warped Multi-Output Gaussian Processes** --*Markus Kaiser &middot; Clemens Otte &middot; Thomas Runkler &middot; Carl Henrik Ek*
 > We propose a novel Bayesian approach to modelling nonlinear alignments of time series based on latent shared information. We apply the method to the real-world problem of finding common structure in the sensor data of wind turbines introduced by the underlying latent and turbulent wind field. The proposed model allows for both arbitrary alignments of the inputs and non-parametric output warpings to transform the observations. This gives rise to multiple deep Gaussian process models connected via latent generating processes. We present an efficient variational approximation based on nested variational compression and show how the model can be used to extract shared information between dependent time series, recovering an interpretable functional decomposition of the learning problem. We show results for an artificial data set and real-world data of two wind turbines.
279. **Causal Inference via Kernel Deviance Measures** --*Jovana Mitrovic &middot; Dino Sejdinovic &middot; Yee Whye Teh*
 > Discovering the causal structure among a set of variables is a fundamental problem in many areas of science. In this paper, we propose Kernel Conditional Deviance for Causal Inference (KCDC) a fully nonparametric causal discovery method based on purely observational data. From a novel interpretation of the notion of asymmetry between cause and effect, we derive a corresponding asymmetry measure using the framework of reproducing kernel Hilbert spaces. Based on this, we propose three decision rules for causal discovery. We demonstrate the wide applicability of our method across a range of diverse synthetic datasets. Furthermore, we test our method on real-world time series data and the real-world benchmark dataset Tubingen Cause-Effect Pairs where we outperform existing state-of-the-art methods.
280. **Unorganized Malicious Attacks Detection** --*Ming Pang &middot; Wei Gao &middot; Min Tao &middot; Zhi-Hua Zhou*
 > Recommender system has attracted much attention during the past decade. Many attack detection algorithms have been developed for better recommendations, mostly focusing on shilling attacks, where an attack organizer produces a large number of user profiles by the same strategy to promote or demote an item. This work considers a different attack style: unorganized malicious attacks, where attackers individually utilize a small number of user profiles to attack different items without any organizer. This attack style occurs in many real applications, yet relevant study remains open. We first formulate unorganized malicious attacks detection as a matrix completion problem, and propose the Unorganized Malicious Attacks detection (UMA) approach, based on the alternating splitting augmented Lagrangian method. We verify, both theoretically and empirically, the effectiveness of our proposed approach.
281. **A Probabilistic U-Net for Segmentation of Ambiguous Images** --*Simon Kohl &middot; Bernardino Romera-Paredes &middot; Clemens Meyer &middot; Klaus Maier-Hein &middot; S. M. Ali Eslami &middot; Danilo Jimenez Rezende &middot; Olaf Ronneberger*
 > Many real-world vision problems suffer from inherent ambiguities. In clinical applications for example, it might not be clear from a CT scan alone which particular region is cancer tissue. Therefore a group of graders typically produces a set of diverse but plausible segmentations. We consider the task of learning a distribution over segmentations given an input. To this end we propose a generative segmentation model based on a combination of a U-Net with a conditional variational autoencoder that is capable of efficiently producing an unlimited number of plausible hypotheses. We show on a lung abnormalities segmentation task and on a Cityscapes segmentation task that our model reproduces the possible segmentation variants as well as the frequencies with which they occur, doing so significantly better than published approaches. These models could have a high impact in real-world applications, such as being used as clinical decision-making algorithms accounting for multiple plausible semantic segmentation hypotheses to provide possible diagnoses and recommend further actions to resolve the present ambiguities.
282. **Uncertainty Sampling is Preconditioned Stochastic Gradient Descent on Zero-One Loss** --*Stephen Mussmann &middot; Percy Liang*
 > Uncertainty sampling, a popular active learning algorithm, is used to reduce the amount of data required to learn a classifier, but it is observed in practice to converge to a variety of values depending on the initialization and sometimes to even better values than the convergence value of random sampling. In this work, we give a theoretical explanation of this phenomena, showing that uncertainty sampling on a convex (e.g., logistic) loss can be interpreted as performing a pre-conditioned stochastic gradient step on the zero-one loss. Experiments on synthetic and real datasets support this connection.
283. **Joint Autoregressive and Hierarchical Priors for Learned Image Compression** --*David Minnen &middot; Johannes BallÃ© &middot; George D Toderici*
 > Recent models for learned image compression are based on autoencoders, learning approximately invertible mappings from pixels to a quantized latent representation. These are combined with an entropy model, a prior on the latent representation that can be used with standard arithmetic coding algorithms to yield a compressed bitstream. Recently, hierarchical entropy models have been introduced as a way to exploit more structure in the latents than simple fully factorized priors, improving compression performance while maintaining end-to-end optimization. Inspired by the success of autoregressive priors in probabilistic generative models, we examine autoregressive, hierarchical, as well as combined priors as alternatives, weighing their costs and benefits in the context of image compression. While it is well known that autoregressive models come with a significant computational penalty, we find that in terms of compression performance, autoregressive and hierarchical priors are complementary and, together, exploit the probabilistic structure in the latents better than all previous learned models.  The combined model yields state-of-the-art rate--distortion performance, providing a 15.8\% average reduction in file size over the previous state-of-the-art method based on deep learning, which corresponds to a 59.8% size reduction over JPEG, more than 35% reduction compared to WebP and JPEG2000, and bitstreams 8.4% smaller than BPG, the current state-of-the-art image codec. To the best of our knowledge, our model is the first learning-based method to outperform BPG on both PSNR and MS-SSIM distortion metrics.
284. **Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters** --*Darina Dvinskikh &middot; Alexander Gasnikov &middot; Cesar Uribe &middot; Angelia Nedich &middot; Pavel Dvurechensky*
 > We study the problem of decentralized distributed computation of a discrete approximation for regularized Wasserstein barycenter of a finite set of continuous probability measures distributedly stored over a network. Particularly, we assume that there is a network of agents/machines/computers where each agent holds a private continuous probability measure, and seeks to compute the barycenter of all the measures in the network by getting samples from its local measure and exchanging information with its neighbors. Motivated by this problem, we develop a novel accelerated primal-dual stochastic gradient method for general stochastic convex optimization problems with linear equality constraints. Then, we apply this method to the decentralized distributed optimization setting to generate a new algorithm for the distributed semi-discrete regularized Wasserstein barycenter problem. The proposed algorithm can be executed over arbitrary networks that are undirected, connected and static, using the local information only. Moreover, we show explicit non-asymptotic complexity in terms of the problem parameters. Finally, we show the effectiveness of our method on the distributed computation of the regularized Wasserstein barycenter of univariate Gaussian and von Mises distributions, as well as some applications to image aggregation.
285. **With Friends Like These, Who Needs Adversaries?** --*Nicholas Lord &middot; Saumya Jetley*
 > The vulnerability of deep networks to adversarial attack is now well known, but less well understood. Via a novel empirical analysis, we illustrate some facts about deep convolutional networks that shed new light on the behaviour of deep nets and the problem of adversaries, with two key results. The first is a straightforward explanation of the existence of universal adversarial perturbations, obtained by analysing the connection between class identity and nets' logit responses as functions of movements along (1D) image-space dimensions. The second is the clear demonstration of the tight coupling between classification performance and vulnerability to adversarial attack within these dimensions. Prior work has noted the importance of low-dimensional subspaces in adversarial vulnerability: we illustrate that this is simply the dual of the nets' notion of saliency. In all, we provide a digestible perspective from which to understand previously reported results which have appeared disjoint or contradictory, with implications for efforts to construct neural nets that are both accurate and robust to adversarial attack.
286. **Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger** --*Zeming Lin &middot; Gabriel Synnaeve &middot; Nicolas Usunier &middot; Nicolas Carion &middot; Vasil Khalidov &middot; Vegard Mella*
 > We formulate the problem of \emph{defogging} as state estimation and future state prediction from previous, partial observations in the context of real-time strategy games. We propose to employ encoder-decoder neural networks for this task, and introduce proxy tasks and baselines for evaluation to assess their ability of capturing basic game rules and high-level dynamics. By combining convolutional neural networks and recurrent networks, we exploit spatial and sequential correlations and train well-performing models on a large dataset of human games of StarCraft: Brood War. Finally, we demonstrate the relevance of our models to downstream tasks by applying them for enemy unit prediction in a state-of-the-art, rule-based StarCraft bot. We observe improvements in win rates against several strong community bots.
287. **DropBlock: A regularization method for convolutional networks** --*Golnaz Ghiasi &middot; Tsung-Yi Lin &middot; Quoc V Le*
 >   Deep neural networks often work well when they are over-parameterized and trained with a massive amount of noise and regularization, such as weight decay and dropout. Although dropout is widely used as a regularization technique for fully connected layers, it is often less effective for convolutional layers. This lack of success of dropout for convolutional layers is perhaps due to the fact that neurons in a contiguous region in convolutional layers are strongly correlated so information can still flow through convolutional networks despite dropout. Thus a structured form of dropout is needed to regularize convolutional networks. In this paper, we introduce DropBlock, a form of structured dropout, where neurons in a contiguous region of a feature map are dropped together. Extensive experiments show that DropBlock works much better than dropout in regularizing convolutional networks.   On ImageNet, DropBlock with ResNet-50 architecture achieves $77.65\%$ accuracy, which is more than $1\%$ improvement on the previous result of this architecture.
288. **Autoconj: Recognizing and Exploiting Conjugacy Without a Domain-Specific Language** --*Matthew D. Hoffman &middot; Matthew Johnson &middot; Dustin Tran*
 > Deriving conditional and marginal distributions using conjugacy relationships can be time consuming and error prone. In this paper, we propose a strategy for automating such derivations. Unlike previous systems which focus on relationships between pairs of random variables, our system (which we call Autoconj) operates directly on Python functions that compute log-joint distribution functions. Autoconj provides support for conjugacy-exploiting algorithms in any Python embedded PPL. This paves the way for accelerating development of novel inference algorithms and structure-exploiting modeling strategies.
289. **Analysis of Krylov Subspace Solutions of  Regularized Non-Convex Quadratic Problems** --*Yair Carmon &middot; John C Duchi*
 > We provide convergence rates for Krylov subspace solutions to the trust-region and cubic-regularized (nonconvex) quadratic problems. Such solutions may be efficiently computed by the Lanczos method and have long been used in practice. We prove error bounds of the form $1/t^2$ and $e^{-4t/\sqrt{\kappa}}$, where $\kappa$ is a condition number for the problem, and $t$ is the Krylov subspace order (number of Lanczos iterations). We also provide lower bounds showing that our analysis is sharp.
290. **Mean Field for the Stochastic Blockmodel: Optimization Landscape and Convergence Issues** --*Soumendu Sundar Mukherjee &middot; Purnamrita Sarkar &middot; Y. X. Rachel Wang &middot; Bowei Yan*
 > Variational approximation has been widely used in large-scale Bayesian inference recently, the simplest kind of which involves imposing a mean field assumption to approximate complicated latent structures. Despite the computational scalability of mean field, theoretical studies of its loss function surface and the convergence behavior of iterative updates for optimizing the loss are far from complete. In this paper, we focus on the problem of community detection for a simple two-class Stochastic Blockmodel (SBM). Using batch co-ordinate ascent (BCAVI) for updates, we give a complete characterization of all the critical points and show different convergence behaviors with respect to initializations. When the parameters are known, we show a significant proportion of random initializations will converge to ground truth. On the other hand, when the parameters themselves need to be estimated, a random initialization will converge to an uninformative local optimum.
291. **Robust Subspace Approximation in a Stream** --*Roie Levin &middot; David Woodruff &middot; Anish Prasad Sevekari*
 > <pre><code>We study robust subspace estimation in the streaming and distributed settings. Given a set of n data points {a_i}_{i=1}^n in R^d and an integer k, we wish to find a linear subspace S of dimension k for which sum_i M(dist(S, a_i)) is minimized, where dist(S,x) := min_{y in S} |x-y|_2, and M() is some loss function. When M is the identity function, S gives a subspace that is more robust to outliers than that provided by the truncated SVD. Though the problem is NP-hard, it is approximable within a (1+epsilon) factor in polynomial time when k and epsilon are constant. We give the first sublinear approximation algorithm for this problem in the turnstile streaming and arbitrary partition distributed models, achieving the same time guarantees as in the offline case. Our algorithm is the first based entirely on oblivious dimensionality reduction, and significantly simplifies prior methods for this problem, which held in neither the streaming nor distributed models. </code></pre> 
292. **Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo for Bayesian learning** --*Rui Luo &middot; Yaodong Yang &middot; Jianhong Wang &middot; Jun WANG &middot; Zhanxing Zhu*
 > In this paper, we propose a novel sampling method, the thermostat-assisted continuously-tempered Hamiltonian Monte Carlo, for the purpose of multimodal Bayesian learning. It simulates a noisy dynamical system by incorporating both a continuously-varying tempering variable and the Nos\'e-Hoover thermostats. A significant benefit is that it is not only able to efficiently generate i.i.d. samples when the underlying posterior distributions are multimodal, but also capable of adaptively neutralising the noise arising from the use of mini-batches. While the properties of the approach have been studied using synthetic datasets, our experiments on three real datasets have also shown its performance gains over several strong baselines for Bayesian learning with various types of neural networks plunged in.
293. **Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks** --*Abdullah Rashwan &middot; Agastya Kalra &middot; Pascal Poupart &middot; Prashant Doshi &middot; George Trimponias &middot; Wei-Shou Hsu*
 > Sum-product networks have recently emerged as an attractive representation due to their dual view as a special type of deep neural network with clear semantics and a special type of probabilistic graphical model for which inference is always tractable. Those properties follow from some conditions (i.e., completeness and decomposability) that must be respected by the structure of the network.  As a result, it is not easy to specify a valid sum-product network by hand and therefore structure learning techniques are typically used in practice.  This paper describes a new online structure learning technique for feed-forward and recurrent SPNs. The algorithm is demonstrated on real-world datasets with continuous features for which it is not clear what network architecture might be best, including sequence datasets of varying length.
294. **rho-POMDPs have Lipschitz-Continuous epsilon-Optimal Value Functions** --*Mathieu Fehr &middot; Olivier Buffet &middot; Vincent Thomas &middot; Jilles Dibangoye*
 > Many state-of-the-art algorithms for solving Partially Observable Markov Decision Processes (POMDPs) rely on turning the problem into a â€œfully observableâ€ problemâ€”a belief MDPâ€”and exploiting the piece-wise linearity and convexity (PWLC) of the optimal value function in this new state space (the belief simplex âˆ†). This approach has been extended to solving Ï-POMDPsâ€”i.e., for information-oriented criteriaâ€”when the reward Ï is convex in âˆ†. General Ï-POMDPs can also be turned into â€œfully observableâ€ problems, but with no means to exploit the PWLC property. In this paper, we focus on POMDPs and Ï-POMDPs with Î» Ï -Lipschitz reward function, and demonstrate that, for finite horizons, the optimal value function is Lipschitz-continuous. Then, value function approximators are proposed for both upper- and lower-bounding the optimal value function, which are shown to provide uniformly improvable bounds. This allows proposing two algorithms derived from HSVI which are empirically evaluated on various benchmark problems.
295. **Causal Inference with Noisy and Missing Covariates via Matrix Factorization** --*Xiaojie Mao &middot; Madeleine Udell &middot; Nathan Kallus*
 > Valid causal inference in observational studies often requires controlling for confounders. However, in practice measurements of confounders may be noisy, and can lead to biased estimates of causal effects. We show that we can reduce the bias caused by measurement noise using a large number of noisy measurements of the underlying confounders. We propose the use of matrix factorization to infer the confounders from noisy covariates, a flexible and principled framework that adapts to missing values, accommodates a wide variety of data types, and can augment a wide variety of causal inference methods. We bound the error for the induced average treatment effect estimator and show it is consistent in a linear regression setting, using Exponential Family Matrix Completion preprocessing. We demonstrate the effectiveness of the proposed procedure in numerical experiments  with both synthetic data and real clinical data.
296. **Maximizing Induced Cardinality Under a Determinantal Point Process** --*Jennifer Gillenwater &middot; Alex Kulesza &middot; Sergei Vassilvitskii &middot; Zelda Mariet*
 > Determinantal point processes (DPPs) are well-suited to recommender systems where the goal is to generate collections of diverse, high-quality items. In the existing literature this is usually formulated as finding the mode of the DPP (the so-called MAP set). However, the MAP objective inherently assumes that the DPP models "optimal" recommendation sets, and yet obtaining such a DPP is nontrivial when there is no ready source of example optimal sets. In this paper we advocate an alternative framework for applying DPPs to recommender systems. Our approach assumes that the DPP simply models user engagements with recommended items, which is more consistent with how DPPs for recommender systems are typically trained.  With this assumption, we are able to formulate a metric that measures the expected number of items that a user will engage with.  We formalize this optimization of this metric as the Maximum Induced Cardinality (MIC) problem. Although the MIC objective is not submodular, we show that it can be approximated by a submodular function, and that empirically it is well-optimized by a greedy algorithm.
297. **Efficient Convex Completion of Coupled Tensors using Coupled Nuclear Norms** --*Kishan Wimalawarne &middot; Hiroshi Mamitsuka*
 > Coupled norms have emerged as a convex method to solve coupled tensor completion.    A limitation with coupled norms is that they only induce low rankness using the multilinear rank of coupled tensors. In this paper, we introduce a new set of coupled norms known as coupled nuclear norms by constraining the CP rank of coupled tensors. We propose new coupled completion models using the coupled nuclear norms as regularizers, that can be optimized using computationally efficient optimization methods. We derive excess risk bounds for proposed coupled completion models and show that proposed norms lead to better performances.  Through simulation and real-data experiments, we demonstrate that proposed norms achieve better performances for coupled completion compared to existing coupled norms. 
298. **Bayesian Adversarial Learning** --*Nanyang Ye &middot; Zhanxing Zhu*
 > Deep neural networks have been known to be vulnerable to adversarial attacks, raising lots of security concerns in the practical deployment. Popular defensive approaches can be formulated as a (distributionally) robust optimization problem, which minimizes a ``point estimate'' of worst-case loss derived from either per-datum perturbation or adversary data-generating distribution within certain pre-defined constraints. This point estimate ignores potential test adversaries that are beyond the pre-defined constraints. The model robustness might deteriorate sharply in the scenario of stronger test adversarial data. In this work, a novel robust training framework is proposed to alleviate this issue, Bayesian Robust Learning, in which a  distribution is put on the adversarial data-generating distribution to account for the uncertainty of the adversarial data-generating process. The uncertainty directly helps to consider the potential adversaries that are stronger than the point estimate in the cases of distributionally robust optimization. The uncertainty of model parameters is also incorporated to accommodate the full Bayesian framework. We design a scalable Markov Chain Monte Carlo sampling strategy to obtain the posterior distribution over model parameters. Various experiments are conducted to verify the superiority of BAL over existing adversarial training methods. 
299. **Differentially Private Testing of Identity and Closeness of Discrete Distributions** --*Jayadev Acharya &middot; Ziteng Sun &middot; Huanyu Zhang*
 > We study the fundamental problems of identity testing (goodness of fit), and closeness testing (two sample test) of distributions over $k$ elements, under differential privacy. While the problems have a long history in statistics,  finite sample bounds for these problems have only been established recently.   In this work, we derive upper and lower bounds on the sample complexity of both the problems under $(\varepsilon, \delta)$-differential privacy. We provide optimal sample complexity algorithms for identity testing problem for all parameter ranges, and  the first results for closeness testing. Our closeness testing bounds are optimal in the sparse regime where the number of samples is at most $k$.   Our upper bounds are obtained by privatizing non-private estimators for these problems. The non-private estimators are chosen to have small sensitivity. We propose a general framework to establish lower bounds on the sample complexity of statistical tasks under differential privacy. We show a bound on differentially private algorithms in terms of a coupling between the two hypothesis classes we aim to test. By constructing carefully chosen priors over the hypothesis classes, and using Le Cam's two point theorem we provide a general mechanism for proving lower bounds.  We believe that the framework can be used to obtain strong lower bounds for other statistical tasks under privacy.
300. **Scaling Gaussian Process Regression with Derivatives** --*David Eriksson &middot; Kun Dong &middot; Eric H Lee &middot; David Bindel &middot; Andrew G Wilson*
 > Gaussian processes (GPs) with derivatives are useful in many applications, including Bayesian optimization, implicit surface reconstruction, and terrain reconstruction. Fitting a GP to function values and derivatives at $n$ points in $d$ dimensions requires linear solves and log determinants with an ${n(d+1) \times n(d+1)}$ positive definite matrix -- leading to prohibitive $\mathcal{O}(n^3d^3)$ computations for standard direct methods. We propose $\mathcal{O}(nd)$ iterative solvers using fast matrix-vector multiplications (MVMs), together with pivoted Cholesky preconditioning that cuts the iterations to convergence by several orders of magnitude, allowing for fast kernel learning and prediction. Our approaches, together with dimensionality reduction, allows us to scale Bayesian optimization with derivatives to high-dimensional problems and large evaluation budgets. 
301. **Stochastic Nonparametric Event-Tensor Decomposition** --*Shandian Zhe &middot; Yishuai Du*
 > Tensor decompositions are fundamental tools for multiway data analysis. Existing approaches, however, ignore the valuable temporal information along with data, or simply discretize them into time steps so that important temporal patterns are easily missed. Moreover, most methods are limited to multilinear decomposition forms, and hence are unable to capture intricate, nonlinear relationships in data. To address these issues, we formulate event-tensors, to preserve the complete temporal information for multiway data, and propose a novel Bayesian nonparametric decomposition model. Our model can (1) fully exploit the time stamps to capture the critical, causal/triggering effects between the interaction events,  (2) flexibly estimate the complex relationships between the entities in tensor modes, and (3) uncover hidden structures from their temporal interactions. For scalable inference, we develop a doubly stochastic variational Expectation-Maximization algorithm to conduct an online decomposition. Evaluations on both synthetic and real-world datasets show that our model not only improves upon the predictive performance of existing methods, but also discovers interesting clusters underlying the data. 
302. **Scalable Hyperparameter Transfer Learning** --*Valerio Perrone &middot; Rodolphe Jenatton &middot; Matthias W Seeger &middot; Cedric Archambeau*
 > Bayesian optimization (BO) is a model-based approach for gradient-free black-box function optimization, such as hyperparameter optimization. Typically, BO relies on conventional Gaussian process (GP) regression, whose algorithmic complexity is cubic in the number of evaluations. As a result, GP-based BO cannot leverage large numbers of past function evaluations, for example, to warm-start related BO runs. We propose a multi-task adaptive Bayesian linear regression model for transfer learning in BO, whose complexity is linear in the function evaluations: one Bayesian linear regression model is associated to each black-box function optimization problem (or task), while transfer learning is achieved by coupling the models through a shared deep neural net. Experiments show that the neural net learns a representation suitable for warm-starting the black-box optimization problems and that BO runs can be accelerated when the target black-box function (e.g., validation loss) is learned together with other related signals (e.g., training loss). The proposed method was found to be at least one order of magnitude faster that methods recently published in the literature.
303. **Diminishing Returns Shape Constraints for Interpretability and Regularization** --*Maya Gupta &middot; Dara Bahri &middot; Andrew Cotter &middot; Kevin Canini*
 > We investigate machine learning models that can provide diminishing returns and accelerating returns guarantees to capture prior knowledge or policies about how outputs should depend on inputs. Shape constraints are well-explored for one-dimensional models and generalized additive models (GAMs). We show that one can build flexible, nonlinear, multi-dimensional models using lattice functions with any combination of (ceterus paribus) concavity/convexity and monotonicity constraints on any subsets of features. We show better accuracy than shape-constrained GAMs, and more flexibility in shape constraint choice and training stability than for shape-constrained neural networks, which we also extend to handle the diminishing returns case. We demonstrate on real-world examples that additional shape constraints aid interpretability and can improve accuracy, especially when tuning-free regularization is useful.
304. **Generative Probabilistic Novelty Detection with Adversarial Autoencoders** --*Stanislav Pidhorskyi &middot; Ranya Almohsen &middot; Gianfranco Doretto*
 > Novelty detection is the problem of identifying whether a new data point is considered to be an inlier or an outlier. We assume that training data is available to describe only the inlier distribution. Recent approaches primarily leverage deep encoder-decoder network architectures to compute a reconstruction error that is used to either compute a novelty score or to train a one-class classifier. While we too leverage a novel network of that kind, we take a probabilistic approach and effectively compute how likely is that a sample was generated by the inlier distribution. We achieve this with two main contributions. First, we make the computation of the novelty probability feasible because we linearize the parameterized manifold capturing the underlying structure of the inlier distribution, and show how the probability factorizes and can be computed with respect to local coordinates of the manifold tangent space. Second, we improved the training of the autoencoder network. An extensive set of results show that the approach achieves state-of-the-art results on several benchmark datasets.
305. **Efficient Gradient Computation for Structured Output Learning with Rational and Tropical Losses** --*Dmitry Storcheus &middot; Mehryar Mohri &middot; Vitaly Kuznetsov &middot; Corinna Cortes &middot; Scott Yang*
 > We present a general framework for designing efficient and scalable gradient computations for structured output prediction problems. These gradients can be used with algorithms such as back propagation for deep learning. While many structured prediction problems admit a natural loss function for evaluation such as the edit-distance or $n$-gram loss, existing learning algorithms are typically designed to optimize alternative objectives such as the cross-entropy. This is because a na\"{i}ve implementation of the natural loss functions often results in intractable gradient computations. In this paper, we design efficient gradient computations for learning algorithms for two broad families of structured prediction loss functions, rational and tropical losses, which include the edit-distance and other string similarity measures as special cases.  Our methods cast the gradient computation as a shortest path problem on a weighted finite state transducer and allow training machine learning models (including neural networks) using complex structured losses which were heretofore intractable. We report experimental results confirming significant runtime improvement compared to direct methods.
306. **Extracting Relationships by Multi-Domain Matching** --*Yitong Li &middot; David E Carlson*
 > In many biological and medical contexts, we construct a large labeled corpus by aggregating many sources to use in target prediction tasks.  Unfortunately, many of the sources may be irrelevant to our target task, so ignoring the structure of the dataset is detrimental.  This work proposes a novel approach, the Multiple Domain Matching Network (MDMN), to exploit this structure. MDMN embeds all data into a shared feature space while learning which domains share strong statistical relationships. These relationships are often insightful in their own right, and they allow domains to share strength without interference from irrelevant data. This methodology builds on existing distribution-matching approaches by assuming that source domains are varied and outcomes multi-factorial. Therefore, each domain should only match a relevant subset. Theoretical analysis shows that the proposed approach can have a tighter generalization bound than existing multiple-domain adaptation approaches.  Empirically, we show that the proposed methodology handles higher numbers of source domains (up to 21 empirically), and provides state-of-the-art performance on image, text, and multi-channel time series classification, including clinically relevant data of a novel treatment of Autism Spectrum Disorder.
307. **M-Walk: Learning to Walk in Graph  with Monte Carlo Tree Search** --*Yelong Shen &middot; Jianshu Chen &middot; Po-Sen Huang &middot; Yuqing Guo &middot; Jianfeng Gao*
 > Learning to walk over a graph towards a target node for a given input query and a source node is an important problem in  applications such as knowledge base completion (KBC). It can be formulated as a reinforcement learning (RL) problem that has a known state transition model, but with sparse reward. To overcome the challenge, we develop a graph walking agent called M-Walk, which consists of a deep recurrent neural network (RNN) and a Monte Carlo Tree Search (MCTS). The RNN encodes the state (i.e., history of the walking path) and map it into the Q-value, the policy and the state value. In order to effectively train the agent from sparse reward, we combine MCTS with the neural policy to generate trajectories with more positive rewards. From these trajectories, we improve the network in an off-policy manner using Q-learning, which indirectly improves the RNN policy via parameter sharing. Our proposed RL algorithm repeatedly applies this policy improvement step to learn the entire model. At testing stage, the MCTS is also applied with the neural policy to predict the target node. Experiment results on several graph-walking benchmarks show that we are able to learn better policies compared to other RL-based baseline methods, which are mainly based on policy gradient method. It also outperforms traditional KBC baselines.
308. **BRITS: Bidirectional Recurrent Imputation for Time Series** --*Wei Cao &middot; Dong Wang &middot; Jian Li &middot; Hao Zhou &middot; Lei Li &middot; Yitan Li*
 > Time series are widely used as signals in many classification/regression tasks. It is ubiquitous that time series contains many missing values. Given multiple correlated time series data, how to fill in missing values and to predict their class labels? Existing imputation methods often impose strong assumptions of the underlying data generating process, such as linear dynamics in the state space.  In this paper, we propose BRITS, a novel method based on recurrent neural networks for missing value imputation in time series data.  Our proposed method directly learns the missing values in a bidirectional recurrent dynamical system, without any specific assumption. The imputed values are treated as variables of RNN graph and can be effectively updated during the backpropagation. BRITS has three advantages: (a) it can handle multiple correlated missing values in time series; (b) it generalizes to time series with nonlinear dynamics underlying; (c) it provides a data-driven imputation procedure and applies to general settings with missing data. We evaluate our model on three real-world datasets, including an air quality dataset, a health-care data, and a localization data for human activity. Experiments show that our model outperforms the state-of-the-art methods in both imputation and classification/regression accuracies. 
309. **Provable Gaussian Embedding with One Observation** --*Ming Yu &middot; Zhuoran Yang &middot; Tuo Zhao &middot; Mladen Kolar &middot; Princeton Zhaoran Wang*
 > Success of machine learning methods heavily relies on having an appropriate representation for data at hand. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about data. However, recently there has been a surge in approaches that learn how to encode the data automatically in a low dimensional space. Exponential family embedding provides a probabilistic framework for learning low-dimensional representation for various types of high-dimensional data. Though successful in practice, theoretical underpinnings for exponential family embeddings have not been established. In this paper, we study Gaussian embedding model and develop the first theoretical results for exponential family embedding models. First, we show that, under mild condition, the embedding structure can be learned from one observation by leveraging the parameter sharing between different contexts even though the data are dependent with each other.  Second, we study properties of two algorithms used for learning the embedding structure and establish convergence results for each of them. The first algorithm is based on a convex relaxation, while the other solved the non-convex formulation of the problem directly. Experiments demonstrate the effectiveness of our approach.
310. **Banach Wasserstein GAN** --*Jonas Adler &middot; Sebastian Lunz*
 > Wasserstein Generative Adversarial Networks (WGANs) can be used to generate realistic samples from complicated image distributions. The Wasserstein metric used in WGANs is based on a notion of distance between individual images, which  induces a notion of distance between probability distributions of images. So far the community has considered l^2 as the underlying distance. We generalize the theory of WGAN with gradient penalty to Banach spaces, allowing practitioners to select the features to emphasize in the generator. We further discuss the effect of some particular choices of underlying norms, focusing on Sobolev norms. Finally, we demonstrate the impact of the choice of norm on model performance and show state-of-the-art inception scores for non-progressive growing GANs on CIFAR-10.
311. **A Theory-Based Evaluation of Nearest Neighbor Models Put Into Practice** --*Hendrik Fichtenberger &middot; Dennis Rohde*
 > In the $k$-nearest neighborhood model ($k$-NN), we are given a set of points $P$, and we shall answer queries $q$ by returning the $k$ nearest neighbors of $q$ in $P$ according to some metric. This concept is crucial in many areas of data analysis and data processing, e.g., computer vision, document retrieval and machine learning. Many $k$-NN algorithms have been published and implemented, but often the relation between parameters and accuracy of the computed $k$-NN is not explicit. We study property testing of $k$-NN graphs in theory and evaluate it empirically: given a point set $P \subset \mathbb{R}^\delta$ and a directed graph $G=(P,E)$, is $G$ a $k$-NN graph, i.e., every point $p \in P$ has outgoing edges to its $k$ nearest neighbors, or is it $\epsilon$-far from being a $k$-NN graph? Here, $\epsilon$-far means that one has to change more than an $\epsilon$-fraction of the edges in order to make $G$ a $k$-NN graph. We develop a randomized algorithm with one-sided error that decides this question, i.e., a property tester for the $k$-NN property, with complexity $O(\sqrt{n} k^2 / \epsilon^2)$ measured in terms of the number of vertices and edges it inspects, and we prove a lower bound of $\Omega(\sqrt{n})$. We evaluate our tester empirically on the $k$-NN models computed by various algorithms and show that it can be used to detect $k$-NN models with bad accuracy in significantly less time than the building time of the $k$-NN model.
312. **Policy Regret in Repeated Games** --*Raman Arora &middot; Michael Dinitz &middot; Teodor Vanislavov Marinov &middot; Mehryar Mohri*
 > The notion of <code>policy regret'' in online learning is supposed to capture the reactions of the adversary to the actions taken by the learner, which more traditional notions such as external regret do not take into account.  We revisit this notion of policy regret, and first show that there are online learning settings in which policy regret and external regret are incompatible: any sequence of play which does well with respect to one must do poorly with respect to the other.  We then focus on the game theoretic setting, when the adversary is a self-interested agent.  In this setting we show that the external regret and policy regret are not in conflict, and in fact that a wide class of algorithms can ensure both as long as the adversary is also using such an algorithm.  We also define a new notion of equilibrium which we call a</code>policy equilibrium'', and show that no-policy regret algorithms will have play which converges to such an equilibrium.  Relating this back to external regret, we show that coarse correlated equilibria (which no-external regret players will converge to) are a strict subset of policy equilibria.  So in game-theoretic settings every sequence of play with no external regret also has no policy regret, but the converse is not true.
313. **Large-Scale Stochastic Sampling from the Probability Simplex** --*Jack Baker &middot; Paul Fearnhead &middot; Emily Fox &middot; Christopher Nemeth*
 > Stochastic gradient Markov chain Monte Carlo (SGMCMC) has become a popular method for scalable Bayesian inference. These methods are based on sampling a discrete-time approximation to a continuous time process, such as the Langevin diffusion. When applied to distributions defined on a constrained space, such as the simplex, the time-discretisation error can dominate when we are near the boundary of the space. We demonstrate that while current SGMCMC methods for the simplex perform well in certain cases, they struggle with sparse simplex spaces; when many of the components are close to zero. However, most popular large-scale applications of Bayesian inference on simplex spaces, such as network or topic models, are  sparse. We argue that this poor performance is due to the biases of SGMCMC caused by the discretization error. To get around this, we propose the stochastic CIR process, which removes all discretization error and we prove that samples from the stochastic CIR process are asymptotically unbiased.  Use of the stochastic CIR process within a SGMCMC algorithm is shown to give substantially better performance for a topic model and a Dirichlet process mixture model than existing SGMCMC approaches.
314. **Heterogeneous Multi-output Gaussian Process Prediction** --*Pablo Moreno-MuÃ±oz &middot; Antonio ArtÃ©s &middot; Mauricio Ãlvarez*
 > We present a novel extension of multi-output Gaussian processes for handling heterogeneous outputs. We assume that each output has its own likelihood function and use a vector-valued Gaussian process prior to jointly model the parameters in all likelihoods as latent functions. Our multi-output Gaussian process uses a covariance function with a linear model of coregionalisation form. Assuming conditional independence across the underlying latent functions together with an inducing variable framework, we are able to obtain tractable variational bounds amenable to stochastic variational inference.  We illustrate the performance of the model on synthetic data and two real datasets: a human behavioral study and a demographic high-dimensional dataset.
315. **On gradient regularizers for MMD GANs** --*Michael Arbel &middot; Dougal Sutherland &middot; Mikolaj Binkowski &middot; Arthur Gretton*
 > We propose a principled method for gradient-based regularization of the critic of GAN-like models trained by adversarially optimizing the kernel of a Maximum Mean Discrepancy (MMD). Our method is based on studying the behavior of the optimized MMD, and constrains the gradient based on analytical results rather than an optimization penalty. Experimental results show that the proposed regularization leads to stable training and outperforms state-of-the art methods on image generation, including on 160 Ã— 160 CelebA and 64 Ã— 64 ImageNet.
316. **Model-based targeted dimensionality reduction for neuronal population data** --*Mikio C Aoi &middot; Jonathan W Pillow*
 > Summarizing high-dimensional data using a small number of parameters is a ubiquitous first step in the analysis of neuronal population activity. Recently developed methods use "targeted" approaches that work by identifying multiple, distinct low-dimensional subspaces of activity that capture the population response to individual experimental task variables, such as the value of a presented stimulus or the behavior of the animal. These methods have gained attention because they decompose total neural activity into what are ostensibly different parts of a neuronal computation. However, existing targeted methods have been developed outside of the confines of probabilistic modeling, making some aspects of the procedures ad hoc, or limited in flexibility or interpretability. Here we propose a new model-based method for targeted dimensionality reduction based on a probabilistic generative model of the population response data.  The low-dimensional structure of our model is expressed as a low-rank factorization of a linear regression model. We perform efficient inference using a combination of expectation maximization and direct maximization of the marginal likelihood. We also develop an efficient method for estimating the dimensionality of each subspace. We show that our approach outperforms alternative methods in both mean squared error of the parameter estimates, and in identifying the correct dimensionality of encoding using simulated data. We also show that our method provides more accurate inference of low-dimensional subspaces of activity than a competing algorithm, demixed PCA.
317. **Representation Learning of Compositional Data** --*Richard Nock &middot; Cheng Soon Ong &middot; Ke Sun &middot; Julien Rouar &middot; Marta Avalos*
 > We consider the problem of learning a low dimensional representation for   compositional data. Compositional data consists of a collection of nonnegative data   that sum to a constant value. Since the parts of the collection are statistically   dependent, many standard tools cannot be directly applied. Instead compositional data must   be first transformed before analysis. Focusing on   principal component analysis (PCA), we propose an approach that allows low dimensional   representation learning directly from the original data.   We show that our proposed loss function upper bounds the exponential family PCA   loss applied to transformed compositional data.   A key tool in showing this relationship is a generalization of the scaled Bregman   Theorem that equates the perspective transform of the generator of a Bregman divergence   to the Bregman divergence of the perspective transform and a conformal divergence.   Our proposed surrogate loss has an easy to optimize form, and we also derive the corresponding   form for nonlinear autoencoders. Experiments on simulated data and microbiome data show   the promise of our method.
318. **Modeling Dynamic Missingness of Implicit Feedback for Recommendation** --*  &middot; Kun Zhang &middot; Xiaolin Zheng &middot; Mingming Gong*
 > Implicit feedback is widely used in collaborative filtering methods for recommendation. It is well known that implicit feedback contains a large number of values that are \emph{missing not at random} (MNAR); and the missing data is a mixture of negative and unknown feedback, making it difficult to learn user's negative preferences.  Recent studies modeled \emph{exposure}, a latent missingness variable which indicates whether an item is missing to a user, to give each missing entry a confidence of being negative feedback. However, these studies use static models and ignore the information in temporal dependencies among items, which seems to be a essential underlying factor to subsequent missingness. To model and exploit the dynamics of missingness, we propose a latent variable named ``\emph{user intent}'' to govern the temporal changes of item missingness, and a hidden Markov model to represent such a process. The resulting framework captures the dynamic item missingness and incorporate it into matrix factorization (MF) for recommendation. We also explore two types of constraints to achieve a more compact and interpretable representation of \emph{user intents}. Experiments on real-world datasets demonstrate the superiority of our method against state-of-the-art recommender systems.
319. **Training Neural Networks Using Features Replay** --*Zhouyuan Huo &middot; Bin Gu &middot; Heng Huang*
 > Training a neural network using backpropagation algorithm requires passing error gradients sequentially through the network. The backward locking prevents us from updating network layers in parallel and fully leveraging the computing resources.  Recently, there are several works trying to decouple and parallelize the backpropagation algorithm. However, all of them suffer from severe accuracy loss or memory explosion when the neural network is deep.  To address these challenging issues, we propose a novel parallel-objective formulation for the objective function of the neural network. After that,  we introduce features replay algorithm and prove that it is guaranteed to converge to critical points for the non-convex problem under certain conditions. Finally, we apply our method to training deep convolutional neural networks, and the experimental results show that the proposed method achieves {faster} convergence, {lower} memory consumption, and {better} generalization error than compared methods.
320. **Query K-means Clustering and the Double Dixie Cup Problem** --*I Chien &middot; Chao Pan &middot; Olgica Milenkovic*
 > We consider the problem of approximate $K$-means clustering with outliers and side information provided by same-cluster queries and possibly noisy answers. Our solution shows that, under some mild assumptions on the smallest cluster size, one can obtain an $(1+\epsilon)$-approximation for the optimal potential with probability at least $1-\delta$, where $\epsilon>0$ and $\delta\in(0,1)$, using an expected number of $O(\frac{K^3}{\epsilon \delta})$ noiseless same-cluster queries and comparison-based clustering of complexity $O(ndK + \frac{K^3}{\epsilon \delta})$; here, $n$ denotes the number of points and $d$ the dimension of space. Compared to a handful of other known approaches that perform importance sampling to account for small cluster sizes, the proposed query technique reduces the number of queries by a factor of roughly $O(\frac{K^6}{\epsilon^3})$, at the cost of possibly missing very small clusters. We extend this settings to the case where some queries to the oracle produce erroneous information, and where certain points, termed outliers, do not belong to any clusters. Our proof techniques differ from previous methods used for $K$-means clustering analysis, as they rely on estimating the sizes of the clusters and the number of points needed for accurate centroid estimation and subsequent nontrivial generalizations of the double Dixie cup problem. We illustrate the performance of the proposed algorithm both on synthetic and real datasets, including MNIST and CIFAR $10$.
321. **CatBoost: unbiased boosting with categorical features** --*Liudmila Prokhorenkova &middot; Gleb Gusev &middot; Aleksandr Vorobev &middot; Anna Veronika Dorogush &middot; Andrey Gulin*
 > This paper presents the key algorithmic techniques behind CatBoost, a new gradient boosting toolkit. Their combination leads to CatBoost outperforming other publicly available boosting implementations in terms of quality on a variety of datasets. Two critical algorithmic advances introduced in CatBoost are the implementation of ordered boosting, a permutation-driven alternative to the classic algorithm, and an innovative algorithm for processing categorical features. Both techniques were created to fight a prediction shift caused by a special kind of target leakage present in all currently existing implementations of gradient boosting algorithms. In this paper, we provide a detailed analysis of this problem and demonstrate that proposed algorithms solve it effectively, leading to excellent empirical results.
322. **Incorporating Context into Language Encoding Models for fMRI** --*Shailee Jain &middot; Alexander Huth*
 > Language encoding models help explain language processing in the human brain by learning functions that predict brain responses from the language stimuli that elicited them. Current word embedding-based approaches treat each stimulus word independently and thus ignore the influence of context on language understanding. In this work we instead build encoding models using rich contextual representations derived from an LSTM language model. Our models show a significant improvement in encoding performance relative to state-of-the-art embeddings in nearly every brain area. By varying the amount of context used in the models and providing the models with distorted context, we show that this improvement is due to a combination of better word embeddings learned by the LSTM language model and contextual information. We are also able to use our models to map context sensitivity across the cortex. These results suggest that LSTM language models learn high-level representations that are related to representations in the human brain.
323. **An Improved Analysis of Alternating Minimization for Structured Multi-Response Regression** --*Sheng Chen &middot; Arindam Banerjee*
 > Multi-response linear models aggregate a set of vanilla linear models by assuming correlated noise across them, which has an unknown covariance structure. To find the coefficient vector, estimators with a joint approximation of the noise covariance are often preferred than the simple linear regression in view of their superior empirical performance, which can be generally solved by alternating-minimization type procedures. Due to the non-convex nature of such joint estimators, the theoretical justification of their efficiency is typically challenging. The existing analyses fail to fully explain the empirical observations due to the assumption of resampling on the alternating procedures, which requires access to fresh samples in each iteration. In this work, we present a resampling-free analysis for the alternating minimization algorithm applied to the multi-response regression. In particular, we focus on the high-dimensional setting of multi-response linear models with structured coefficient parameter, and the statistical error of the parameter can be expressed by the complexity measure, Gaussian width, which is related to the assumed structure. More importantly, to the best of our knowledge, our result reveals for the first time that the alternating minimization with random initialization can achieve the same performance as the well-initialized one when solving this multi-response regression problem. Experimental results support our theoretical developments.
324. **Contamination Attacks in Multi-Party Machine Learning** --*Jamie Hayes &middot; Olya Ohrimenko*
 > Machine learning is data hungry; the more data a model has access to in training, the more likely it is to perform well at inference time. Distinct parties may want to combine their local data to gain the benefits of a model trained on a large corpus of data. We consider such a case, where the local data remains private and only the model trained on the joint data is revealed. We show that there exists attacks that are stealthy and can compromise the integrity of the model. We then show how adversarial training can defend against such attacks.
325. **Approximating Real-Time Recurrent Learning with Random Kronecker Factors** --*Asier Mujika &middot; Florian Meier &middot; Angelika Steger*
 > Despite all the impressive advances of recurrent neural networks, sequential data is still in need of better modelling. Truncated backpropagation through time (TBPTT), the learning algorithm most widely used in practice, suffers from the truncation bias, which drastically limits its ability to learn long-term dependencies.The Real Time Recurrent Learning algorithm (RTRL) addresses this issue,  but its high computational requirements  make it infeasible in practice. The Unbiased Online Recurrent Optimization algorithm (UORO) approximates RTRL with a smaller runtime and memory cost, but with the disadvantage  of obtaining noisy gradients that also limit its practical applicability. In this paper we propose the Kronecker Factored RTRL (KF-RTRL) algorithm that uses a Kronecker product decomposition to approximate the gradients for a large class of RNNs. We show that KF-RTRL is an unbiased and memory efficient online learning algorithm. Our theoretical analysis shows that, under reasonable assumptions, the noise introduced by our algorithm is not only stable over time but also asymptotically much smaller than the one of the UORO algorithm. We also confirm these theoretical results experimentally. Further, we show empirically that the KF-RTRL algorithm captures long-term dependencies and almost matches the performance of TBPTT on real world tasks by training Recurrent Highway Networks on a synthetic string memorization task and on the Penn TreeBank task, respectively. These results indicate that RTRL based approaches might be a promising future alternative to TBPTT.
326. **Unsupervised Learning of Artistic Styles with Archetypal Style Analysis** --*Daan Wynen &middot; Cordelia Schmid &middot; Julien Mairal*
 > In this paper, we introduce an unsupervised learning approach to automatically dis- cover, summarize, and manipulate artistic styles from large collections of paintings. Our method is based on archetypal analysis, which is an unsupervised learning technique akin to sparse coding with a geometric interpretation. When applied to deep image representations from a data collection, it learns a dictionary of archetypal styles, which can be easily visualized. After training the model, the style of a new image, which is characterized by local statistics of deep visual features, is approximated by a sparse convex combination of archetypes. This allows us to interpret which archetypal styles are present in the input image, and in which proportion. Finally, our approach allows us to manipulate the coefficients of the latent archetypal decomposition, and achieve various special effects such as style enhancement, transfer, and interpolation between multiple archetypes.
327. **Black-box ODE Solvers as a Modeling Primitive** --*Tian Qi Chen &middot; Yulia Rubanova &middot; Jesse Bettencourt &middot; David Duvenaud*
 > We explore the use of ordinary differential equations (ODEs) as a primitive for model-building. First, we show how to perform efficient reverse-mode automatic differentiation through any ODE solver. We then demonstrate this new modeling primitive by training continuous-time analogs of residual networks, normalizing flows, and recurrent neural networks. We demonstrate convenient properties of these models, including limited memory usage and an explicit tradeoff between accuracy and computational cost. In the case of time-series models, ODE solvers allow both continuous-time observations, and conditioning on event times using Poisson process likelihoods. In the case of normalizing flows, our continuous formulation lets us scalably use multiple concurrent flows, and are cheaply reversible.
328. **On Coresets for Logistic Regression** --*Alexander Munteanu &middot; Christian Sohler &middot; Chris Schwiegelshohn &middot; David Woodruff*
 > Coresets are one of the central methods to facilitate the analysis of large data sets. We continue a recent line of research applying the theory of coresets to logistic regression. First, we show a negative result, namely, that no strongly sublinear sized coresets exist for logistic regression. To deal with intractable worst-case instances we introduce a complexity measure $\mu(X)$, which quantifies the hardness of compressing a data set for logistic regression. $\mu(X)$ has an intuitive statistical interpretation that may be of independent interest. For data sets with bounded $\mu(X)$-complexity, we show that a novel sensitivity sampling scheme produces the first provably sublinear $(1\pm\eps)$-coreset. We illustrate the performance of our method by comparing to uniform sampling as well as to state of the art methods in the area. The experiments are conducted on real world benchmark data for logistic regression.
329. **Proximal SCOPE for Distributed Sparse Learning** --*Shenyi Zhao &middot; Gong-Duo Zhang &middot; Ming-Wei Li &middot; Wu-Jun Li*
 > Distributed sparse learning with a cluster of multiple machines has attracted much attention in machine learning, especially for large-scale applications with high-dimensional data. One popular way to implement sparse learning is to use L<em>1 regularization. In this paper, we propose a novel method, called proximal SCOPE(pSCOPE), for distributed sparse learning with L</em>1 regularization. pSCOPE is based on a cooperative autonomous local learning (CALL) framework. In the CALL framework of pSCOPE, we find that the data partition affects the convergence of the learning procedure, and subsequently we define a metric to measure the goodness of a data partition. Based on the defined metric, we theoretically prove that pSCOPE is convergent with a linear convergence rate if the data partition is good enough. We also prove that better data partition implies faster convergence rate. Furthermore, pSCOPE is also communication efficient. Experimental results on real data sets show that pSCOPE can outperform other state-of-the-art distributed methods for sparse learning.
330. **Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks** --*Yusuke Tsuzuku &middot; Issei Sato &middot; Masashi Sugiyama*
 > High sensitivity of neural networks against malicious perturbations on inputs causes security concerns. To take a steady step towards robust classifiers, we aim to create neural network models provably defended from perturbations. Prior certification work requires strong assumptions on network structures and massive computational costs, and thus, their applications are limited. Based on the relationship between the Lipschitz constants and prediction margins, we present a computationally efficient calculation technique that lower-bounds the size of adversarial perturbations that can deceive networks, and that is widely applicable to various complicated networks. Moreover, we propose an efficient training procedure, which robustifies networks and significantly improves the provably guarded areas around data points. In experimental evaluations, our method showed its ability to provide a non-trivial guarantee and improve robustness for even large networks.
331. **The Everlasting Database: Statistical Validity at a Fair Price** --*Blake Woodworth &middot; Vitaly Feldman &middot; Saharon Rosset &middot; Nati Srebro*
 >   The problem of handling adaptivity in data analysis, intentional or not,  permeates   a variety of fields, including  test-set overfitting in ML challenges and the   accumulation of invalid scientific discoveries.   We propose a mechanism for answering an arbitrarily long sequence of   potentially adaptive statistical queries, by charging a price for   each query and using the proceeds to collect additional samples.   Crucially, we guarantee statistical validity without any assumptions on   how the queries are generated. We also ensure with high probability that   the cost for $M$ non-adaptive queries is $O(\log M)$,   while the cost to a potentially adaptive user who makes $M$   queries that do not depend on any others is $O(\sqrt{M})$.
332. **On the Local Hessian in Back-propagation** --*Huishuai Zhang &middot; Wei Chen &middot; Tieyan Liu*
 > Back-propagation (BP) is the foundation for successfully training deep neural networks. However, BP sometimes has difficulties in propagating a learning signal deep enough effectively, e.g., the vanishing gradient phenomenon. Meanwhile, BP often works well when combining with ``designing tricks'' like orthogonal initialization, batch normalization and skip connection. There is no clear understanding on what is essential to the efficiency of BP. In this paper, we take one step towards clarifying this problem. We view BP as a solution of back-matching propagation which minimizes a sequence of back-matching losses each corresponding to one block of the network. We study the Hessian of the local back-matching loss (local Hessian)  and connect it to the efficiency of BP. It turns out that those designing tricks facilitate BP by improving the spectrum of local Hessian. In addition, we can utilize the local Hessian to balance the training pace of each block and design new training algorithms. Based on a scalar approximation of local Hessian, we propose a scale-amended SGD algorithm. We apply it to train neural networks with batch normalization, and achieve favorable results over vanilla SGD. This corroborates the importance of local Hessian from another side.
333. **Compact Generalized Non-local Network** --*Kaiyu Yue &middot; Ming Sun &middot; Yuchen Yuan &middot; Errui Ding &middot; Fuxin Xu &middot; Feng Zhou*
 > The non-local module is designed for capturing long-range spatio-temporal dependencies in images and videos. Although having shown excellent performance, it lacks the mechanism to model the interactions between positions across channels, which are of vital importance in recognizing fine-grained objects and actions. To address this limitation, we generalize the non-local module and take the correlations between the positions of any two channels into account. This extension unifies second-order feature pooling and achieves state-of-the-arts performance on a variety of fine-grained classification tasks. However, it also leads to an explosion in the computational complexity. To alleviate such an issue, we further propose its compact representation to reduce the high-dimensional feature space and large computation burden involved. Moreover, we try to group the channels and do our generalized non-local method within each group. Experimental results illustrate the significant improvements and practical applicability of the generalized non-local module on both fine-grained object and video classification. Code will be made publicly available to ease the future research.
334. **Online Adaptive Methods, Universality and Acceleration** --*Yehuda Kfir Levy &middot; Alp Yurtsever &middot; Volkan Cevher*
 > We present a novel method for convex unconstrained optimization that, without  any modifications ensures: (1) accelerated convergence rate for smooth objectives, (2) standard convergence rate in the general (non-smooth) setting, and (3)  standard convergence rate in the stochastic optimization setting. <br /> To the best of our knowledge, this is the first method that simultaneously applies to all of the above settings. <br /> At the heart of our method is an adaptive learning rate rule that employs importance weights, in the spirit of adaptive online learning algorithms  [duchi2011adaptive,levy2017online],  combined with an update  that linearly couples two sequences, in the spirit of [AllenOrecchia2017]. An empirical examination of our method demonstrates its applicability to the above mentioned scenarios and corroborates our theoretical findings.
